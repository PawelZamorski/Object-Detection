{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This example uses Iris dataset downloaded from scikit-learn.\n",
    "\n",
    "Target are classes: 3 types of Iris flowers.\n",
    "\n",
    "We use classification Neuron Nets to predict the result based on 4 features (petal width, ...)\n",
    "\n",
    "Input layer - there are 4 features - we need 4 inputs.\n",
    "\n",
    "Hidden layer - we will use Feed Forward type of NN. In Keras it is implemented by Sequential class. \n",
    "\n",
    "Output layer - there are 3 classes - we need 3 outputs.\n",
    "\n",
    "# Conda\n",
    "\n",
    "At first we need to intall keras library. Conda is a package manager used by Anaconda. It installs packages into Anaconda environment. Conda uses command line interface. It is better to use Anaconda's CMD.exe for that purpose, because it will find conda package. If you want to use Windows CMD you have to define variable PATH at first.\n",
    "\n",
    "Keras package at anaconda channel: https://anaconda.org/anaconda/keras\n",
    "\n",
    "List of conda commands: https://docs.conda.io/projects/conda/en/latest/commands.html\n",
    "\n",
    "To display all packages run this command:\n",
    "\n",
    "conda list\n",
    "\n",
    "\n",
    "By running straight away command ( conda install -c anaconda keras ) I had many conflicts during installation, it took about 30 minutes and did not install keras. I solved this problem by updating all packages before installing keras. Make sure which version of Python is used by Anaconda. It should be 3.8.\n",
    "\n",
    "\n",
    "\n",
    "conda update --all\n",
    "\n",
    "conda install -c anaconda keras\n",
    "\n",
    "-  -c stands for channel, were packages are located. The default channel for conda is anaconda repository\n",
    "\n",
    "It installes keras, tensorflow and CUDA driver.\n",
    "\n",
    "If you will have an error with installaton, you can try at first to install tensorflow and then keras.\n",
    "\n",
    "conda install -c anaconda tensorflow\n",
    "\n",
    "\n",
    "# Keras\n",
    "\n",
    "\n",
    "Sequential model: https://keras.io/guides/sequential_model/\n",
    "\n",
    "\n",
    "Dense layer: https://keras.io/api/layers/core_layers/dense/\n",
    "\n",
    "input_dim: Integer. Size of the vocabulary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# download dataset\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset.keys()) # just checking key names, because I forgot them\n",
    "\n",
    "print(iris_dataset['target_names']) # just checking the target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# target data\n",
    "Y_iris = iris_dataset['target']\n",
    "\n",
    "# the structure of target data is 1 dimensional array\n",
    "print(Y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "X_iris = iris_dataset['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(X_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Create model layers\n",
    "\n",
    "# use Dense layer; add 10 units in hidden layer\n",
    "# This layer include also input layer, so specify how many inputs for input layer (input_dim=4)\n",
    "# specify which activation function you want to use (activation='relu')\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "\n",
    "# you can add more hidden layers here. You do not have to specify the number of units, i.e.:\n",
    "# model.add(Dense(activation='relu'))\n",
    "\n",
    "# add output layer with 3 outputs and softmax function\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Complile model\n",
    "\n",
    "# specify loss function, optimizer and metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The structure of target data is 1-d array containing 0, 1, and 2.\n",
    "# 'setosa'=0 'versicolor'=1 'virginica'=2\n",
    "\n",
    "# we have 3 categories/classes, so we have 3 Neuron Net outputs.\n",
    "# It means that every output instance must be able to represent 3 options.\n",
    "# another words, every instance must be represented as an array of 3 element ['setosa', 'versicolor', 'virginica'] in which only one element is true.\n",
    "# The output is either true or false. We will use numbers to describe it false=0, true=1\n",
    "# 'setosa'=[1, 0, 0] 'versicolor'=[0, 1, 0] 'virginica'=[0, 0, 1]\n",
    "\n",
    "# We have to transform 1-d array to 2-d array. This 2-d array is a categorical array, because it represents categories.\n",
    "# Keras has a function that makes such transformation.\n",
    "\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "Y_iris_categorical = to_categorical(Y_iris)\n",
    "\n",
    "print(Y_iris_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 800us/step - loss: 3.0131 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e762dd760>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets train our model\n",
    "\n",
    "model.fit(X_iris, Y_iris_categorical)\n",
    "\n",
    "# You should to see your result below. My was: 3ms/step - loss: 1.8627 - accuracy: 0.3333\n",
    "# training run only once\n",
    "# the result is:\n",
    "# loss: 1.8627\n",
    "# accuracy: 0.333\n",
    "\n",
    "# We have 3 categories. Probability of guessing the right answer is 0.333. So accuracy is the same as probability of 'guessing'\n",
    "# What was done by program is that program randomly put weights and biases to Neuron Nets.\n",
    "\n",
    "# In order to improve result we need to run it more times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 2.7799 - accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 2.5634 - accuracy: 0.3333\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 2.3478 - accuracy: 0.3333\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 2.1519 - accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 1.9576 - accuracy: 0.3333\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 1.7894 - accuracy: 0.3333\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 1.6383 - accuracy: 0.3333\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 793us/step - loss: 1.4864 - accuracy: 0.3333\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 1.3612 - accuracy: 0.3333\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 1.2518 - accuracy: 0.3333\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 997us/step - loss: 1.1558 - accuracy: 0.3333\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 999us/step - loss: 1.0775 - accuracy: 0.3333\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 593us/step - loss: 1.0143 - accuracy: 0.3333\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.9590 - accuracy: 0.3333\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.3467\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.8900 - accuracy: 0.4067\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8690 - accuracy: 0.4667\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.8529 - accuracy: 0.6333\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.8377 - accuracy: 0.7600\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.8252 - accuracy: 0.8600\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 794us/step - loss: 0.8127 - accuracy: 0.9067\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.8015 - accuracy: 0.9267\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.7910 - accuracy: 0.9267\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.7799 - accuracy: 0.9333\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7690 - accuracy: 0.9333\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7592 - accuracy: 0.9400\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.7493 - accuracy: 0.9400\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.7394 - accuracy: 0.9400\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 993us/step - loss: 0.7302 - accuracy: 0.9400\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.9400\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.9400\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.7036 - accuracy: 0.9400\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.6947 - accuracy: 0.9400\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.6866 - accuracy: 0.9400\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.9467\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.6702 - accuracy: 0.9467\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.6626 - accuracy: 0.9467\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.6548 - accuracy: 0.9467\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.6473 - accuracy: 0.9467\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.6403 - accuracy: 0.9467\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.6331 - accuracy: 0.9467\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.6258 - accuracy: 0.9467\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.6192 - accuracy: 0.9467\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.6125 - accuracy: 0.9467\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.6060 - accuracy: 0.9467\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.5995 - accuracy: 0.9467\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.9467\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.9467\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.9467\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.5758 - accuracy: 0.9467\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.5698 - accuracy: 0.9533\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.5643 - accuracy: 0.9533\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.5587 - accuracy: 0.9533\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.5538 - accuracy: 0.9533\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.5482 - accuracy: 0.9533\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.9533\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.5383 - accuracy: 0.9533\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.9533\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.5284 - accuracy: 0.9533\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.5238 - accuracy: 0.9533\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.5193 - accuracy: 0.9533\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.5149 - accuracy: 0.9533\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.5103 - accuracy: 0.9533\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.5060 - accuracy: 0.9533\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.5018 - accuracy: 0.9533\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4976 - accuracy: 0.9533\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4936 - accuracy: 0.9533\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.4896 - accuracy: 0.9533\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.4857 - accuracy: 0.9600\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.4818 - accuracy: 0.9600\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.4781 - accuracy: 0.9600\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4744 - accuracy: 0.9533\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.4706 - accuracy: 0.9600\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4671 - accuracy: 0.9600\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.9667\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.4601 - accuracy: 0.9667\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4567 - accuracy: 0.9667\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4532 - accuracy: 0.9667\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.9667\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.4467 - accuracy: 0.9600\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.4437 - accuracy: 0.9667\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4405 - accuracy: 0.9667\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 800us/step - loss: 0.4373 - accuracy: 0.9667\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.4343 - accuracy: 0.9667\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4314 - accuracy: 0.9667\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4284 - accuracy: 0.9667\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.9667\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.9667\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.4198 - accuracy: 0.9667\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4170 - accuracy: 0.9667\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.9667\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4120 - accuracy: 0.9667\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.4091 - accuracy: 0.9667\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.4063 - accuracy: 0.9667\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.9667\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.4015 - accuracy: 0.9667\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3988 - accuracy: 0.9667\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.3960 - accuracy: 0.9667\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.3935 - accuracy: 0.9667\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3912 - accuracy: 0.9600\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3889 - accuracy: 0.9600\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.9600\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3840 - accuracy: 0.9600\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3819 - accuracy: 0.9600\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.3798 - accuracy: 0.9600\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.3772 - accuracy: 0.9667\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.9667\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3727 - accuracy: 0.9600\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3703 - accuracy: 0.9667\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3682 - accuracy: 0.9667\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3660 - accuracy: 0.9667\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.9667\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.3618 - accuracy: 0.9667\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.9667\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3577 - accuracy: 0.9667\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3556 - accuracy: 0.9667\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3535 - accuracy: 0.9667\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3516 - accuracy: 0.9667\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3495 - accuracy: 0.9667\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.3475 - accuracy: 0.9667\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.9667\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.3440 - accuracy: 0.9667\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.9600\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3398 - accuracy: 0.9600\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3380 - accuracy: 0.9667\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3361 - accuracy: 0.9667\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3342 - accuracy: 0.9667\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3326 - accuracy: 0.9667\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3307 - accuracy: 0.9667\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.9667\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3269 - accuracy: 0.9667\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3251 - accuracy: 0.9667\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3235 - accuracy: 0.9667\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.3217 - accuracy: 0.9667\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.9667\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3185 - accuracy: 0.9600\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3166 - accuracy: 0.9667\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.3148 - accuracy: 0.9667\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3131 - accuracy: 0.9667\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.9667\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.3097 - accuracy: 0.9667\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3086 - accuracy: 0.9733\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.3067 - accuracy: 0.9667\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.9667\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.3032 - accuracy: 0.9667\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3017 - accuracy: 0.9667\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.3004 - accuracy: 0.9667\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2984 - accuracy: 0.9667\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2970 - accuracy: 0.9667\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2955 - accuracy: 0.9667\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2942 - accuracy: 0.9667\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2933 - accuracy: 0.9667\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2908 - accuracy: 0.9667\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.9600\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.2875 - accuracy: 0.9667\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2860 - accuracy: 0.9667\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2850 - accuracy: 0.9733\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.9667\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2824 - accuracy: 0.9667\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2804 - accuracy: 0.9667\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2790 - accuracy: 0.9667\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2778 - accuracy: 0.9667\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.2762 - accuracy: 0.9667\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2750 - accuracy: 0.9667\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2734 - accuracy: 0.9667\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2719 - accuracy: 0.9667\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2707 - accuracy: 0.9733\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2695 - accuracy: 0.9667\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2678 - accuracy: 0.9667\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2665 - accuracy: 0.9667\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.9600\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2638 - accuracy: 0.9600\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2626 - accuracy: 0.9667\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2612 - accuracy: 0.9667\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2603 - accuracy: 0.9667\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2586 - accuracy: 0.9667\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2576 - accuracy: 0.9667\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2560 - accuracy: 0.9667\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2548 - accuracy: 0.9667\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2536 - accuracy: 0.9667\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2523 - accuracy: 0.9667\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2510 - accuracy: 0.9667\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2499 - accuracy: 0.9600\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2496 - accuracy: 0.9600\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2472 - accuracy: 0.9667\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2461 - accuracy: 0.9667\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2452 - accuracy: 0.9667\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2439 - accuracy: 0.9667\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2428 - accuracy: 0.9600\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.2414 - accuracy: 0.9600\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2401 - accuracy: 0.9600\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2392 - accuracy: 0.9667\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2380 - accuracy: 0.9667\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2369 - accuracy: 0.9667\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2354 - accuracy: 0.9667\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2344 - accuracy: 0.9600\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.2333 - accuracy: 0.9667\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9667\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.2310 - accuracy: 0.9667\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2299 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e780b3550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify 'epoch'. Epoch means generation. But you can think about it as iteration. So specify the number of iterations\n",
    "\n",
    "model.fit(X_iris, Y_iris_categorical, epochs=200)\n",
    "\n",
    "# result:\n",
    "# loss dropped, which is very good. By definition loss fuction should never choose to walk up hill\n",
    "# accuracy improved, which is also very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2288 - accuracy: 0.9667\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2278 - accuracy: 0.9600\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2273 - accuracy: 0.9600\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9600\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9667\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9667\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.2223 - accuracy: 0.9667\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9667\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9667\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.9667\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2181 - accuracy: 0.9667\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2171 - accuracy: 0.9600\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2160 - accuracy: 0.9600\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2150 - accuracy: 0.9600\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2146 - accuracy: 0.9667\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2130 - accuracy: 0.9667\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.9667\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2110 - accuracy: 0.9667\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2101 - accuracy: 0.9600\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.2095 - accuracy: 0.9600\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2082 - accuracy: 0.9667\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9667\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2062 - accuracy: 0.9667\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2054 - accuracy: 0.9600\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2047 - accuracy: 0.9667\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.2034 - accuracy: 0.9600\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2025 - accuracy: 0.9600\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.2018 - accuracy: 0.9600\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.2008 - accuracy: 0.9667\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.9600\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1991 - accuracy: 0.9600\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9600\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1974 - accuracy: 0.9600\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9600\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1957 - accuracy: 0.9667\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1947 - accuracy: 0.9667\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1935 - accuracy: 0.9667\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.9600\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1918 - accuracy: 0.9600\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9600\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1901 - accuracy: 0.9600\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1896 - accuracy: 0.9600\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1888 - accuracy: 0.9600\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.9600\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1870 - accuracy: 0.9667\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9667\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1853 - accuracy: 0.9667\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.9667\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1836 - accuracy: 0.9600\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.9600\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1823 - accuracy: 0.9667\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9600\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.9600\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1798 - accuracy: 0.9600\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.9600\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.9667\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.9667\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1767 - accuracy: 0.9600\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.9600\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1752 - accuracy: 0.9600\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.9600\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1738 - accuracy: 0.9600\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1731 - accuracy: 0.9600\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1725 - accuracy: 0.9600\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1716 - accuracy: 0.9667\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.1709 - accuracy: 0.9667\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1703 - accuracy: 0.9667\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9600\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1689 - accuracy: 0.9600\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.1683 - accuracy: 0.9600\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1678 - accuracy: 0.9667\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1672 - accuracy: 0.9600\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1662 - accuracy: 0.9667\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1656 - accuracy: 0.9600\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1649 - accuracy: 0.9600\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1642 - accuracy: 0.9600\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1637 - accuracy: 0.9600\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1646 - accuracy: 0.9667\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1625 - accuracy: 0.9733\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1619 - accuracy: 0.9600\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1611 - accuracy: 0.9667\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9667\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1597 - accuracy: 0.9667\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1593 - accuracy: 0.9667\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1591 - accuracy: 0.9667\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1580 - accuracy: 0.9600\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9667\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.1567 - accuracy: 0.9667\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9667\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1563 - accuracy: 0.9667\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1559 - accuracy: 0.9600\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9667\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1541 - accuracy: 0.9667\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9667\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1528 - accuracy: 0.9600\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1521 - accuracy: 0.9667\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1515 - accuracy: 0.9667\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1510 - accuracy: 0.9667\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1504 - accuracy: 0.9667\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1503 - accuracy: 0.9667\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1501 - accuracy: 0.9733\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1493 - accuracy: 0.9667\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1484 - accuracy: 0.9667\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9667\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1475 - accuracy: 0.9667\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9733\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1466 - accuracy: 0.9733\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1454 - accuracy: 0.9733\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1452 - accuracy: 0.9667\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1451 - accuracy: 0.9667\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.9667\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1438 - accuracy: 0.9667\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1431 - accuracy: 0.9667\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1428 - accuracy: 0.9667\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1422 - accuracy: 0.9733\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9667\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1414 - accuracy: 0.9667\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9733\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1405 - accuracy: 0.9733\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1399 - accuracy: 0.9667\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1393 - accuracy: 0.9667\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1389 - accuracy: 0.9667\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1384 - accuracy: 0.9667\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1380 - accuracy: 0.9667\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1376 - accuracy: 0.9733\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1373 - accuracy: 0.9667\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1370 - accuracy: 0.9667\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1362 - accuracy: 0.9667\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1356 - accuracy: 0.9733\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9733\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.1349 - accuracy: 0.9733\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1344 - accuracy: 0.9667\n",
      "Epoch 133/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1340 - accuracy: 0.9733\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1336 - accuracy: 0.9667\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9733\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1328 - accuracy: 0.9733\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1323 - accuracy: 0.9733\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1319 - accuracy: 0.9733\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1319 - accuracy: 0.9733\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9733\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1311 - accuracy: 0.9733\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1303 - accuracy: 0.9733\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1302 - accuracy: 0.9733\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1297 - accuracy: 0.9733\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1292 - accuracy: 0.9733\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1288 - accuracy: 0.9667\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1283 - accuracy: 0.9733\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1281 - accuracy: 0.9667\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1276 - accuracy: 0.9667\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1270 - accuracy: 0.9733\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1267 - accuracy: 0.9733\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9733\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9733\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9733\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1251 - accuracy: 0.9733\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1248 - accuracy: 0.9733\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.1243 - accuracy: 0.9733\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1241 - accuracy: 0.9733\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1241 - accuracy: 0.9733\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1236 - accuracy: 0.9733\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9733\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1227 - accuracy: 0.9733\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1225 - accuracy: 0.9733\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 801us/step - loss: 0.1219 - accuracy: 0.9733\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1220 - accuracy: 0.9733\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9733\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1209 - accuracy: 0.9800\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1210 - accuracy: 0.9733\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1202 - accuracy: 0.9733\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1199 - accuracy: 0.9667\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1195 - accuracy: 0.9733\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.1196 - accuracy: 0.9733\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9733\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1189 - accuracy: 0.9733\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1193 - accuracy: 0.9667\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.1180 - accuracy: 0.9733\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.1177 - accuracy: 0.9733\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.9733\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1171 - accuracy: 0.9733\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1167 - accuracy: 0.9733\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1163 - accuracy: 0.9733\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1173 - accuracy: 0.9667\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9733\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1154 - accuracy: 0.9667\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9733\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1150 - accuracy: 0.9733\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1146 - accuracy: 0.9733\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1141 - accuracy: 0.9733\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1138 - accuracy: 0.9733\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1137 - accuracy: 0.9800\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1133 - accuracy: 0.9733\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1130 - accuracy: 0.9667\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1128 - accuracy: 0.9733\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1125 - accuracy: 0.9733\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.1124 - accuracy: 0.9733\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1117 - accuracy: 0.9733\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9667\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1113 - accuracy: 0.9733\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1111 - accuracy: 0.9733\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1109 - accuracy: 0.9800\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1108 - accuracy: 0.9733\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9733\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1102 - accuracy: 0.9733\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.9733\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.1096 - accuracy: 0.9733\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1098 - accuracy: 0.9733\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 798us/step - loss: 0.1089 - accuracy: 0.9733\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1086 - accuracy: 0.9733\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9733\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9733\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1078 - accuracy: 0.9733\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1075 - accuracy: 0.9733\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1076 - accuracy: 0.9733\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1071 - accuracy: 0.9733\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1068 - accuracy: 0.9733\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.9733\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1065 - accuracy: 0.9733\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.1060 - accuracy: 0.9800\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 797us/step - loss: 0.1060 - accuracy: 0.9733\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1057 - accuracy: 0.9733\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9733\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1054 - accuracy: 0.9733\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1048 - accuracy: 0.9733\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1047 - accuracy: 0.9733\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1043 - accuracy: 0.9800\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9733\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.1040 - accuracy: 0.9733\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1039 - accuracy: 0.9733\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1035 - accuracy: 0.9733\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1031 - accuracy: 0.9733\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9733\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1027 - accuracy: 0.9733\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1029 - accuracy: 0.9733\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1024 - accuracy: 0.9733\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.1022 - accuracy: 0.9733\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1019 - accuracy: 0.9733\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1016 - accuracy: 0.9733\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.9733\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.1011 - accuracy: 0.9733\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1021 - accuracy: 0.9667\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1006 - accuracy: 0.9733\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.1004 - accuracy: 0.9733\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9733\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1005 - accuracy: 0.9733\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9733\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0997 - accuracy: 0.9733\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0995 - accuracy: 0.9733\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0992 - accuracy: 0.9800\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0993 - accuracy: 0.9800\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.9733\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0990 - accuracy: 0.9733\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0986 - accuracy: 0.9733\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0987 - accuracy: 0.9733\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0987 - accuracy: 0.9733\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0978 - accuracy: 0.9733\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0976 - accuracy: 0.9733\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.9800\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0974 - accuracy: 0.9800\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9733\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0970 - accuracy: 0.9800\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0967 - accuracy: 0.9733\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0965 - accuracy: 0.9733\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0969 - accuracy: 0.9733\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0959 - accuracy: 0.9733\n",
      "Epoch 265/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9733\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0958 - accuracy: 0.9733\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0957 - accuracy: 0.9733\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0953 - accuracy: 0.9733\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0960 - accuracy: 0.9733\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.9733\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0954 - accuracy: 0.9800\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0949 - accuracy: 0.9733\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0949 - accuracy: 0.9733\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0945 - accuracy: 0.9733\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0944 - accuracy: 0.9800\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0941 - accuracy: 0.9733\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9733\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0937 - accuracy: 0.9733\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0937 - accuracy: 0.9733\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0934 - accuracy: 0.9733\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0930 - accuracy: 0.9733\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0932 - accuracy: 0.9733\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0928 - accuracy: 0.9733\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0926 - accuracy: 0.9733\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0929 - accuracy: 0.9733\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0929 - accuracy: 0.9733\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0921 - accuracy: 0.9800\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0928 - accuracy: 0.9733\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0916 - accuracy: 0.9800\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0917 - accuracy: 0.9733\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0923 - accuracy: 0.9733\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0911 - accuracy: 0.9733\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0914 - accuracy: 0.9733\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9733\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0910 - accuracy: 0.9733\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0906 - accuracy: 0.9733\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0904 - accuracy: 0.9733\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0903 - accuracy: 0.9733\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0903 - accuracy: 0.9733\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0901 - accuracy: 0.9733\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0902 - accuracy: 0.9733\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0897 - accuracy: 0.9733\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0895 - accuracy: 0.9800\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0896 - accuracy: 0.9800\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0899 - accuracy: 0.9733\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.9800\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0893 - accuracy: 0.9800\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0892 - accuracy: 0.9800\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0888 - accuracy: 0.9800\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0892 - accuracy: 0.9733\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0886 - accuracy: 0.9800\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0883 - accuracy: 0.9733\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0886 - accuracy: 0.9733\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0879 - accuracy: 0.9733\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0879 - accuracy: 0.9733\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0875 - accuracy: 0.9800\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9733\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0880 - accuracy: 0.9733\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0877 - accuracy: 0.9733\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0871 - accuracy: 0.9733\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0869 - accuracy: 0.9733\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0869 - accuracy: 0.9800\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0867 - accuracy: 0.9800\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.0872 - accuracy: 0.9800\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0864 - accuracy: 0.9733\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 600us/step - loss: 0.0865 - accuracy: 0.9733\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0866 - accuracy: 0.9733\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0862 - accuracy: 0.9733\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0861 - accuracy: 0.9733\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0859 - accuracy: 0.9733\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0859 - accuracy: 0.9800\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0856 - accuracy: 0.9733\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0855 - accuracy: 0.9733\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0852 - accuracy: 0.9733\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0854 - accuracy: 0.9733\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0852 - accuracy: 0.9733\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0851 - accuracy: 0.9733\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0847 - accuracy: 0.9733\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0848 - accuracy: 0.9800\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0845 - accuracy: 0.9800\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0846 - accuracy: 0.9800\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0852 - accuracy: 0.9733\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0845 - accuracy: 0.9733\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0840 - accuracy: 0.9733\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0841 - accuracy: 0.9800\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0841 - accuracy: 0.9800\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0837 - accuracy: 0.9800\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0836 - accuracy: 0.9800\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0838 - accuracy: 0.9800\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0836 - accuracy: 0.9800\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.0833 - accuracy: 0.9800\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0836 - accuracy: 0.9800\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0834 - accuracy: 0.9733\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0829 - accuracy: 0.9800\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0829 - accuracy: 0.9733\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0831 - accuracy: 0.9733\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0827 - accuracy: 0.9733\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0823 - accuracy: 0.9733\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0822 - accuracy: 0.9800\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0827 - accuracy: 0.9733\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0824 - accuracy: 0.9733\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0822 - accuracy: 0.9733\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 802us/step - loss: 0.0821 - accuracy: 0.9800\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0815 - accuracy: 0.9800\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0816 - accuracy: 0.9733\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0818 - accuracy: 0.9733\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0818 - accuracy: 0.9733\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.0813 - accuracy: 0.9733\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.0812 - accuracy: 0.9800\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0820 - accuracy: 0.9733\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0820 - accuracy: 0.9800\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0811 - accuracy: 0.9800\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0811 - accuracy: 0.9800\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0808 - accuracy: 0.9800\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0821 - accuracy: 0.9800\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0811 - accuracy: 0.9733\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0804 - accuracy: 0.9800\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0806 - accuracy: 0.9800\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0803 - accuracy: 0.9800\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0806 - accuracy: 0.9733\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0800 - accuracy: 0.9733\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0801 - accuracy: 0.9733\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0798 - accuracy: 0.9733\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0799 - accuracy: 0.9800\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0798 - accuracy: 0.9733\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.0803 - accuracy: 0.9800\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0795 - accuracy: 0.9733\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0793 - accuracy: 0.9800\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0792 - accuracy: 0.9800\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0792 - accuracy: 0.9800\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0797 - accuracy: 0.9733\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0793 - accuracy: 0.9800\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0792 - accuracy: 0.9800\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0788 - accuracy: 0.9800\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0789 - accuracy: 0.9733\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0788 - accuracy: 0.9733\n",
      "Epoch 397/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0794 - accuracy: 0.9800\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0784 - accuracy: 0.9800\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0787 - accuracy: 0.9800\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0781 - accuracy: 0.9800\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0783 - accuracy: 0.9733\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0783 - accuracy: 0.9733\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0780 - accuracy: 0.9733\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0779 - accuracy: 0.9733\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0778 - accuracy: 0.9733\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0776 - accuracy: 0.9800\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 600us/step - loss: 0.0777 - accuracy: 0.9800\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0776 - accuracy: 0.9733\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0779 - accuracy: 0.9800\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0784 - accuracy: 0.9733\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0774 - accuracy: 0.9800\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0778 - accuracy: 0.9733\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.0774 - accuracy: 0.9733\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0773 - accuracy: 0.9733\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0768 - accuracy: 0.9800\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0770 - accuracy: 0.9800\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0771 - accuracy: 0.9800\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0770 - accuracy: 0.9800\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0767 - accuracy: 0.9733\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0766 - accuracy: 0.9800\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0766 - accuracy: 0.9733\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0765 - accuracy: 0.9733\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0763 - accuracy: 0.9800\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0765 - accuracy: 0.9800\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0763 - accuracy: 0.9800\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0759 - accuracy: 0.9800\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0762 - accuracy: 0.9733\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0758 - accuracy: 0.9800\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0758 - accuracy: 0.9800\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0762 - accuracy: 0.9800\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0760 - accuracy: 0.9800\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0767 - accuracy: 0.9800\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0755 - accuracy: 0.9800\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0755 - accuracy: 0.9800\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0756 - accuracy: 0.9733\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0751 - accuracy: 0.9733\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0751 - accuracy: 0.9800\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0751 - accuracy: 0.9800\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0758 - accuracy: 0.9800\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0748 - accuracy: 0.9800\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0748 - accuracy: 0.9800\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0759 - accuracy: 0.9733\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0750 - accuracy: 0.9800\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0749 - accuracy: 0.9800\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0748 - accuracy: 0.9733\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0752 - accuracy: 0.9733\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0749 - accuracy: 0.9800\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.0745 - accuracy: 0.9800\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0745 - accuracy: 0.9800\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0742 - accuracy: 0.9733\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0740 - accuracy: 0.9800\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0739 - accuracy: 0.9800\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0743 - accuracy: 0.9800\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0743 - accuracy: 0.9733\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0737 - accuracy: 0.9800\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0742 - accuracy: 0.9800\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0734 - accuracy: 0.9800\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 601us/step - loss: 0.0744 - accuracy: 0.9733\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0748 - accuracy: 0.9733\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0734 - accuracy: 0.9800\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0734 - accuracy: 0.9800\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0735 - accuracy: 0.9800\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0732 - accuracy: 0.9800\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 602us/step - loss: 0.0731 - accuracy: 0.9800\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0732 - accuracy: 0.9800\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0732 - accuracy: 0.9800\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0729 - accuracy: 0.9800\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0731 - accuracy: 0.9800\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0731 - accuracy: 0.9800\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0731 - accuracy: 0.9800\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0727 - accuracy: 0.9800\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0727 - accuracy: 0.9800\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.9800\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0725 - accuracy: 0.9800\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0728 - accuracy: 0.9800\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0726 - accuracy: 0.9800\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0726 - accuracy: 0.9800\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0722 - accuracy: 0.9800\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0727 - accuracy: 0.9733\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0720 - accuracy: 0.9800\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0720 - accuracy: 0.9800\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0719 - accuracy: 0.9800\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0718 - accuracy: 0.9800\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0717 - accuracy: 0.9800\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0718 - accuracy: 0.9800\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0716 - accuracy: 0.9800\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0717 - accuracy: 0.9800\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 800us/step - loss: 0.0715 - accuracy: 0.9800\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0714 - accuracy: 0.9800\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.0714 - accuracy: 0.9800\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0716 - accuracy: 0.9800\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0713 - accuracy: 0.9800\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0713 - accuracy: 0.9800\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0715 - accuracy: 0.9733\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 400us/step - loss: 0.0713 - accuracy: 0.9733\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0710 - accuracy: 0.9800\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0709 - accuracy: 0.9800\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0709 - accuracy: 0.9800\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0710 - accuracy: 0.9800\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0714 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e7812d730>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets train it more\n",
    "# You can notice that this time the result of first iteration gave very good accuracy (0.91 in my case)\n",
    "# It is because the previous model is in memory, so actually it does not start from the beginning but uses the previously traind model\n",
    "\n",
    "model.fit(X_iris, Y_iris_categorical, epochs=500)\n",
    "\n",
    "# loss is still dropping\n",
    "# accuracy is going up and down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - overfitting\n",
    "\n",
    "There is possibility that the model is overfitted.\n",
    "\n",
    "It could have learned training data (and only this set of data) so well, that it is not doing any useful job.\n",
    "\n",
    "For that reason we can not use the same dataset for testing our model.\n",
    "\n",
    "\n",
    "The way of avoiding overfitting is to choose the correct number of epoch.\n",
    "Train model as many times as necessary, but no more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset\n",
    "iris_dataset = load_iris()\n",
    "\n",
    "X = iris_dataset['data']\n",
    "Y = iris_dataset['target']\n",
    "\n",
    "Y_categorical = to_categorical(Y)\n",
    "\n",
    "# This time we will split our dataset into two groups: training data and test data.\n",
    "# we should to choose the random data to our test data.\n",
    "# sklearn model_selection module has function train_test_split() that can do this. \n",
    "# By default it splits in proportion 75/25, but classical proportion is 70/30.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_categorical, test_size=0.3) # test_size=0.3 - proportion 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(10, input_dim = 4, activation='relu'))\n",
    "model_2.add(Dense(3, activation='softmax'))\n",
    "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 1.4093 - accuracy: 0.3438WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6026 - accuracy: 0.3048 - val_loss: 1.4514 - val_accuracy: 0.4000\n",
      "Epoch 2/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.4828 - accuracy: 0.3048 - val_loss: 1.3493 - val_accuracy: 0.4000\n",
      "Epoch 3/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.3668 - accuracy: 0.3048 - val_loss: 1.2586 - val_accuracy: 0.4000\n",
      "Epoch 4/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.2651 - accuracy: 0.3143 - val_loss: 1.1781 - val_accuracy: 0.4667\n",
      "Epoch 5/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1729 - accuracy: 0.3619 - val_loss: 1.1087 - val_accuracy: 0.6222\n",
      "Epoch 6/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1013 - accuracy: 0.5429 - val_loss: 1.0494 - val_accuracy: 0.6667\n",
      "Epoch 7/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.0351 - accuracy: 0.6571 - val_loss: 1.0044 - val_accuracy: 0.6667\n",
      "Epoch 8/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9823 - accuracy: 0.6571 - val_loss: 0.9718 - val_accuracy: 0.6667\n",
      "Epoch 9/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9444 - accuracy: 0.6571 - val_loss: 0.9456 - val_accuracy: 0.6222\n",
      "Epoch 10/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.9090 - accuracy: 0.6857 - val_loss: 0.9272 - val_accuracy: 0.5778\n",
      "Epoch 11/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8867 - accuracy: 0.6381 - val_loss: 0.9142 - val_accuracy: 0.6222\n",
      "Epoch 12/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8674 - accuracy: 0.6667 - val_loss: 0.9040 - val_accuracy: 0.5778\n",
      "Epoch 13/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8513 - accuracy: 0.7524 - val_loss: 0.8956 - val_accuracy: 0.6000\n",
      "Epoch 14/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8411 - accuracy: 0.7333 - val_loss: 0.8885 - val_accuracy: 0.6000\n",
      "Epoch 15/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8322 - accuracy: 0.7333 - val_loss: 0.8823 - val_accuracy: 0.6000\n",
      "Epoch 16/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8234 - accuracy: 0.7048 - val_loss: 0.8764 - val_accuracy: 0.6222\n",
      "Epoch 17/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8164 - accuracy: 0.6952 - val_loss: 0.8700 - val_accuracy: 0.6222\n",
      "Epoch 18/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8094 - accuracy: 0.6952 - val_loss: 0.8630 - val_accuracy: 0.6222\n",
      "Epoch 19/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8022 - accuracy: 0.6952 - val_loss: 0.8554 - val_accuracy: 0.6222\n",
      "Epoch 20/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7947 - accuracy: 0.6952 - val_loss: 0.8471 - val_accuracy: 0.6222\n",
      "Epoch 21/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7870 - accuracy: 0.6952 - val_loss: 0.8390 - val_accuracy: 0.6222\n",
      "Epoch 22/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7794 - accuracy: 0.6952 - val_loss: 0.8311 - val_accuracy: 0.6222\n",
      "Epoch 23/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7726 - accuracy: 0.7048 - val_loss: 0.8224 - val_accuracy: 0.6222\n",
      "Epoch 24/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.7048 - val_loss: 0.8158 - val_accuracy: 0.6222\n",
      "Epoch 25/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7566 - accuracy: 0.7048 - val_loss: 0.8074 - val_accuracy: 0.6222\n",
      "Epoch 26/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7480 - accuracy: 0.7048 - val_loss: 0.8013 - val_accuracy: 0.6222\n",
      "Epoch 27/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7390 - accuracy: 0.6952 - val_loss: 0.7951 - val_accuracy: 0.6222\n",
      "Epoch 28/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.6952 - val_loss: 0.7893 - val_accuracy: 0.6222\n",
      "Epoch 29/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7215 - accuracy: 0.6952 - val_loss: 0.7805 - val_accuracy: 0.6222\n",
      "Epoch 30/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.7116 - accuracy: 0.6952 - val_loss: 0.7724 - val_accuracy: 0.6222\n",
      "Epoch 31/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.6952 - val_loss: 0.7634 - val_accuracy: 0.6222\n",
      "Epoch 32/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.7048 - val_loss: 0.7520 - val_accuracy: 0.6222\n",
      "Epoch 33/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.6839 - accuracy: 0.7238 - val_loss: 0.7410 - val_accuracy: 0.6222\n",
      "Epoch 34/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.7333 - val_loss: 0.7327 - val_accuracy: 0.6222\n",
      "Epoch 35/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.7333 - val_loss: 0.7235 - val_accuracy: 0.6222\n",
      "Epoch 36/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.7333 - val_loss: 0.7153 - val_accuracy: 0.6222\n",
      "Epoch 37/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.7333 - val_loss: 0.7088 - val_accuracy: 0.6222\n",
      "Epoch 38/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.7333 - val_loss: 0.7031 - val_accuracy: 0.6222\n",
      "Epoch 39/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.7333 - val_loss: 0.6958 - val_accuracy: 0.6444\n",
      "Epoch 40/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7429 - val_loss: 0.6892 - val_accuracy: 0.6444\n",
      "Epoch 41/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6262 - accuracy: 0.7524 - val_loss: 0.6837 - val_accuracy: 0.6444\n",
      "Epoch 42/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.7429 - val_loss: 0.6778 - val_accuracy: 0.6444\n",
      "Epoch 43/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.7619 - val_loss: 0.6742 - val_accuracy: 0.6444\n",
      "Epoch 44/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7524 - val_loss: 0.6695 - val_accuracy: 0.6444\n",
      "Epoch 45/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7333 - val_loss: 0.6653 - val_accuracy: 0.6444\n",
      "Epoch 46/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.7429 - val_loss: 0.6601 - val_accuracy: 0.6667\n",
      "Epoch 47/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.7429 - val_loss: 0.6549 - val_accuracy: 0.6667\n",
      "Epoch 48/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5897 - accuracy: 0.7524 - val_loss: 0.6511 - val_accuracy: 0.6667\n",
      "Epoch 49/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5854 - accuracy: 0.7143 - val_loss: 0.6492 - val_accuracy: 0.6000\n",
      "Epoch 50/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.7143 - val_loss: 0.6451 - val_accuracy: 0.6000\n",
      "Epoch 51/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.7143 - val_loss: 0.6397 - val_accuracy: 0.6000\n",
      "Epoch 52/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.7238 - val_loss: 0.6369 - val_accuracy: 0.6000\n",
      "Epoch 53/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.7143 - val_loss: 0.6319 - val_accuracy: 0.6000\n",
      "Epoch 54/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5650 - accuracy: 0.7143 - val_loss: 0.6290 - val_accuracy: 0.6000\n",
      "Epoch 55/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.7238 - val_loss: 0.6223 - val_accuracy: 0.6444\n",
      "Epoch 56/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7524 - val_loss: 0.6173 - val_accuracy: 0.6667\n",
      "Epoch 57/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7619 - val_loss: 0.6139 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.7524 - val_loss: 0.6111 - val_accuracy: 0.6667\n",
      "Epoch 59/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7524 - val_loss: 0.6073 - val_accuracy: 0.6667\n",
      "Epoch 60/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5412 - accuracy: 0.7524 - val_loss: 0.6028 - val_accuracy: 0.6667\n",
      "Epoch 61/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7619 - val_loss: 0.5983 - val_accuracy: 0.7778\n",
      "Epoch 62/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5345 - accuracy: 0.8000 - val_loss: 0.5950 - val_accuracy: 0.7778\n",
      "Epoch 63/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.8000 - val_loss: 0.5913 - val_accuracy: 0.7778\n",
      "Epoch 64/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.8095 - val_loss: 0.5886 - val_accuracy: 0.7778\n",
      "Epoch 65/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.8095 - val_loss: 0.5869 - val_accuracy: 0.6889\n",
      "Epoch 66/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7619 - val_loss: 0.5866 - val_accuracy: 0.6444\n",
      "Epoch 67/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5182 - accuracy: 0.7333 - val_loss: 0.5858 - val_accuracy: 0.6000\n",
      "Epoch 68/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7238 - val_loss: 0.5836 - val_accuracy: 0.6000\n",
      "Epoch 69/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7143 - val_loss: 0.5804 - val_accuracy: 0.6000\n",
      "Epoch 70/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7143 - val_loss: 0.5776 - val_accuracy: 0.6000\n",
      "Epoch 71/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7238 - val_loss: 0.5725 - val_accuracy: 0.6000\n",
      "Epoch 72/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7238 - val_loss: 0.5687 - val_accuracy: 0.6222\n",
      "Epoch 73/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7429 - val_loss: 0.5646 - val_accuracy: 0.6444\n",
      "Epoch 74/800\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.7619 - val_loss: 0.5595 - val_accuracy: 0.7556\n",
      "Epoch 75/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4944 - accuracy: 0.8000 - val_loss: 0.5554 - val_accuracy: 0.8222\n",
      "Epoch 76/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.8286 - val_loss: 0.5516 - val_accuracy: 0.8444\n",
      "Epoch 77/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.8762 - val_loss: 0.5488 - val_accuracy: 0.8444\n",
      "Epoch 78/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.9048 - val_loss: 0.5457 - val_accuracy: 0.8444\n",
      "Epoch 79/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.9143 - val_loss: 0.5437 - val_accuracy: 0.8444\n",
      "Epoch 80/800\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.8762 - val_loss: 0.5422 - val_accuracy: 0.8444\n",
      "Epoch 81/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.8571 - val_loss: 0.5396 - val_accuracy: 0.8444\n",
      "Epoch 82/800\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.8857 - val_loss: 0.5364 - val_accuracy: 0.8444\n",
      "Epoch 83/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.9048 - val_loss: 0.5344 - val_accuracy: 0.8444\n",
      "Epoch 84/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8857 - val_loss: 0.5333 - val_accuracy: 0.8444\n",
      "Epoch 85/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8571 - val_loss: 0.5315 - val_accuracy: 0.8444\n",
      "Epoch 86/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.8381 - val_loss: 0.5288 - val_accuracy: 0.8444\n",
      "Epoch 87/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.8762 - val_loss: 0.5247 - val_accuracy: 0.8444\n",
      "Epoch 88/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.9333 - val_loss: 0.5214 - val_accuracy: 0.8889\n",
      "Epoch 89/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.9333 - val_loss: 0.5180 - val_accuracy: 0.9111\n",
      "Epoch 90/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.9333 - val_loss: 0.5148 - val_accuracy: 0.9111\n",
      "Epoch 91/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.9333 - val_loss: 0.5123 - val_accuracy: 0.9111\n",
      "Epoch 92/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.9238 - val_loss: 0.5109 - val_accuracy: 0.9111\n",
      "Epoch 93/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.9333 - val_loss: 0.5102 - val_accuracy: 0.8889\n",
      "Epoch 94/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.9333 - val_loss: 0.5082 - val_accuracy: 0.8889\n",
      "Epoch 95/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.9238 - val_loss: 0.5068 - val_accuracy: 0.8667\n",
      "Epoch 96/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.9048 - val_loss: 0.5056 - val_accuracy: 0.8444\n",
      "Epoch 97/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8857 - val_loss: 0.5054 - val_accuracy: 0.8444\n",
      "Epoch 98/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8667 - val_loss: 0.5058 - val_accuracy: 0.7778\n",
      "Epoch 99/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8286 - val_loss: 0.5055 - val_accuracy: 0.7778\n",
      "Epoch 100/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8095 - val_loss: 0.5033 - val_accuracy: 0.7778\n",
      "Epoch 101/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.8476 - val_loss: 0.5003 - val_accuracy: 0.7778\n",
      "Epoch 102/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8571 - val_loss: 0.4965 - val_accuracy: 0.8000\n",
      "Epoch 103/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8762 - val_loss: 0.4932 - val_accuracy: 0.8667\n",
      "Epoch 104/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8952 - val_loss: 0.4888 - val_accuracy: 0.8889\n",
      "Epoch 105/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.9238 - val_loss: 0.4842 - val_accuracy: 0.8889\n",
      "Epoch 106/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.9333 - val_loss: 0.4810 - val_accuracy: 0.9111\n",
      "Epoch 107/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.9429 - val_loss: 0.4778 - val_accuracy: 0.9111\n",
      "Epoch 108/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.9619 - val_loss: 0.4752 - val_accuracy: 0.9111\n",
      "Epoch 109/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4156 - accuracy: 0.9619 - val_loss: 0.4737 - val_accuracy: 0.9111\n",
      "Epoch 110/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.9429 - val_loss: 0.4728 - val_accuracy: 0.8889\n",
      "Epoch 111/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.9429 - val_loss: 0.4696 - val_accuracy: 0.9111\n",
      "Epoch 112/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.9524 - val_loss: 0.4684 - val_accuracy: 0.9111\n",
      "Epoch 113/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.9524 - val_loss: 0.4685 - val_accuracy: 0.8889\n",
      "Epoch 114/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.9238 - val_loss: 0.4701 - val_accuracy: 0.8889\n",
      "Epoch 115/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.9048 - val_loss: 0.4695 - val_accuracy: 0.8667\n",
      "Epoch 116/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8952 - val_loss: 0.4693 - val_accuracy: 0.8667\n",
      "Epoch 117/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8952 - val_loss: 0.4672 - val_accuracy: 0.8667\n",
      "Epoch 118/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8952 - val_loss: 0.4656 - val_accuracy: 0.8667\n",
      "Epoch 119/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8952 - val_loss: 0.4631 - val_accuracy: 0.8667\n",
      "Epoch 120/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8952 - val_loss: 0.4596 - val_accuracy: 0.8889\n",
      "Epoch 121/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.9238 - val_loss: 0.4547 - val_accuracy: 0.8889\n",
      "Epoch 122/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.9429 - val_loss: 0.4498 - val_accuracy: 0.9333\n",
      "Epoch 123/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.9714 - val_loss: 0.4458 - val_accuracy: 0.9333\n",
      "Epoch 124/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.9619 - val_loss: 0.4434 - val_accuracy: 0.9333\n",
      "Epoch 125/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3869 - accuracy: 0.9619 - val_loss: 0.4415 - val_accuracy: 0.9333\n",
      "Epoch 126/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.9619 - val_loss: 0.4400 - val_accuracy: 0.9333\n",
      "Epoch 127/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.9619 - val_loss: 0.4385 - val_accuracy: 0.9333\n",
      "Epoch 128/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.9714 - val_loss: 0.4375 - val_accuracy: 0.9333\n",
      "Epoch 129/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.9714 - val_loss: 0.4352 - val_accuracy: 0.9333\n",
      "Epoch 130/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.9714 - val_loss: 0.4344 - val_accuracy: 0.9111\n",
      "Epoch 131/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.9714 - val_loss: 0.4328 - val_accuracy: 0.9111\n",
      "Epoch 132/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3736 - accuracy: 0.9714 - val_loss: 0.4305 - val_accuracy: 0.9333\n",
      "Epoch 133/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.9714 - val_loss: 0.4273 - val_accuracy: 0.9333\n",
      "Epoch 134/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.9619 - val_loss: 0.4258 - val_accuracy: 0.9333\n",
      "Epoch 135/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3693 - accuracy: 0.9714 - val_loss: 0.4248 - val_accuracy: 0.9333\n",
      "Epoch 136/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3672 - accuracy: 0.9714 - val_loss: 0.4254 - val_accuracy: 0.9111\n",
      "Epoch 137/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.9619 - val_loss: 0.4261 - val_accuracy: 0.9111\n",
      "Epoch 138/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.9524 - val_loss: 0.4271 - val_accuracy: 0.9111\n",
      "Epoch 139/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.9524 - val_loss: 0.4250 - val_accuracy: 0.9111\n",
      "Epoch 140/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.9524 - val_loss: 0.4228 - val_accuracy: 0.9111\n",
      "Epoch 141/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.9619 - val_loss: 0.4189 - val_accuracy: 0.9111\n",
      "Epoch 142/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.9619 - val_loss: 0.4152 - val_accuracy: 0.9111\n",
      "Epoch 143/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 1.00 - 0s 4ms/step - loss: 0.3562 - accuracy: 0.9714 - val_loss: 0.4146 - val_accuracy: 0.9111\n",
      "Epoch 144/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.9714 - val_loss: 0.4137 - val_accuracy: 0.9111\n",
      "Epoch 145/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.9714 - val_loss: 0.4142 - val_accuracy: 0.9111\n",
      "Epoch 146/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.9619 - val_loss: 0.4127 - val_accuracy: 0.9111\n",
      "Epoch 147/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3504 - accuracy: 0.9619 - val_loss: 0.4106 - val_accuracy: 0.9111\n",
      "Epoch 148/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.9714 - val_loss: 0.4089 - val_accuracy: 0.9111\n",
      "Epoch 149/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.9714 - val_loss: 0.4078 - val_accuracy: 0.9111\n",
      "Epoch 150/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.9619 - val_loss: 0.4064 - val_accuracy: 0.9111\n",
      "Epoch 151/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.9714 - val_loss: 0.4041 - val_accuracy: 0.9111\n",
      "Epoch 152/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.9714 - val_loss: 0.4028 - val_accuracy: 0.9111\n",
      "Epoch 153/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.9714 - val_loss: 0.4005 - val_accuracy: 0.9111\n",
      "Epoch 154/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.9714 - val_loss: 0.3978 - val_accuracy: 0.9111\n",
      "Epoch 155/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.9714 - val_loss: 0.3956 - val_accuracy: 0.9111\n",
      "Epoch 156/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.9714 - val_loss: 0.3923 - val_accuracy: 0.9111\n",
      "Epoch 157/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.9810 - val_loss: 0.3906 - val_accuracy: 0.9111\n",
      "Epoch 158/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.9714 - val_loss: 0.3900 - val_accuracy: 0.9111\n",
      "Epoch 159/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.9714 - val_loss: 0.3889 - val_accuracy: 0.9111\n",
      "Epoch 160/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.9714 - val_loss: 0.3886 - val_accuracy: 0.9111\n",
      "Epoch 161/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.9714 - val_loss: 0.3881 - val_accuracy: 0.9111\n",
      "Epoch 162/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.9714 - val_loss: 0.3873 - val_accuracy: 0.9111\n",
      "Epoch 163/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.9714 - val_loss: 0.3849 - val_accuracy: 0.9111\n",
      "Epoch 164/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.9714 - val_loss: 0.3817 - val_accuracy: 0.9111\n",
      "Epoch 165/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 1.00 - 0s 4ms/step - loss: 0.3255 - accuracy: 0.9714 - val_loss: 0.3807 - val_accuracy: 0.9111\n",
      "Epoch 166/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3240 - accuracy: 0.9714 - val_loss: 0.3783 - val_accuracy: 0.9111\n",
      "Epoch 167/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.9810 - val_loss: 0.3774 - val_accuracy: 0.9111\n",
      "Epoch 168/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.9714 - val_loss: 0.3759 - val_accuracy: 0.9111\n",
      "Epoch 169/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.9810 - val_loss: 0.3739 - val_accuracy: 0.9333\n",
      "Epoch 170/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3192 - accuracy: 0.9810 - val_loss: 0.3706 - val_accuracy: 0.9333\n",
      "Epoch 171/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.9810 - val_loss: 0.3683 - val_accuracy: 0.9333\n",
      "Epoch 172/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3168 - accuracy: 0.9905 - val_loss: 0.3677 - val_accuracy: 0.9333\n",
      "Epoch 173/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3158 - accuracy: 0.9810 - val_loss: 0.3684 - val_accuracy: 0.9333\n",
      "Epoch 174/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.9810 - val_loss: 0.3687 - val_accuracy: 0.9111\n",
      "Epoch 175/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.9810 - val_loss: 0.3673 - val_accuracy: 0.9111\n",
      "Epoch 176/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.9810 - val_loss: 0.3637 - val_accuracy: 0.9333\n",
      "Epoch 177/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.9810 - val_loss: 0.3610 - val_accuracy: 0.9333\n",
      "Epoch 178/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.9810 - val_loss: 0.3592 - val_accuracy: 0.9333\n",
      "Epoch 179/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.9810 - val_loss: 0.3595 - val_accuracy: 0.9333\n",
      "Epoch 180/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3060 - accuracy: 0.9810 - val_loss: 0.3586 - val_accuracy: 0.9333\n",
      "Epoch 181/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.9810 - val_loss: 0.3573 - val_accuracy: 0.9333\n",
      "Epoch 182/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3034 - accuracy: 0.9810 - val_loss: 0.3561 - val_accuracy: 0.9333\n",
      "Epoch 183/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3023 - accuracy: 0.9810 - val_loss: 0.3556 - val_accuracy: 0.9333\n",
      "Epoch 184/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3009 - accuracy: 0.9810 - val_loss: 0.3535 - val_accuracy: 0.9333\n",
      "Epoch 185/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.9810 - val_loss: 0.3519 - val_accuracy: 0.9333\n",
      "Epoch 186/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.9810 - val_loss: 0.3521 - val_accuracy: 0.9333\n",
      "Epoch 187/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.9810 - val_loss: 0.3528 - val_accuracy: 0.9333\n",
      "Epoch 188/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.9810 - val_loss: 0.3510 - val_accuracy: 0.9333\n",
      "Epoch 189/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.9810 - val_loss: 0.3488 - val_accuracy: 0.9333\n",
      "Epoch 190/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 0.9810 - val_loss: 0.3454 - val_accuracy: 0.9333\n",
      "Epoch 191/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.9810 - val_loss: 0.3447 - val_accuracy: 0.9333\n",
      "Epoch 192/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.9810 - val_loss: 0.3438 - val_accuracy: 0.9333\n",
      "Epoch 193/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2907 - accuracy: 0.9810 - val_loss: 0.3430 - val_accuracy: 0.9333\n",
      "Epoch 194/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.9810 - val_loss: 0.3395 - val_accuracy: 0.9333\n",
      "Epoch 195/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.9810 - val_loss: 0.3377 - val_accuracy: 0.9333\n",
      "Epoch 196/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2873 - accuracy: 0.9905 - val_loss: 0.3349 - val_accuracy: 0.9333\n",
      "Epoch 197/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2865 - accuracy: 0.9905 - val_loss: 0.3333 - val_accuracy: 0.9333\n",
      "Epoch 198/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.9905 - val_loss: 0.3330 - val_accuracy: 0.9333\n",
      "Epoch 199/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2839 - accuracy: 0.9905 - val_loss: 0.3339 - val_accuracy: 0.9333\n",
      "Epoch 200/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.9810 - val_loss: 0.3345 - val_accuracy: 0.9333\n",
      "Epoch 201/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2826 - accuracy: 0.9810 - val_loss: 0.3369 - val_accuracy: 0.9333\n",
      "Epoch 202/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2811 - accuracy: 0.9810 - val_loss: 0.3355 - val_accuracy: 0.9333\n",
      "Epoch 203/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2794 - accuracy: 0.9810 - val_loss: 0.3321 - val_accuracy: 0.9333\n",
      "Epoch 204/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.9810 - val_loss: 0.3276 - val_accuracy: 0.9333\n",
      "Epoch 205/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.9905 - val_loss: 0.3263 - val_accuracy: 0.9333\n",
      "Epoch 206/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2759 - accuracy: 0.9810 - val_loss: 0.3268 - val_accuracy: 0.9333\n",
      "Epoch 207/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.9810 - val_loss: 0.3266 - val_accuracy: 0.9333\n",
      "Epoch 208/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.9810 - val_loss: 0.3244 - val_accuracy: 0.9333\n",
      "Epoch 209/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.9810 - val_loss: 0.3227 - val_accuracy: 0.9333\n",
      "Epoch 210/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.9810 - val_loss: 0.3224 - val_accuracy: 0.9333\n",
      "Epoch 211/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2709 - accuracy: 0.9810 - val_loss: 0.3229 - val_accuracy: 0.9333\n",
      "Epoch 212/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2698 - accuracy: 0.9810 - val_loss: 0.3218 - val_accuracy: 0.9333\n",
      "Epoch 213/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.9810 - val_loss: 0.3195 - val_accuracy: 0.9333\n",
      "Epoch 214/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.9810 - val_loss: 0.3166 - val_accuracy: 0.9333\n",
      "Epoch 215/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.9810 - val_loss: 0.3149 - val_accuracy: 0.9333\n",
      "Epoch 216/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.9905 - val_loss: 0.3122 - val_accuracy: 0.9333\n",
      "Epoch 217/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.9905 - val_loss: 0.3099 - val_accuracy: 0.9333\n",
      "Epoch 218/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.9905 - val_loss: 0.3080 - val_accuracy: 0.9111\n",
      "Epoch 219/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2643 - accuracy: 0.9810 - val_loss: 0.3065 - val_accuracy: 0.9111\n",
      "Epoch 220/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.9905 - val_loss: 0.3061 - val_accuracy: 0.9333\n",
      "Epoch 221/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.9905 - val_loss: 0.3066 - val_accuracy: 0.9333\n",
      "Epoch 222/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2595 - accuracy: 0.9905 - val_loss: 0.3083 - val_accuracy: 0.9333\n",
      "Epoch 223/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2583 - accuracy: 0.9810 - val_loss: 0.3081 - val_accuracy: 0.9333\n",
      "Epoch 224/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2573 - accuracy: 0.9810 - val_loss: 0.3071 - val_accuracy: 0.9333\n",
      "Epoch 225/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.9810 - val_loss: 0.3058 - val_accuracy: 0.9333\n",
      "Epoch 226/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2555 - accuracy: 0.9905 - val_loss: 0.3018 - val_accuracy: 0.9333\n",
      "Epoch 227/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.9905 - val_loss: 0.2990 - val_accuracy: 0.9333\n",
      "Epoch 228/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.9905 - val_loss: 0.2974 - val_accuracy: 0.9333\n",
      "Epoch 229/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.9905 - val_loss: 0.2968 - val_accuracy: 0.9333\n",
      "Epoch 230/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.9905 - val_loss: 0.2961 - val_accuracy: 0.9333\n",
      "Epoch 231/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.9905 - val_loss: 0.2959 - val_accuracy: 0.9333\n",
      "Epoch 232/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.9905 - val_loss: 0.2951 - val_accuracy: 0.9333\n",
      "Epoch 233/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.9905 - val_loss: 0.2943 - val_accuracy: 0.9333\n",
      "Epoch 234/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2475 - accuracy: 0.9905 - val_loss: 0.2948 - val_accuracy: 0.9333\n",
      "Epoch 235/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.9905 - val_loss: 0.2934 - val_accuracy: 0.9333\n",
      "Epoch 236/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.9905 - val_loss: 0.2912 - val_accuracy: 0.9333\n",
      "Epoch 237/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2449 - accuracy: 0.9905 - val_loss: 0.2895 - val_accuracy: 0.9333\n",
      "Epoch 238/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2437 - accuracy: 0.9905 - val_loss: 0.2897 - val_accuracy: 0.9333\n",
      "Epoch 239/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.9905 - val_loss: 0.2897 - val_accuracy: 0.9333\n",
      "Epoch 240/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2420 - accuracy: 0.9905 - val_loss: 0.2895 - val_accuracy: 0.9333\n",
      "Epoch 241/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9905 - val_loss: 0.2881 - val_accuracy: 0.9333\n",
      "Epoch 242/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.9905 - val_loss: 0.2867 - val_accuracy: 0.9333\n",
      "Epoch 243/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2401 - accuracy: 0.9905 - val_loss: 0.2844 - val_accuracy: 0.9333\n",
      "Epoch 244/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2386 - accuracy: 0.9905 - val_loss: 0.2852 - val_accuracy: 0.9333\n",
      "Epoch 245/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.9905 - val_loss: 0.2841 - val_accuracy: 0.9333\n",
      "Epoch 246/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2365 - accuracy: 0.9905 - val_loss: 0.2818 - val_accuracy: 0.9333\n",
      "Epoch 247/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2361 - accuracy: 0.9905 - val_loss: 0.2795 - val_accuracy: 0.9333\n",
      "Epoch 248/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2351 - accuracy: 0.9905 - val_loss: 0.2789 - val_accuracy: 0.9333\n",
      "Epoch 249/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2344 - accuracy: 0.9905 - val_loss: 0.2774 - val_accuracy: 0.9333\n",
      "Epoch 250/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9905 - val_loss: 0.2775 - val_accuracy: 0.9333\n",
      "Epoch 251/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2323 - accuracy: 0.9905 - val_loss: 0.2760 - val_accuracy: 0.9333\n",
      "Epoch 252/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2315 - accuracy: 0.9905 - val_loss: 0.2750 - val_accuracy: 0.9333\n",
      "Epoch 253/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.9905 - val_loss: 0.2733 - val_accuracy: 0.9333\n",
      "Epoch 254/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.9905 - val_loss: 0.2716 - val_accuracy: 0.9111\n",
      "Epoch 255/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9905 - val_loss: 0.2704 - val_accuracy: 0.9111\n",
      "Epoch 256/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2287 - accuracy: 0.9905 - val_loss: 0.2690 - val_accuracy: 0.9111\n",
      "Epoch 257/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2281 - accuracy: 0.9905 - val_loss: 0.2680 - val_accuracy: 0.9111\n",
      "Epoch 258/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2274 - accuracy: 0.9905 - val_loss: 0.2676 - val_accuracy: 0.9111\n",
      "Epoch 259/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2263 - accuracy: 0.9905 - val_loss: 0.2674 - val_accuracy: 0.9333\n",
      "Epoch 260/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2253 - accuracy: 0.9905 - val_loss: 0.2658 - val_accuracy: 0.9111\n",
      "Epoch 261/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2246 - accuracy: 0.9905 - val_loss: 0.2649 - val_accuracy: 0.9111\n",
      "Epoch 262/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2236 - accuracy: 0.9905 - val_loss: 0.2645 - val_accuracy: 0.9333\n",
      "Epoch 263/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9905 - val_loss: 0.2663 - val_accuracy: 0.9333\n",
      "Epoch 264/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 1.00 - 0s 4ms/step - loss: 0.2214 - accuracy: 0.9905 - val_loss: 0.2666 - val_accuracy: 0.9333\n",
      "Epoch 265/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2203 - accuracy: 0.9905 - val_loss: 0.2656 - val_accuracy: 0.9333\n",
      "Epoch 266/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2200 - accuracy: 0.9905 - val_loss: 0.2642 - val_accuracy: 0.9333\n",
      "Epoch 267/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2189 - accuracy: 0.9905 - val_loss: 0.2658 - val_accuracy: 0.9333\n",
      "Epoch 268/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2186 - accuracy: 0.9810 - val_loss: 0.2669 - val_accuracy: 0.9333\n",
      "Epoch 269/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2179 - accuracy: 0.9810 - val_loss: 0.2660 - val_accuracy: 0.9333\n",
      "Epoch 270/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2171 - accuracy: 0.9810 - val_loss: 0.2671 - val_accuracy: 0.9333\n",
      "Epoch 271/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9810 - val_loss: 0.2655 - val_accuracy: 0.9333\n",
      "Epoch 272/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2156 - accuracy: 0.9810 - val_loss: 0.2634 - val_accuracy: 0.9333\n",
      "Epoch 273/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2144 - accuracy: 0.9810 - val_loss: 0.2604 - val_accuracy: 0.9333\n",
      "Epoch 274/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 1.00 - 0s 4ms/step - loss: 0.2135 - accuracy: 0.9905 - val_loss: 0.2564 - val_accuracy: 0.9333\n",
      "Epoch 275/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2123 - accuracy: 0.9905 - val_loss: 0.2539 - val_accuracy: 0.9333\n",
      "Epoch 276/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9905 - val_loss: 0.2518 - val_accuracy: 0.9111\n",
      "Epoch 277/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2118 - accuracy: 0.9905 - val_loss: 0.2524 - val_accuracy: 0.9333\n",
      "Epoch 278/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9905 - val_loss: 0.2546 - val_accuracy: 0.9333\n",
      "Epoch 279/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2098 - accuracy: 0.9905 - val_loss: 0.2568 - val_accuracy: 0.9333\n",
      "Epoch 280/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2093 - accuracy: 0.9905 - val_loss: 0.2574 - val_accuracy: 0.9333\n",
      "Epoch 281/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2087 - accuracy: 0.9810 - val_loss: 0.2565 - val_accuracy: 0.9333\n",
      "Epoch 282/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2078 - accuracy: 0.9810 - val_loss: 0.2550 - val_accuracy: 0.9333\n",
      "Epoch 283/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2070 - accuracy: 0.9905 - val_loss: 0.2536 - val_accuracy: 0.9333\n",
      "Epoch 284/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2062 - accuracy: 0.9905 - val_loss: 0.2512 - val_accuracy: 0.9333\n",
      "Epoch 285/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2051 - accuracy: 0.9905 - val_loss: 0.2493 - val_accuracy: 0.9333\n",
      "Epoch 286/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2043 - accuracy: 0.9905 - val_loss: 0.2479 - val_accuracy: 0.9333\n",
      "Epoch 287/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2038 - accuracy: 0.9905 - val_loss: 0.2466 - val_accuracy: 0.9333\n",
      "Epoch 288/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.9905 - val_loss: 0.2476 - val_accuracy: 0.9333\n",
      "Epoch 289/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2021 - accuracy: 0.9905 - val_loss: 0.2489 - val_accuracy: 0.9333\n",
      "Epoch 290/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2016 - accuracy: 0.9905 - val_loss: 0.2495 - val_accuracy: 0.9333\n",
      "Epoch 291/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2014 - accuracy: 0.9810 - val_loss: 0.2492 - val_accuracy: 0.9333\n",
      "Epoch 292/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9810 - val_loss: 0.2458 - val_accuracy: 0.9333\n",
      "Epoch 293/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1994 - accuracy: 0.9905 - val_loss: 0.2421 - val_accuracy: 0.9333\n",
      "Epoch 294/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9905 - val_loss: 0.2392 - val_accuracy: 0.9333\n",
      "Epoch 295/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1979 - accuracy: 0.9905 - val_loss: 0.2378 - val_accuracy: 0.9333\n",
      "Epoch 296/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.9905 - val_loss: 0.2376 - val_accuracy: 0.9333\n",
      "Epoch 297/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1963 - accuracy: 0.9905 - val_loss: 0.2380 - val_accuracy: 0.9333\n",
      "Epoch 298/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1957 - accuracy: 0.9905 - val_loss: 0.2389 - val_accuracy: 0.9333\n",
      "Epoch 299/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1949 - accuracy: 0.9905 - val_loss: 0.2384 - val_accuracy: 0.9333\n",
      "Epoch 300/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1944 - accuracy: 0.9905 - val_loss: 0.2353 - val_accuracy: 0.9333\n",
      "Epoch 301/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.9905 - val_loss: 0.2338 - val_accuracy: 0.9333\n",
      "Epoch 302/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1930 - accuracy: 0.9905 - val_loss: 0.2333 - val_accuracy: 0.9333\n",
      "Epoch 303/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9905 - val_loss: 0.2341 - val_accuracy: 0.9333\n",
      "Epoch 304/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.9905 - val_loss: 0.2367 - val_accuracy: 0.9333\n",
      "Epoch 305/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9905 - val_loss: 0.2365 - val_accuracy: 0.9333\n",
      "Epoch 306/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9905 - val_loss: 0.2355 - val_accuracy: 0.9333\n",
      "Epoch 307/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 0.9905 - val_loss: 0.2340 - val_accuracy: 0.9333\n",
      "Epoch 308/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9905 - val_loss: 0.2309 - val_accuracy: 0.9333\n",
      "Epoch 309/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9905 - val_loss: 0.2279 - val_accuracy: 0.9333\n",
      "Epoch 310/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9905 - val_loss: 0.2246 - val_accuracy: 0.9111\n",
      "Epoch 311/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1892 - accuracy: 0.9810 - val_loss: 0.2231 - val_accuracy: 0.9111\n",
      "Epoch 312/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9810 - val_loss: 0.2227 - val_accuracy: 0.9111\n",
      "Epoch 313/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9810 - val_loss: 0.2226 - val_accuracy: 0.9111\n",
      "Epoch 314/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1854 - accuracy: 0.9905 - val_loss: 0.2240 - val_accuracy: 0.9333\n",
      "Epoch 315/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1842 - accuracy: 0.9905 - val_loss: 0.2262 - val_accuracy: 0.9333\n",
      "Epoch 316/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9905 - val_loss: 0.2263 - val_accuracy: 0.9333\n",
      "Epoch 317/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9905 - val_loss: 0.2228 - val_accuracy: 0.9333\n",
      "Epoch 318/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1821 - accuracy: 0.9905 - val_loss: 0.2210 - val_accuracy: 0.9111\n",
      "Epoch 319/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1816 - accuracy: 0.9905 - val_loss: 0.2201 - val_accuracy: 0.9111\n",
      "Epoch 320/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9905 - val_loss: 0.2203 - val_accuracy: 0.9333\n",
      "Epoch 321/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1801 - accuracy: 0.9905 - val_loss: 0.2213 - val_accuracy: 0.9333\n",
      "Epoch 322/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9905 - val_loss: 0.2251 - val_accuracy: 0.9333\n",
      "Epoch 323/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1797 - accuracy: 0.9905 - val_loss: 0.2292 - val_accuracy: 0.9333\n",
      "Epoch 324/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1800 - accuracy: 0.9810 - val_loss: 0.2279 - val_accuracy: 0.9333\n",
      "Epoch 325/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1788 - accuracy: 0.9905 - val_loss: 0.2239 - val_accuracy: 0.9333\n",
      "Epoch 326/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1776 - accuracy: 0.9905 - val_loss: 0.2216 - val_accuracy: 0.9333\n",
      "Epoch 327/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.9905 - val_loss: 0.2186 - val_accuracy: 0.9333\n",
      "Epoch 328/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9905 - val_loss: 0.2161 - val_accuracy: 0.9333\n",
      "Epoch 329/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1755 - accuracy: 0.9905 - val_loss: 0.2150 - val_accuracy: 0.9333\n",
      "Epoch 330/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9905 - val_loss: 0.2140 - val_accuracy: 0.9333\n",
      "Epoch 331/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9905 - val_loss: 0.2133 - val_accuracy: 0.9333\n",
      "Epoch 332/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9905 - val_loss: 0.2133 - val_accuracy: 0.9333\n",
      "Epoch 333/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1734 - accuracy: 0.9905 - val_loss: 0.2119 - val_accuracy: 0.9111\n",
      "Epoch 334/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1726 - accuracy: 0.9905 - val_loss: 0.2118 - val_accuracy: 0.9333\n",
      "Epoch 335/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9905 - val_loss: 0.2122 - val_accuracy: 0.9333\n",
      "Epoch 336/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.9905 - val_loss: 0.2142 - val_accuracy: 0.9333\n",
      "Epoch 337/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9905 - val_loss: 0.2184 - val_accuracy: 0.9333\n",
      "Epoch 338/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9905 - val_loss: 0.2215 - val_accuracy: 0.9333\n",
      "Epoch 339/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9810 - val_loss: 0.2184 - val_accuracy: 0.9333\n",
      "Epoch 340/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1694 - accuracy: 0.9905 - val_loss: 0.2129 - val_accuracy: 0.9333\n",
      "Epoch 341/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1689 - accuracy: 0.9905 - val_loss: 0.2081 - val_accuracy: 0.9333\n",
      "Epoch 342/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1682 - accuracy: 0.9905 - val_loss: 0.2065 - val_accuracy: 0.9111\n",
      "Epoch 343/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1679 - accuracy: 0.9905 - val_loss: 0.2067 - val_accuracy: 0.9333\n",
      "Epoch 344/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9905 - val_loss: 0.2069 - val_accuracy: 0.9333\n",
      "Epoch 345/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1674 - accuracy: 0.9905 - val_loss: 0.2104 - val_accuracy: 0.9333\n",
      "Epoch 346/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1661 - accuracy: 0.9905 - val_loss: 0.2116 - val_accuracy: 0.9333\n",
      "Epoch 347/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9905 - val_loss: 0.2128 - val_accuracy: 0.9333\n",
      "Epoch 348/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1658 - accuracy: 0.9905 - val_loss: 0.2122 - val_accuracy: 0.9333\n",
      "Epoch 349/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1650 - accuracy: 0.9905 - val_loss: 0.2099 - val_accuracy: 0.9333\n",
      "Epoch 350/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9905 - val_loss: 0.2055 - val_accuracy: 0.9333\n",
      "Epoch 351/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.9905 - val_loss: 0.2034 - val_accuracy: 0.9333\n",
      "Epoch 352/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1631 - accuracy: 0.9905 - val_loss: 0.2003 - val_accuracy: 0.9111\n",
      "Epoch 353/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1627 - accuracy: 0.9905 - val_loss: 0.1990 - val_accuracy: 0.9111\n",
      "Epoch 354/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1628 - accuracy: 0.9905 - val_loss: 0.1990 - val_accuracy: 0.9111\n",
      "Epoch 355/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9905 - val_loss: 0.1978 - val_accuracy: 0.9111\n",
      "Epoch 356/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1613 - accuracy: 0.9905 - val_loss: 0.1991 - val_accuracy: 0.9111\n",
      "Epoch 357/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9905 - val_loss: 0.2029 - val_accuracy: 0.9333\n",
      "Epoch 358/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1593 - accuracy: 0.9905 - val_loss: 0.2068 - val_accuracy: 0.9333\n",
      "Epoch 359/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1615 - accuracy: 0.9810 - val_loss: 0.2122 - val_accuracy: 0.9333\n",
      "Epoch 360/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1614 - accuracy: 0.9714 - val_loss: 0.2113 - val_accuracy: 0.9333\n",
      "Epoch 361/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1598 - accuracy: 0.9905 - val_loss: 0.2038 - val_accuracy: 0.9333\n",
      "Epoch 362/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1585 - accuracy: 0.9905 - val_loss: 0.1976 - val_accuracy: 0.9333\n",
      "Epoch 363/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.9905 - val_loss: 0.1953 - val_accuracy: 0.9111\n",
      "Epoch 364/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1572 - accuracy: 0.9905 - val_loss: 0.1941 - val_accuracy: 0.9111\n",
      "Epoch 365/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1563 - accuracy: 0.9905 - val_loss: 0.1959 - val_accuracy: 0.9333\n",
      "Epoch 366/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9905 - val_loss: 0.2015 - val_accuracy: 0.9333\n",
      "Epoch 367/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9905 - val_loss: 0.2088 - val_accuracy: 0.9333\n",
      "Epoch 368/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9714 - val_loss: 0.2083 - val_accuracy: 0.9333\n",
      "Epoch 369/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1576 - accuracy: 0.9714 - val_loss: 0.2014 - val_accuracy: 0.9333\n",
      "Epoch 370/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9905 - val_loss: 0.1979 - val_accuracy: 0.9333\n",
      "Epoch 371/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1538 - accuracy: 0.9905 - val_loss: 0.1935 - val_accuracy: 0.9333\n",
      "Epoch 372/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1528 - accuracy: 0.9905 - val_loss: 0.1923 - val_accuracy: 0.9333\n",
      "Epoch 373/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1525 - accuracy: 0.9905 - val_loss: 0.1919 - val_accuracy: 0.9333\n",
      "Epoch 374/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9905 - val_loss: 0.1903 - val_accuracy: 0.9111\n",
      "Epoch 375/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1517 - accuracy: 0.9905 - val_loss: 0.1911 - val_accuracy: 0.9333\n",
      "Epoch 376/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1511 - accuracy: 0.9905 - val_loss: 0.1911 - val_accuracy: 0.9333\n",
      "Epoch 377/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9905 - val_loss: 0.1917 - val_accuracy: 0.9333\n",
      "Epoch 378/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9905 - val_loss: 0.1923 - val_accuracy: 0.9333\n",
      "Epoch 379/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9905 - val_loss: 0.1933 - val_accuracy: 0.9333\n",
      "Epoch 380/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1492 - accuracy: 0.9905 - val_loss: 0.1913 - val_accuracy: 0.9333\n",
      "Epoch 381/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1489 - accuracy: 0.9905 - val_loss: 0.1898 - val_accuracy: 0.9333\n",
      "Epoch 382/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1482 - accuracy: 0.9905 - val_loss: 0.1909 - val_accuracy: 0.9333\n",
      "Epoch 383/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1481 - accuracy: 0.9905 - val_loss: 0.1914 - val_accuracy: 0.9333\n",
      "Epoch 384/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9905 - val_loss: 0.1878 - val_accuracy: 0.9333\n",
      "Epoch 385/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9905 - val_loss: 0.1845 - val_accuracy: 0.9111\n",
      "Epoch 386/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.9905 - val_loss: 0.1826 - val_accuracy: 0.9111\n",
      "Epoch 387/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1469 - accuracy: 0.9810 - val_loss: 0.1824 - val_accuracy: 0.9111\n",
      "Epoch 388/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9905 - val_loss: 0.1824 - val_accuracy: 0.9111\n",
      "Epoch 389/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1454 - accuracy: 0.9905 - val_loss: 0.1851 - val_accuracy: 0.9333\n",
      "Epoch 390/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1443 - accuracy: 0.9905 - val_loss: 0.1871 - val_accuracy: 0.9333\n",
      "Epoch 391/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1448 - accuracy: 0.9905 - val_loss: 0.1897 - val_accuracy: 0.9333\n",
      "Epoch 392/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1441 - accuracy: 0.9905 - val_loss: 0.1894 - val_accuracy: 0.9333\n",
      "Epoch 393/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1437 - accuracy: 0.9905 - val_loss: 0.1916 - val_accuracy: 0.9333\n",
      "Epoch 394/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9905 - val_loss: 0.1921 - val_accuracy: 0.9333\n",
      "Epoch 395/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9905 - val_loss: 0.1913 - val_accuracy: 0.9333\n",
      "Epoch 396/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.9905 - val_loss: 0.1873 - val_accuracy: 0.9333\n",
      "Epoch 397/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9905 - val_loss: 0.1829 - val_accuracy: 0.9333\n",
      "Epoch 398/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9905 - val_loss: 0.1810 - val_accuracy: 0.9333\n",
      "Epoch 399/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1408 - accuracy: 0.9905 - val_loss: 0.1796 - val_accuracy: 0.9111\n",
      "Epoch 400/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9905 - val_loss: 0.1790 - val_accuracy: 0.9111\n",
      "Epoch 401/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1398 - accuracy: 0.9905 - val_loss: 0.1830 - val_accuracy: 0.9333\n",
      "Epoch 402/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1398 - accuracy: 0.9905 - val_loss: 0.1858 - val_accuracy: 0.9333\n",
      "Epoch 403/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.9905 - val_loss: 0.1876 - val_accuracy: 0.9333\n",
      "Epoch 404/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1395 - accuracy: 0.9905 - val_loss: 0.1854 - val_accuracy: 0.9333\n",
      "Epoch 405/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.9905 - val_loss: 0.1836 - val_accuracy: 0.9333\n",
      "Epoch 406/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9905 - val_loss: 0.1796 - val_accuracy: 0.9333\n",
      "Epoch 407/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9905 - val_loss: 0.1773 - val_accuracy: 0.9333\n",
      "Epoch 408/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9905 - val_loss: 0.1753 - val_accuracy: 0.9111\n",
      "Epoch 409/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 0.9905 - val_loss: 0.1745 - val_accuracy: 0.9111\n",
      "Epoch 410/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.9905 - val_loss: 0.1748 - val_accuracy: 0.9111\n",
      "Epoch 411/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1361 - accuracy: 0.9905 - val_loss: 0.1750 - val_accuracy: 0.9111\n",
      "Epoch 412/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.9905 - val_loss: 0.1741 - val_accuracy: 0.9111\n",
      "Epoch 413/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9905 - val_loss: 0.1752 - val_accuracy: 0.9333\n",
      "Epoch 414/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1345 - accuracy: 0.9905 - val_loss: 0.1768 - val_accuracy: 0.9333\n",
      "Epoch 415/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1344 - accuracy: 0.9905 - val_loss: 0.1792 - val_accuracy: 0.9333\n",
      "Epoch 416/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1352 - accuracy: 0.9905 - val_loss: 0.1795 - val_accuracy: 0.9333\n",
      "Epoch 417/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9905 - val_loss: 0.1744 - val_accuracy: 0.9333\n",
      "Epoch 418/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1330 - accuracy: 0.9905 - val_loss: 0.1710 - val_accuracy: 0.9111\n",
      "Epoch 419/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1332 - accuracy: 0.9905 - val_loss: 0.1698 - val_accuracy: 0.9111\n",
      "Epoch 420/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1331 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9111\n",
      "Epoch 421/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9111\n",
      "Epoch 422/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1323 - accuracy: 0.9905 - val_loss: 0.1741 - val_accuracy: 0.9333\n",
      "Epoch 423/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9905 - val_loss: 0.1764 - val_accuracy: 0.9333\n",
      "Epoch 424/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9905 - val_loss: 0.1776 - val_accuracy: 0.9333\n",
      "Epoch 425/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9905 - val_loss: 0.1778 - val_accuracy: 0.9333\n",
      "Epoch 426/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9905 - val_loss: 0.1753 - val_accuracy: 0.9333\n",
      "Epoch 427/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9905 - val_loss: 0.1761 - val_accuracy: 0.9333\n",
      "Epoch 428/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9905 - val_loss: 0.1776 - val_accuracy: 0.9333\n",
      "Epoch 429/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9905 - val_loss: 0.1746 - val_accuracy: 0.9333\n",
      "Epoch 430/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1287 - accuracy: 0.9905 - val_loss: 0.1707 - val_accuracy: 0.9333\n",
      "Epoch 431/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1282 - accuracy: 0.9905 - val_loss: 0.1686 - val_accuracy: 0.9333\n",
      "Epoch 432/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1288 - accuracy: 0.9905 - val_loss: 0.1665 - val_accuracy: 0.9111\n",
      "Epoch 433/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9905 - val_loss: 0.1683 - val_accuracy: 0.9333\n",
      "Epoch 434/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9905 - val_loss: 0.1728 - val_accuracy: 0.9333\n",
      "Epoch 435/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1274 - accuracy: 0.9905 - val_loss: 0.1736 - val_accuracy: 0.9333\n",
      "Epoch 436/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.9905 - val_loss: 0.1728 - val_accuracy: 0.9333\n",
      "Epoch 437/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9905 - val_loss: 0.1722 - val_accuracy: 0.9333\n",
      "Epoch 438/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9905 - val_loss: 0.1705 - val_accuracy: 0.9333\n",
      "Epoch 439/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1265 - accuracy: 0.9905 - val_loss: 0.1670 - val_accuracy: 0.9333\n",
      "Epoch 440/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1256 - accuracy: 0.9905 - val_loss: 0.1689 - val_accuracy: 0.9333\n",
      "Epoch 441/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9905 - val_loss: 0.1703 - val_accuracy: 0.9333\n",
      "Epoch 442/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9905 - val_loss: 0.1699 - val_accuracy: 0.9333\n",
      "Epoch 443/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9905 - val_loss: 0.1677 - val_accuracy: 0.9333\n",
      "Epoch 444/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9905 - val_loss: 0.1673 - val_accuracy: 0.9333\n",
      "Epoch 445/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9905 - val_loss: 0.1662 - val_accuracy: 0.9333\n",
      "Epoch 446/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9905 - val_loss: 0.1682 - val_accuracy: 0.9333\n",
      "Epoch 447/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.9905 - val_loss: 0.1675 - val_accuracy: 0.9333\n",
      "Epoch 448/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1227 - accuracy: 0.9905 - val_loss: 0.1653 - val_accuracy: 0.9333\n",
      "Epoch 449/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9905 - val_loss: 0.1600 - val_accuracy: 0.9111\n",
      "Epoch 450/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1228 - accuracy: 0.9905 - val_loss: 0.1582 - val_accuracy: 0.9333\n",
      "Epoch 451/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1235 - accuracy: 0.9905 - val_loss: 0.1579 - val_accuracy: 0.9333\n",
      "Epoch 452/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9905 - val_loss: 0.1590 - val_accuracy: 0.9111\n",
      "Epoch 453/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1217 - accuracy: 0.9905 - val_loss: 0.1622 - val_accuracy: 0.9333\n",
      "Epoch 454/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9905 - val_loss: 0.1647 - val_accuracy: 0.9333\n",
      "Epoch 455/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9905 - val_loss: 0.1650 - val_accuracy: 0.9333\n",
      "Epoch 456/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1201 - accuracy: 0.9905 - val_loss: 0.1618 - val_accuracy: 0.9333\n",
      "Epoch 457/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9905 - val_loss: 0.1593 - val_accuracy: 0.9111\n",
      "Epoch 458/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.9905 - val_loss: 0.1581 - val_accuracy: 0.9111\n",
      "Epoch 459/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1579 - val_accuracy: 0.9111\n",
      "Epoch 460/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9111\n",
      "Epoch 461/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1561 - val_accuracy: 0.9111\n",
      "Epoch 462/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 0.9111\n",
      "Epoch 463/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9111\n",
      "Epoch 464/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9905 - val_loss: 0.1602 - val_accuracy: 0.9333\n",
      "Epoch 465/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1174 - accuracy: 0.9905 - val_loss: 0.1640 - val_accuracy: 0.9333\n",
      "Epoch 466/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1184 - accuracy: 0.9905 - val_loss: 0.1677 - val_accuracy: 0.9333\n",
      "Epoch 467/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9905 - val_loss: 0.1661 - val_accuracy: 0.9333\n",
      "Epoch 468/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 1.00 - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9905 - val_loss: 0.1616 - val_accuracy: 0.9333\n",
      "Epoch 469/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1158 - accuracy: 0.9905 - val_loss: 0.1589 - val_accuracy: 0.9333\n",
      "Epoch 470/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9905 - val_loss: 0.1561 - val_accuracy: 0.9111\n",
      "Epoch 471/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9905 - val_loss: 0.1543 - val_accuracy: 0.9111\n",
      "Epoch 472/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9111\n",
      "Epoch 473/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9111\n",
      "Epoch 474/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9905 - val_loss: 0.1581 - val_accuracy: 0.9333\n",
      "Epoch 475/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9905 - val_loss: 0.1578 - val_accuracy: 0.9333\n",
      "Epoch 476/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9905 - val_loss: 0.1593 - val_accuracy: 0.9333\n",
      "Epoch 477/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1134 - accuracy: 0.9905 - val_loss: 0.1619 - val_accuracy: 0.9333\n",
      "Epoch 478/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9905 - val_loss: 0.1649 - val_accuracy: 0.9333\n",
      "Epoch 479/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9905 - val_loss: 0.1647 - val_accuracy: 0.9333\n",
      "Epoch 480/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.9905 - val_loss: 0.1630 - val_accuracy: 0.9333\n",
      "Epoch 481/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9905 - val_loss: 0.1609 - val_accuracy: 0.9333\n",
      "Epoch 482/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9905 - val_loss: 0.1570 - val_accuracy: 0.9333\n",
      "Epoch 483/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9905 - val_loss: 0.1559 - val_accuracy: 0.9333\n",
      "Epoch 484/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9905 - val_loss: 0.1539 - val_accuracy: 0.9111\n",
      "Epoch 485/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9905 - val_loss: 0.1542 - val_accuracy: 0.9333\n",
      "Epoch 486/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9905 - val_loss: 0.1551 - val_accuracy: 0.9333\n",
      "Epoch 487/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9905 - val_loss: 0.1554 - val_accuracy: 0.9333\n",
      "Epoch 488/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9905 - val_loss: 0.1553 - val_accuracy: 0.9333\n",
      "Epoch 489/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9905 - val_loss: 0.1566 - val_accuracy: 0.9333\n",
      "Epoch 490/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9905 - val_loss: 0.1577 - val_accuracy: 0.9333\n",
      "Epoch 491/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9905 - val_loss: 0.1571 - val_accuracy: 0.9333\n",
      "Epoch 492/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1099 - accuracy: 0.9905 - val_loss: 0.1544 - val_accuracy: 0.9333\n",
      "Epoch 493/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1092 - accuracy: 0.9905 - val_loss: 0.1535 - val_accuracy: 0.9333\n",
      "Epoch 494/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9905 - val_loss: 0.1523 - val_accuracy: 0.9333\n",
      "Epoch 495/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9905 - val_loss: 0.1515 - val_accuracy: 0.9111\n",
      "Epoch 496/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9905 - val_loss: 0.1520 - val_accuracy: 0.9333\n",
      "Epoch 497/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9905 - val_loss: 0.1534 - val_accuracy: 0.9333\n",
      "Epoch 498/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.9905 - val_loss: 0.1544 - val_accuracy: 0.9333\n",
      "Epoch 499/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9905 - val_loss: 0.1551 - val_accuracy: 0.9333\n",
      "Epoch 500/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9905 - val_loss: 0.1575 - val_accuracy: 0.9333\n",
      "Epoch 501/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9905 - val_loss: 0.1539 - val_accuracy: 0.9333\n",
      "Epoch 502/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1069 - accuracy: 0.9905 - val_loss: 0.1531 - val_accuracy: 0.9333\n",
      "Epoch 503/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9905 - val_loss: 0.1530 - val_accuracy: 0.9333\n",
      "Epoch 504/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.9905 - val_loss: 0.1530 - val_accuracy: 0.9333\n",
      "Epoch 505/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9905 - val_loss: 0.1541 - val_accuracy: 0.9333\n",
      "Epoch 506/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9905 - val_loss: 0.1538 - val_accuracy: 0.9333\n",
      "Epoch 507/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9905 - val_loss: 0.1557 - val_accuracy: 0.9333\n",
      "Epoch 508/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9905 - val_loss: 0.1572 - val_accuracy: 0.9333\n",
      "Epoch 509/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9905 - val_loss: 0.1546 - val_accuracy: 0.9333\n",
      "Epoch 510/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9905 - val_loss: 0.1530 - val_accuracy: 0.9333\n",
      "Epoch 511/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 0.9905 - val_loss: 0.1481 - val_accuracy: 0.9111\n",
      "Epoch 512/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9905 - val_loss: 0.1475 - val_accuracy: 0.9111\n",
      "Epoch 513/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 0.9111\n",
      "Epoch 514/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9111\n",
      "Epoch 515/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9111\n",
      "Epoch 516/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9111\n",
      "Epoch 517/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9111\n",
      "Epoch 518/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9333\n",
      "Epoch 519/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9905 - val_loss: 0.1493 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 520/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9905 - val_loss: 0.1524 - val_accuracy: 0.9333\n",
      "Epoch 521/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9905 - val_loss: 0.1503 - val_accuracy: 0.9333\n",
      "Epoch 522/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1019 - accuracy: 0.9905 - val_loss: 0.1498 - val_accuracy: 0.9333\n",
      "Epoch 523/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9905 - val_loss: 0.1484 - val_accuracy: 0.9333\n",
      "Epoch 524/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9905 - val_loss: 0.1479 - val_accuracy: 0.9333\n",
      "Epoch 525/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9905 - val_loss: 0.1512 - val_accuracy: 0.9333\n",
      "Epoch 526/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9905 - val_loss: 0.1523 - val_accuracy: 0.9333\n",
      "Epoch 527/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9905 - val_loss: 0.1537 - val_accuracy: 0.9333\n",
      "Epoch 528/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9905 - val_loss: 0.1541 - val_accuracy: 0.9333\n",
      "Epoch 529/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9905 - val_loss: 0.1522 - val_accuracy: 0.9333\n",
      "Epoch 530/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9905 - val_loss: 0.1503 - val_accuracy: 0.9333\n",
      "Epoch 531/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9905 - val_loss: 0.1450 - val_accuracy: 0.9333\n",
      "Epoch 532/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9905 - val_loss: 0.1435 - val_accuracy: 0.9111\n",
      "Epoch 533/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9111\n",
      "Epoch 534/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9111\n",
      "Epoch 535/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9333\n",
      "Epoch 536/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9905 - val_loss: 0.1468 - val_accuracy: 0.9333\n",
      "Epoch 537/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9905 - val_loss: 0.1483 - val_accuracy: 0.9333\n",
      "Epoch 538/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0987 - accuracy: 0.9905 - val_loss: 0.1505 - val_accuracy: 0.9333\n",
      "Epoch 539/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0984 - accuracy: 0.9905 - val_loss: 0.1490 - val_accuracy: 0.9333\n",
      "Epoch 540/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9905 - val_loss: 0.1459 - val_accuracy: 0.9333\n",
      "Epoch 541/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9905 - val_loss: 0.1451 - val_accuracy: 0.9333\n",
      "Epoch 542/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9905 - val_loss: 0.1424 - val_accuracy: 0.9111\n",
      "Epoch 543/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.9905 - val_loss: 0.1409 - val_accuracy: 0.9111\n",
      "Epoch 544/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9111\n",
      "Epoch 545/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9111\n",
      "Epoch 546/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9111\n",
      "Epoch 547/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0963 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9111\n",
      "Epoch 548/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9111\n",
      "Epoch 549/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9905 - val_loss: 0.1436 - val_accuracy: 0.9333\n",
      "Epoch 550/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9905 - val_loss: 0.1448 - val_accuracy: 0.9333\n",
      "Epoch 551/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0952 - accuracy: 0.9905 - val_loss: 0.1449 - val_accuracy: 0.9333\n",
      "Epoch 552/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0951 - accuracy: 0.9905 - val_loss: 0.1443 - val_accuracy: 0.9333\n",
      "Epoch 553/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0946 - accuracy: 0.9905 - val_loss: 0.1415 - val_accuracy: 0.9333\n",
      "Epoch 554/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9111\n",
      "Epoch 555/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9111\n",
      "Epoch 556/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9333\n",
      "Epoch 557/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9905 - val_loss: 0.1437 - val_accuracy: 0.9333\n",
      "Epoch 558/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0938 - accuracy: 0.9905 - val_loss: 0.1441 - val_accuracy: 0.9333\n",
      "Epoch 559/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9905 - val_loss: 0.1417 - val_accuracy: 0.9333\n",
      "Epoch 560/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9905 - val_loss: 0.1398 - val_accuracy: 0.9111\n",
      "Epoch 561/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9905 - val_loss: 0.1397 - val_accuracy: 0.9111\n",
      "Epoch 562/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9905 - val_loss: 0.1393 - val_accuracy: 0.9111\n",
      "Epoch 563/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9333\n",
      "Epoch 564/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9905 - val_loss: 0.1410 - val_accuracy: 0.9333\n",
      "Epoch 565/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0922 - accuracy: 0.9905 - val_loss: 0.1412 - val_accuracy: 0.9333\n",
      "Epoch 566/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0925 - accuracy: 0.9905 - val_loss: 0.1394 - val_accuracy: 0.9333\n",
      "Epoch 567/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9905 - val_loss: 0.1403 - val_accuracy: 0.9333\n",
      "Epoch 568/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9905 - val_loss: 0.1394 - val_accuracy: 0.9333\n",
      "Epoch 569/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9905 - val_loss: 0.1378 - val_accuracy: 0.9111\n",
      "Epoch 570/800\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9111\n",
      "Epoch 571/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9333\n",
      "Epoch 572/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9905 - val_loss: 0.1412 - val_accuracy: 0.9333\n",
      "Epoch 573/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9905 - val_loss: 0.1420 - val_accuracy: 0.9333\n",
      "Epoch 574/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9905 - val_loss: 0.1399 - val_accuracy: 0.9333\n",
      "Epoch 575/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9905 - val_loss: 0.1373 - val_accuracy: 0.9111\n",
      "Epoch 576/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9111\n",
      "Epoch 577/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9111\n",
      "Epoch 578/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9111\n",
      "Epoch 579/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9111\n",
      "Epoch 580/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9905 - val_loss: 0.1392 - val_accuracy: 0.9333\n",
      "Epoch 581/800\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9905 - val_loss: 0.1400 - val_accuracy: 0.9333\n",
      "Epoch 582/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9905 - val_loss: 0.1422 - val_accuracy: 0.9333\n",
      "Epoch 583/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9905 - val_loss: 0.1412 - val_accuracy: 0.9333\n",
      "Epoch 584/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9905 - val_loss: 0.1364 - val_accuracy: 0.9111\n",
      "Epoch 585/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9111\n",
      "Epoch 586/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9111\n",
      "Epoch 587/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9333\n",
      "Epoch 588/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9333\n",
      "Epoch 589/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9905 - val_loss: 0.1312 - val_accuracy: 0.9111\n",
      "Epoch 590/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9333\n",
      "Epoch 591/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9905 - val_loss: 0.1430 - val_accuracy: 0.9333\n",
      "Epoch 592/800\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9905 - val_loss: 0.1464 - val_accuracy: 0.9333\n",
      "Epoch 593/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0882 - accuracy: 0.9905 - val_loss: 0.1463 - val_accuracy: 0.9333\n",
      "Epoch 594/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9905 - val_loss: 0.1418 - val_accuracy: 0.9333\n",
      "Epoch 595/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0873 - accuracy: 0.9905 - val_loss: 0.1393 - val_accuracy: 0.9333\n",
      "Epoch 596/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9905 - val_loss: 0.1413 - val_accuracy: 0.9333\n",
      "Epoch 597/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9905 - val_loss: 0.1401 - val_accuracy: 0.9333\n",
      "Epoch 598/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9905 - val_loss: 0.1376 - val_accuracy: 0.9333\n",
      "Epoch 599/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9111\n",
      "Epoch 600/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9111\n",
      "Epoch 601/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9111\n",
      "Epoch 602/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9111\n",
      "Epoch 603/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9111\n",
      "Epoch 604/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9111\n",
      "Epoch 605/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9333\n",
      "Epoch 606/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0844 - accuracy: 0.9905 - val_loss: 0.1338 - val_accuracy: 0.9111\n",
      "Epoch 607/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9111\n",
      "Epoch 608/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9111\n",
      "Epoch 609/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9333\n",
      "Epoch 610/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9905 - val_loss: 0.1401 - val_accuracy: 0.9333\n",
      "Epoch 611/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9905 - val_loss: 0.1438 - val_accuracy: 0.9333\n",
      "Epoch 612/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9905 - val_loss: 0.1452 - val_accuracy: 0.9333\n",
      "Epoch 613/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0847 - accuracy: 0.9905 - val_loss: 0.1434 - val_accuracy: 0.9333\n",
      "Epoch 614/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0847 - accuracy: 0.9905 - val_loss: 0.1370 - val_accuracy: 0.9333\n",
      "Epoch 615/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9905 - val_loss: 0.1348 - val_accuracy: 0.9333\n",
      "Epoch 616/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9905 - val_loss: 0.1339 - val_accuracy: 0.9333\n",
      "Epoch 617/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9905 - val_loss: 0.1337 - val_accuracy: 0.9333\n",
      "Epoch 618/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9111\n",
      "Epoch 619/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9111\n",
      "Epoch 620/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9111\n",
      "Epoch 621/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9111\n",
      "Epoch 622/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9111\n",
      "Epoch 623/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9111\n",
      "Epoch 624/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9333\n",
      "Epoch 625/800\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9905 - val_loss: 0.1392 - val_accuracy: 0.9333\n",
      "Epoch 626/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9905 - val_loss: 0.1395 - val_accuracy: 0.9333\n",
      "Epoch 627/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9905 - val_loss: 0.1369 - val_accuracy: 0.9333\n",
      "Epoch 628/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9905 - val_loss: 0.1317 - val_accuracy: 0.9111\n",
      "Epoch 629/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9111\n",
      "Epoch 630/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9111\n",
      "Epoch 631/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9333\n",
      "Epoch 632/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9905 - val_loss: 0.1344 - val_accuracy: 0.9333\n",
      "Epoch 633/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9905 - val_loss: 0.1338 - val_accuracy: 0.9333\n",
      "Epoch 634/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9905 - val_loss: 0.1337 - val_accuracy: 0.9333\n",
      "Epoch 635/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9905 - val_loss: 0.1331 - val_accuracy: 0.9333\n",
      "Epoch 636/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9111\n",
      "Epoch 637/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9111\n",
      "Epoch 638/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9111\n",
      "Epoch 639/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9111\n",
      "Epoch 640/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9111\n",
      "Epoch 641/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9333\n",
      "Epoch 642/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9905 - val_loss: 0.1348 - val_accuracy: 0.9333\n",
      "Epoch 643/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9905 - val_loss: 0.1361 - val_accuracy: 0.9333\n",
      "Epoch 644/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9905 - val_loss: 0.1364 - val_accuracy: 0.9333\n",
      "Epoch 645/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9905 - val_loss: 0.1347 - val_accuracy: 0.9333\n",
      "Epoch 646/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9905 - val_loss: 0.1326 - val_accuracy: 0.9333\n",
      "Epoch 647/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9905 - val_loss: 0.1301 - val_accuracy: 0.9111\n",
      "Epoch 648/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9333\n",
      "Epoch 649/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9333\n",
      "Epoch 650/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9905 - val_loss: 0.1335 - val_accuracy: 0.9333\n",
      "Epoch 651/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9905 - val_loss: 0.1310 - val_accuracy: 0.9333\n",
      "Epoch 652/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9111\n",
      "Epoch 653/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9111\n",
      "Epoch 654/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9111\n",
      "Epoch 655/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9333\n",
      "Epoch 656/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9905 - val_loss: 0.1356 - val_accuracy: 0.9333\n",
      "Epoch 657/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9905 - val_loss: 0.1381 - val_accuracy: 0.9333\n",
      "Epoch 658/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9905 - val_loss: 0.1352 - val_accuracy: 0.9333\n",
      "Epoch 659/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9905 - val_loss: 0.1322 - val_accuracy: 0.9333\n",
      "Epoch 660/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9905 - val_loss: 0.1311 - val_accuracy: 0.9333\n",
      "Epoch 661/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9905 - val_loss: 0.1312 - val_accuracy: 0.9333\n",
      "Epoch 662/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9905 - val_loss: 0.1326 - val_accuracy: 0.9333\n",
      "Epoch 663/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9905 - val_loss: 0.1320 - val_accuracy: 0.9333\n",
      "Epoch 664/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9905 - val_loss: 0.1320 - val_accuracy: 0.9333\n",
      "Epoch 665/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9905 - val_loss: 0.1329 - val_accuracy: 0.9333\n",
      "Epoch 666/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9905 - val_loss: 0.1341 - val_accuracy: 0.9333\n",
      "Epoch 667/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9905 - val_loss: 0.1316 - val_accuracy: 0.9333\n",
      "Epoch 668/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0750 - accuracy: 0.9905 - val_loss: 0.1300 - val_accuracy: 0.9333\n",
      "Epoch 669/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9905 - val_loss: 0.1270 - val_accuracy: 0.9111\n",
      "Epoch 670/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9111\n",
      "Epoch 671/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9111\n",
      "Epoch 672/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9111\n",
      "Epoch 673/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9333\n",
      "Epoch 674/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9905 - val_loss: 0.1327 - val_accuracy: 0.9333\n",
      "Epoch 675/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9905 - val_loss: 0.1330 - val_accuracy: 0.9333\n",
      "Epoch 676/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9905 - val_loss: 0.1287 - val_accuracy: 0.9333\n",
      "Epoch 677/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9111\n",
      "Epoch 678/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9111\n",
      "Epoch 679/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9333\n",
      "Epoch 680/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9333\n",
      "Epoch 681/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9333\n",
      "Epoch 682/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9333\n",
      "Epoch 683/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9905 - val_loss: 0.1276 - val_accuracy: 0.9333\n",
      "Epoch 684/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9111\n",
      "Epoch 685/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0724 - accuracy: 0.9905 - val_loss: 0.1314 - val_accuracy: 0.9333\n",
      "Epoch 686/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9905 - val_loss: 0.1365 - val_accuracy: 0.9333\n",
      "Epoch 687/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9905 - val_loss: 0.1355 - val_accuracy: 0.9333\n",
      "Epoch 688/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9905 - val_loss: 0.1348 - val_accuracy: 0.9333\n",
      "Epoch 689/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9905 - val_loss: 0.1307 - val_accuracy: 0.9333\n",
      "Epoch 690/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9111\n",
      "Epoch 691/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9111\n",
      "Epoch 692/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9111\n",
      "Epoch 693/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9111\n",
      "Epoch 694/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9111\n",
      "Epoch 695/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9111\n",
      "Epoch 696/800\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9111\n",
      "Epoch 697/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9333\n",
      "Epoch 698/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9905 - val_loss: 0.1331 - val_accuracy: 0.9333\n",
      "Epoch 699/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0712 - accuracy: 0.9905 - val_loss: 0.1317 - val_accuracy: 0.9333\n",
      "Epoch 700/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9905 - val_loss: 0.1315 - val_accuracy: 0.9333\n",
      "Epoch 701/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9905 - val_loss: 0.1298 - val_accuracy: 0.9333\n",
      "Epoch 702/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9111\n",
      "Epoch 703/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9111\n",
      "Epoch 704/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9111\n",
      "Epoch 705/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9111\n",
      "Epoch 706/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9333\n",
      "Epoch 707/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9333\n",
      "Epoch 708/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9333\n",
      "Epoch 709/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 0.9333\n",
      "Epoch 710/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9905 - val_loss: 0.1300 - val_accuracy: 0.9333\n",
      "Epoch 711/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9905 - val_loss: 0.1290 - val_accuracy: 0.9333\n",
      "Epoch 712/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9905 - val_loss: 0.1256 - val_accuracy: 0.9111\n",
      "Epoch 713/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9111\n",
      "Epoch 714/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9111\n",
      "Epoch 715/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9111\n",
      "Epoch 716/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9111\n",
      "Epoch 717/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9111\n",
      "Epoch 718/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0691 - accuracy: 0.9905 - val_loss: 0.1280 - val_accuracy: 0.9333\n",
      "Epoch 719/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9905 - val_loss: 0.1255 - val_accuracy: 0.9333\n",
      "Epoch 720/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9333\n",
      "Epoch 721/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9111\n",
      "Epoch 722/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9111\n",
      "Epoch 723/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9111\n",
      "Epoch 724/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9111\n",
      "Epoch 725/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9111\n",
      "Epoch 726/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9111\n",
      "Epoch 727/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9111\n",
      "Epoch 728/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9333\n",
      "Epoch 729/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9905 - val_loss: 0.1298 - val_accuracy: 0.9333\n",
      "Epoch 730/800\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0670 - accuracy: 0.9905 - val_loss: 0.1277 - val_accuracy: 0.9333\n",
      "Epoch 731/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9905 - val_loss: 0.1247 - val_accuracy: 0.9111\n",
      "Epoch 732/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9111\n",
      "Epoch 733/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9111\n",
      "Epoch 734/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9111\n",
      "Epoch 735/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9111\n",
      "Epoch 736/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9111\n",
      "Epoch 737/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9111\n",
      "Epoch 738/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9333\n",
      "Epoch 739/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9905 - val_loss: 0.1302 - val_accuracy: 0.9333\n",
      "Epoch 740/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9905 - val_loss: 0.1294 - val_accuracy: 0.9333\n",
      "Epoch 741/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9905 - val_loss: 0.1289 - val_accuracy: 0.9333\n",
      "Epoch 742/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9905 - val_loss: 0.1266 - val_accuracy: 0.9333\n",
      "Epoch 743/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9333\n",
      "Epoch 744/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9333\n",
      "Epoch 745/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9905 - val_loss: 0.1277 - val_accuracy: 0.9333\n",
      "Epoch 746/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9905 - val_loss: 0.1276 - val_accuracy: 0.9333\n",
      "Epoch 747/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9905 - val_loss: 0.1272 - val_accuracy: 0.9333\n",
      "Epoch 748/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9905 - val_loss: 0.1233 - val_accuracy: 0.9111\n",
      "Epoch 749/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9333\n",
      "Epoch 750/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9111\n",
      "Epoch 751/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9111\n",
      "Epoch 752/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9111\n",
      "Epoch 753/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9111\n",
      "Epoch 754/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9333\n",
      "Epoch 755/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9905 - val_loss: 0.1298 - val_accuracy: 0.9333\n",
      "Epoch 756/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9905 - val_loss: 0.1274 - val_accuracy: 0.9333\n",
      "Epoch 757/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9905 - val_loss: 0.1270 - val_accuracy: 0.9333\n",
      "Epoch 758/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9905 - val_loss: 0.1269 - val_accuracy: 0.9333\n",
      "Epoch 759/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9333\n",
      "Epoch 760/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9333\n",
      "Epoch 761/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9333\n",
      "Epoch 762/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9111\n",
      "Epoch 763/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9111\n",
      "Epoch 764/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9111\n",
      "Epoch 765/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9111\n",
      "Epoch 766/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9111\n",
      "Epoch 767/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9111\n",
      "Epoch 768/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9111\n",
      "Epoch 769/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9111\n",
      "Epoch 770/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9111\n",
      "Epoch 771/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9111\n",
      "Epoch 772/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9111\n",
      "Epoch 773/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9111\n",
      "Epoch 774/800\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0653 - accuracy: 1.00 - 0s 4ms/step - loss: 0.0629 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9333\n",
      "Epoch 775/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9905 - val_loss: 0.1280 - val_accuracy: 0.9333\n",
      "Epoch 776/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9905 - val_loss: 0.1271 - val_accuracy: 0.9333\n",
      "Epoch 777/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9905 - val_loss: 0.1284 - val_accuracy: 0.9333\n",
      "Epoch 778/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9905 - val_loss: 0.1290 - val_accuracy: 0.9333\n",
      "Epoch 779/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9905 - val_loss: 0.1309 - val_accuracy: 0.9333\n",
      "Epoch 780/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9905 - val_loss: 0.1332 - val_accuracy: 0.9333\n",
      "Epoch 781/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 0.9905 - val_loss: 0.1228 - val_accuracy: 0.9111\n",
      "Epoch 782/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9111\n",
      "Epoch 783/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9333\n",
      "Epoch 784/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9111\n",
      "Epoch 785/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9111\n",
      "Epoch 786/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9333\n",
      "Epoch 787/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9905 - val_loss: 0.1313 - val_accuracy: 0.9333\n",
      "Epoch 788/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9905 - val_loss: 0.1336 - val_accuracy: 0.9333\n",
      "Epoch 789/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9905 - val_loss: 0.1336 - val_accuracy: 0.9333\n",
      "Epoch 790/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9905 - val_loss: 0.1324 - val_accuracy: 0.9333\n",
      "Epoch 791/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9905 - val_loss: 0.1299 - val_accuracy: 0.9333\n",
      "Epoch 792/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9905 - val_loss: 0.1282 - val_accuracy: 0.9333\n",
      "Epoch 793/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9905 - val_loss: 0.1245 - val_accuracy: 0.9333\n",
      "Epoch 794/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9111\n",
      "Epoch 795/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9111\n",
      "Epoch 796/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9111\n",
      "Epoch 797/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9333\n",
      "Epoch 798/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9905 - val_loss: 0.1263 - val_accuracy: 0.9333\n",
      "Epoch 799/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9905 - val_loss: 0.1247 - val_accuracy: 0.9333\n",
      "Epoch 800/800\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "# apply test data. Model will be tested after every iteration\n",
    "# you can cache model to the variable (my_model_training) to keep historical data\n",
    "my_model_training = model_2.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=800, )\n",
    "\n",
    "# in my case train accuracy dropped to 9.8 and validation accuracy dropped to 9.5\n",
    "# More important is loss function.\n",
    "# train loss function should be dropping all the time.\n",
    "# test lost function is dropping down, adn at certain point is going up and down.\n",
    "# The point where your test loss function starts going up and down is the point where the model should be stopped to be trained.\n",
    "# It starts to be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.callbacks.History'>\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chief_worker_only', '_implements_predict_batch_hooks', '_implements_test_batch_hooks', '_implements_train_batch_hooks', '_keras_api_names', '_keras_api_names_v1', '_supports_tf_logs', 'epoch', 'history', 'model', 'on_batch_begin', 'on_batch_end', 'on_epoch_begin', 'on_epoch_end', 'on_predict_batch_begin', 'on_predict_batch_end', 'on_predict_begin', 'on_predict_end', 'on_test_batch_begin', 'on_test_batch_end', 'on_test_begin', 'on_test_end', 'on_train_batch_begin', 'on_train_batch_end', 'on_train_begin', 'on_train_end', 'params', 'set_model', 'set_params', 'validation_data']\n"
     ]
    }
   ],
   "source": [
    "print(type(my_model_training))\n",
    "\n",
    "# it is from History object from tensorflow package:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History\n",
    "# unfortunately not much in API\n",
    "\n",
    "print(dir(my_model_training)) # some more info here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "my_model_history = my_model_training.history\n",
    "\n",
    "print(type(my_model_history))\n",
    "print(my_model_history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.451370120048523, 1.3492648601531982, 1.258573293685913, 1.1781319379806519, 1.1086578369140625, 1.0494086742401123, 1.0043623447418213, 0.9717866778373718, 0.9456112384796143, 0.927207350730896, 0.9141582250595093, 0.9039748311042786, 0.8955831527709961, 0.8884583115577698, 0.8822905421257019, 0.8764446973800659, 0.8700010776519775, 0.8629611730575562, 0.8554299473762512, 0.8470935225486755, 0.8389986753463745, 0.8310733437538147, 0.8224014043807983, 0.8158220648765564, 0.8074381351470947, 0.8012868165969849, 0.7950541973114014, 0.7892500162124634, 0.7805286049842834, 0.7723983526229858, 0.7633851170539856, 0.7520392537117004, 0.7410037517547607, 0.7326581478118896, 0.7235137224197388, 0.7153105139732361, 0.7087908983230591, 0.7031042575836182, 0.6957670450210571, 0.6891548037528992, 0.683659017086029, 0.6777797937393188, 0.6741812229156494, 0.6695423722267151, 0.6652556657791138, 0.6600679159164429, 0.6548848152160645, 0.6510881185531616, 0.6492323875427246, 0.6450810432434082, 0.639683187007904, 0.6369109749794006, 0.6318731307983398, 0.6290059685707092, 0.6222817301750183, 0.6172504425048828, 0.6139000654220581, 0.6111345291137695, 0.6072520017623901, 0.602824330329895, 0.598294198513031, 0.5949695110321045, 0.5913292169570923, 0.5885816216468811, 0.5868638753890991, 0.586645781993866, 0.5857707262039185, 0.583627462387085, 0.5804035663604736, 0.5776039958000183, 0.5724858641624451, 0.568717360496521, 0.5646470189094543, 0.559520423412323, 0.5553802251815796, 0.551598846912384, 0.5488306879997253, 0.5457243323326111, 0.543723464012146, 0.5421753525733948, 0.5395774841308594, 0.5364003777503967, 0.534353494644165, 0.5333133339881897, 0.5314820408821106, 0.528828501701355, 0.5247446894645691, 0.5213963985443115, 0.5179970264434814, 0.5148264169692993, 0.5123454332351685, 0.5108683705329895, 0.5101521611213684, 0.5082165002822876, 0.5068444609642029, 0.5056284666061401, 0.5053609013557434, 0.5057536363601685, 0.5055218935012817, 0.5033324956893921, 0.5003225803375244, 0.49646204710006714, 0.49317342042922974, 0.4887659251689911, 0.4841594398021698, 0.4809938073158264, 0.47775208950042725, 0.47523078322410583, 0.47373631596565247, 0.4727708697319031, 0.46959277987480164, 0.4683743715286255, 0.4684758186340332, 0.47008633613586426, 0.4694940745830536, 0.4693353772163391, 0.4672468304634094, 0.4655933678150177, 0.463070809841156, 0.4595872759819031, 0.45472365617752075, 0.4498193860054016, 0.4458290934562683, 0.44343408942222595, 0.4415396749973297, 0.43995437026023865, 0.4384832978248596, 0.43748220801353455, 0.4351876974105835, 0.4344090223312378, 0.43276020884513855, 0.4304853677749634, 0.42729780077934265, 0.4257586896419525, 0.42484310269355774, 0.4253908693790436, 0.4260692298412323, 0.42711833119392395, 0.42495644092559814, 0.42284610867500305, 0.4188544452190399, 0.41524538397789, 0.41463160514831543, 0.41374528408050537, 0.41415923833847046, 0.4127323627471924, 0.41063910722732544, 0.4089096188545227, 0.4078005850315094, 0.40644538402557373, 0.40410134196281433, 0.40284618735313416, 0.4005189538002014, 0.3977818489074707, 0.3955528736114502, 0.3923342525959015, 0.39064821600914, 0.3900448977947235, 0.3888678550720215, 0.3885532021522522, 0.3881097435951233, 0.387304425239563, 0.38493454456329346, 0.3817436993122101, 0.3807329535484314, 0.37827450037002563, 0.37736672163009644, 0.3758831024169922, 0.37386032938957214, 0.3706020712852478, 0.3682664632797241, 0.36770549416542053, 0.3684327006340027, 0.3686552345752716, 0.36726024746894836, 0.363744854927063, 0.3609606921672821, 0.3591857850551605, 0.3594987690448761, 0.35858145356178284, 0.35726696252822876, 0.3561127483844757, 0.3555998206138611, 0.3535410165786743, 0.3518509864807129, 0.3521087169647217, 0.35284778475761414, 0.35100576281547546, 0.3487671911716461, 0.34540069103240967, 0.344746857881546, 0.3437926471233368, 0.34302854537963867, 0.33951255679130554, 0.3376985490322113, 0.3348875641822815, 0.33334651589393616, 0.33301714062690735, 0.3338519036769867, 0.3345208466053009, 0.33692482113838196, 0.33554646372795105, 0.33214840292930603, 0.32761889696121216, 0.3263201415538788, 0.3268275260925293, 0.32656410336494446, 0.3244326412677765, 0.322711318731308, 0.32235434651374817, 0.3229447305202484, 0.3218472898006439, 0.3194756507873535, 0.3165571093559265, 0.3149210810661316, 0.31221431493759155, 0.3099018931388855, 0.3079671561717987, 0.30654871463775635, 0.30605775117874146, 0.3066426217556, 0.30832386016845703, 0.30807143449783325, 0.3071393072605133, 0.30576759576797485, 0.30181580781936646, 0.2989993691444397, 0.2974261939525604, 0.2968030273914337, 0.29608166217803955, 0.29593944549560547, 0.2951449453830719, 0.2942848205566406, 0.294811874628067, 0.29340681433677673, 0.29123643040657043, 0.28950387239456177, 0.28974243998527527, 0.28971046209335327, 0.28945082426071167, 0.28811734914779663, 0.28668978810310364, 0.28439921140670776, 0.28516891598701477, 0.28412237763404846, 0.2817617952823639, 0.2794745862483978, 0.2789337933063507, 0.27741536498069763, 0.27749550342559814, 0.2760219871997833, 0.27500346302986145, 0.2732888162136078, 0.2715621292591095, 0.27044758200645447, 0.2690427601337433, 0.26797714829444885, 0.26759862899780273, 0.26736387610435486, 0.2658204734325409, 0.2648661434650421, 0.2645418345928192, 0.2663433849811554, 0.2666354179382324, 0.2655947804450989, 0.2642228305339813, 0.2657894790172577, 0.26688724756240845, 0.2659817039966583, 0.26708337664604187, 0.2654513716697693, 0.2633906602859497, 0.2603977918624878, 0.25641658902168274, 0.25389373302459717, 0.25175824761390686, 0.25241899490356445, 0.2546057403087616, 0.25682079792022705, 0.2574462890625, 0.25651097297668457, 0.2549538016319275, 0.2536221742630005, 0.25124701857566833, 0.24934010207653046, 0.2479267567396164, 0.24660557508468628, 0.24759221076965332, 0.24893701076507568, 0.24951015412807465, 0.24915756285190582, 0.24579323828220367, 0.24214690923690796, 0.23924514651298523, 0.23782941699028015, 0.23763054609298706, 0.23802337050437927, 0.23894102871418, 0.2383870631456375, 0.23534241318702698, 0.23382729291915894, 0.23329810798168182, 0.2341119945049286, 0.23670156300067902, 0.23650851845741272, 0.23548302054405212, 0.2339927703142166, 0.23092354834079742, 0.22789543867111206, 0.22457754611968994, 0.22313031554222107, 0.22268009185791016, 0.2226131409406662, 0.2240179032087326, 0.22617627680301666, 0.22630836069583893, 0.2228400558233261, 0.2210019826889038, 0.22007183730602264, 0.22033792734146118, 0.2213270366191864, 0.22514839470386505, 0.22917591035366058, 0.22792057693004608, 0.22392819821834564, 0.22162523865699768, 0.21864716708660126, 0.21606245636940002, 0.21500974893569946, 0.21398243308067322, 0.21333664655685425, 0.21328744292259216, 0.2118726521730423, 0.21181006729602814, 0.21216335892677307, 0.2141721248626709, 0.21837684512138367, 0.22148263454437256, 0.21835573017597198, 0.21288421750068665, 0.20813429355621338, 0.2065400928258896, 0.20673343539237976, 0.2068915069103241, 0.21042847633361816, 0.21163733303546906, 0.21275009214878082, 0.2121729552745819, 0.20986402034759521, 0.20552705228328705, 0.2033996433019638, 0.20031026005744934, 0.1990404725074768, 0.1990032196044922, 0.19782187044620514, 0.1991310566663742, 0.20292779803276062, 0.20675595104694366, 0.21218396723270416, 0.21126386523246765, 0.20375102758407593, 0.19760464131832123, 0.19529356062412262, 0.19412903487682343, 0.19589418172836304, 0.20150992274284363, 0.20878301560878754, 0.2083260864019394, 0.20140257477760315, 0.19787201285362244, 0.19351333379745483, 0.19227363169193268, 0.191864013671875, 0.1903042197227478, 0.1910892277956009, 0.19111162424087524, 0.19173796474933624, 0.19227375090122223, 0.19331574440002441, 0.19133703410625458, 0.18980775773525238, 0.190876767039299, 0.19135433435440063, 0.18781964480876923, 0.18448469042778015, 0.18256399035453796, 0.18244348466396332, 0.18242225050926208, 0.18514040112495422, 0.1870623528957367, 0.18967704474925995, 0.1893530935049057, 0.1915830373764038, 0.19211313128471375, 0.19129513204097748, 0.18730011582374573, 0.18290498852729797, 0.18103954195976257, 0.1795768290758133, 0.1790376603603363, 0.18302632868289948, 0.18575838208198547, 0.18758217990398407, 0.18535205721855164, 0.18355096876621246, 0.1795666515827179, 0.1772863119840622, 0.17529702186584473, 0.17453506588935852, 0.17484122514724731, 0.174983948469162, 0.1741158813238144, 0.17520301043987274, 0.17679312825202942, 0.17915129661560059, 0.17950499057769775, 0.1743999421596527, 0.17098824679851532, 0.16984614729881287, 0.16931506991386414, 0.17023895680904388, 0.1741233617067337, 0.17642445862293243, 0.1775514781475067, 0.1777845174074173, 0.1752779185771942, 0.17607742547988892, 0.17757296562194824, 0.17462287843227386, 0.17065344750881195, 0.16861684620380402, 0.16649699211120605, 0.1682957112789154, 0.17276890575885773, 0.17362673580646515, 0.17284193634986877, 0.1722227782011032, 0.1705164611339569, 0.16698633134365082, 0.16894544661045074, 0.1703009307384491, 0.1699088215827942, 0.16771693527698517, 0.16728250682353973, 0.1661980152130127, 0.16821619868278503, 0.16746895015239716, 0.16529949009418488, 0.16000400483608246, 0.15822404623031616, 0.15785549581050873, 0.15899880230426788, 0.16216610372066498, 0.16473272442817688, 0.1649547964334488, 0.16179507970809937, 0.1593388170003891, 0.15807341039180756, 0.15790019929409027, 0.15692517161369324, 0.15612588822841644, 0.1571582406759262, 0.15850037336349487, 0.1602381020784378, 0.16396000981330872, 0.16766098141670227, 0.1661318689584732, 0.16158021986484528, 0.15886758267879486, 0.15605363249778748, 0.15432828664779663, 0.15534953773021698, 0.1563640832901001, 0.15813513100147247, 0.1578005701303482, 0.15931488573551178, 0.16192862391471863, 0.1648605614900589, 0.16468112170696259, 0.16300010681152344, 0.16087009012699127, 0.15700265765190125, 0.1559293121099472, 0.15390291810035706, 0.1541658192873001, 0.15505477786064148, 0.1554492861032486, 0.15528762340545654, 0.156553253531456, 0.15770907700061798, 0.15714599192142487, 0.15443187952041626, 0.1535332202911377, 0.15226268768310547, 0.1515427827835083, 0.15201090276241302, 0.1534021496772766, 0.1543605625629425, 0.15507982671260834, 0.157534658908844, 0.1538814902305603, 0.15308250486850739, 0.1529722958803177, 0.1530483216047287, 0.15409021079540253, 0.15381616353988647, 0.15567748248577118, 0.15720467269420624, 0.15457822382450104, 0.15295694768428802, 0.1481005847454071, 0.147498220205307, 0.14618970453739166, 0.14525766670703888, 0.14418138563632965, 0.14338399469852448, 0.14420288801193237, 0.1470891833305359, 0.1492725908756256, 0.15235766768455505, 0.15025199949741364, 0.1497969776391983, 0.14841991662979126, 0.14786866307258606, 0.15115751326084137, 0.1522601842880249, 0.1537211686372757, 0.15411069989204407, 0.15220420062541962, 0.15026628971099854, 0.14496305584907532, 0.1435442715883255, 0.1431015431880951, 0.14269277453422546, 0.14412027597427368, 0.14680230617523193, 0.1483335942029953, 0.15045171976089478, 0.14901649951934814, 0.1459466964006424, 0.14506657421588898, 0.14242014288902283, 0.14089776575565338, 0.138347327709198, 0.13841921091079712, 0.14004658162593842, 0.13989099860191345, 0.1409740000963211, 0.14364416897296906, 0.14479891955852509, 0.14493927359580994, 0.14427411556243896, 0.14153704047203064, 0.13944147527217865, 0.1391787827014923, 0.1408206969499588, 0.1436855047941208, 0.14408285915851593, 0.1416749358177185, 0.13977454602718353, 0.13971497118473053, 0.13931570947170258, 0.14076311886310577, 0.14100991189479828, 0.14119450747966766, 0.13935866951942444, 0.1402609497308731, 0.1393791139125824, 0.13775929808616638, 0.13679131865501404, 0.13865329325199127, 0.14123797416687012, 0.1420138031244278, 0.13988207280635834, 0.13731932640075684, 0.13310636579990387, 0.13278497755527496, 0.1335386484861374, 0.13641539216041565, 0.13920190930366516, 0.14003026485443115, 0.1422034502029419, 0.1412464827299118, 0.13638825714588165, 0.13400669395923615, 0.13205844163894653, 0.13058523833751678, 0.13046185672283173, 0.13118401169776917, 0.1368275135755539, 0.14301040768623352, 0.14641445875167847, 0.146303191781044, 0.14178244769573212, 0.13933995366096497, 0.14132638275623322, 0.1400918811559677, 0.13757236301898956, 0.1333719938993454, 0.1307014375925064, 0.12976448237895966, 0.1329316943883896, 0.1336546540260315, 0.13309061527252197, 0.1347040981054306, 0.13381235301494598, 0.1330711841583252, 0.13349388539791107, 0.13580292463302612, 0.14007115364074707, 0.14375042915344238, 0.14522381126880646, 0.14335916936397552, 0.13704439997673035, 0.1347920447587967, 0.1338515430688858, 0.13373754918575287, 0.13206472992897034, 0.13062550127506256, 0.1281319111585617, 0.12918351590633392, 0.1298777312040329, 0.13054192066192627, 0.13574549555778503, 0.1391831487417221, 0.1395168900489807, 0.1369018852710724, 0.1317165642976761, 0.12966451048851013, 0.12799778580665588, 0.13179628551006317, 0.13441205024719238, 0.13384072482585907, 0.13370724022388458, 0.13305127620697021, 0.12896858155727386, 0.127977654337883, 0.12822170555591583, 0.1276402622461319, 0.12882734835147858, 0.13376179337501526, 0.13483388721942902, 0.13611890375614166, 0.13641884922981262, 0.1346905678510666, 0.1326112151145935, 0.13011422753334045, 0.13017401099205017, 0.1314038336277008, 0.13350728154182434, 0.1310274302959442, 0.1275799423456192, 0.1251945048570633, 0.12589900195598602, 0.13090038299560547, 0.1356145441532135, 0.13808807730674744, 0.13521650433540344, 0.13223955035209656, 0.13108031451702118, 0.1312018483877182, 0.13263151049613953, 0.13199816644191742, 0.1320229023694992, 0.13292522728443146, 0.13407371938228607, 0.13162389397621155, 0.13002952933311462, 0.12702704966068268, 0.12633974850177765, 0.1275949329137802, 0.12702137231826782, 0.1292068213224411, 0.13269560039043427, 0.13298121094703674, 0.1287449151277542, 0.12682856619358063, 0.12688471376895905, 0.12865185737609863, 0.1299777328968048, 0.1277388483285904, 0.12919171154499054, 0.12764695286750793, 0.12715299427509308, 0.131358802318573, 0.1364785134792328, 0.13553883135318756, 0.13476765155792236, 0.13072940707206726, 0.12634062767028809, 0.12526701390743256, 0.12327030301094055, 0.12227316200733185, 0.12381526827812195, 0.12499877065420151, 0.12667404115200043, 0.12997236847877502, 0.13305391371250153, 0.13170328736305237, 0.13149061799049377, 0.12975814938545227, 0.12520982325077057, 0.1232936829328537, 0.12317948788404465, 0.12561021745204926, 0.12641988694667816, 0.12721572816371918, 0.12658895552158356, 0.1286495178937912, 0.13003434240818024, 0.12900446355342865, 0.1256219893693924, 0.12454914301633835, 0.12335734814405441, 0.12263032793998718, 0.12390431016683578, 0.12442866712808609, 0.12802384793758392, 0.12547574937343597, 0.12580379843711853, 0.12295245379209518, 0.12247469276189804, 0.12306569516658783, 0.12456869333982468, 0.12426391243934631, 0.12349162995815277, 0.12393132597208023, 0.12768033146858215, 0.12977203726768494, 0.12774884700775146, 0.12474693357944489, 0.12294968217611313, 0.12032616883516312, 0.11962011456489563, 0.12030976265668869, 0.12141311168670654, 0.12315253913402557, 0.12772417068481445, 0.13023751974105835, 0.12940523028373718, 0.1288805902004242, 0.1266058385372162, 0.12590868771076202, 0.12702928483486176, 0.12773855030536652, 0.12758564949035645, 0.12719620764255524, 0.12327055633068085, 0.12435178458690643, 0.1223987489938736, 0.11997044831514359, 0.11893673241138458, 0.1219911128282547, 0.1284608393907547, 0.12980590760707855, 0.1274157613515854, 0.12699346244335175, 0.12687796354293823, 0.12559327483177185, 0.12504005432128906, 0.12535065412521362, 0.1232324168086052, 0.12167320400476456, 0.12119121849536896, 0.12081453204154968, 0.12097228318452835, 0.11990083009004593, 0.12030358612537384, 0.11948362737894058, 0.11761283874511719, 0.11807411909103394, 0.12085247784852982, 0.12313084304332733, 0.1276451051235199, 0.12802575528621674, 0.12705543637275696, 0.12837083637714386, 0.12902770936489105, 0.13092517852783203, 0.13323411345481873, 0.12284298241138458, 0.11721859872341156, 0.11520100384950638, 0.11734723299741745, 0.12119242548942566, 0.1281578689813614, 0.13130992650985718, 0.13359181582927704, 0.13361875712871552, 0.1324329674243927, 0.12991374731063843, 0.12817181646823883, 0.12453831732273102, 0.1215795949101448, 0.12130298465490341, 0.12119478732347488, 0.12344596534967422, 0.12630237638950348, 0.12467825412750244, 0.12337452918291092]\n"
     ]
    }
   ],
   "source": [
    "print(my_model_history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use historical data to plot diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21e7a1bb790>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAIICAYAAADHZSyIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABSC0lEQVR4nO3dd5xU1f3/8deZtr3AFvrSEVFBEBWx996ixm40GmKixiTfJKb80r5JvumJ6cYYS6KxRE3svTdUkCJFelvaLssW2Drl/P44s7Lgwi7szM7snffz8djHzty5c+dzUHbfnHaNtRYRERGRZPGlugARERHxNoUNERERSSqFDREREUkqhQ0RERFJKoUNERERSSqFDREREUmqQKo+uLS01I4YMSJVHy8iIiIJNHv27C3W2rLOXktZ2BgxYgSzZs1K1ceLiIhIAhlj1uzuNQ2jiIiISFIpbIiIiEhSKWyIiIhIUilsiIiISFIpbIiIiEhSKWyIiIhIUilsiIiISFIpbIiIiEhSKWyIiIhIUilsiIiISFIpbIiIiEhSKWyIiIhIUilsiIiISFIpbIiIiEhSKWyIiIhIUilsiIiISFIpbIiIiEhSdRk2jDF3GmOqjDEL9nDOccaYucaYhcaY1xJbooiIiPRl3enZuBs4bXcvGmOKgT8D51hrDwAuSkhlIiIi4gldhg1r7evA1j2cchnwqLV2bfz8qgTVtk8+949ZXHr7zFSWICIiIh0kYs7GOKCfMeZVY8xsY8xVCbjmPgtHYzS1RVJZgoiIiHQQSNA1DgFOBHKAd4wxM621S3c90RgzA5gBUFFRkYCP7qQYnyEctUm5toiIiOy9RPRsVALPWmsbrbVbgNeBSZ2daK293Vo71Vo7taysLAEf/UkBn49oTGFDREQkXSQibDwGHG2MCRhjcoHDgcUJuO4+8fsN4VgsVR8vIiIiu+hyGMUYcz9wHFBqjKkEvg8EAay1t1lrFxtjngXmAzHgDmvtbpfJJlvQZ9SzISIikka6DBvW2ku7cc4vgV8mpKIe8vt8RDRnQ0REJG14bgfRoN8Q0TCKiIhI2vBc2PD7jHo2RERE0ojnwkbQ7yOiORsiIiJpw3Nhw/VsaBhFREQkXXgubAT8Rj0bIiIiacR7YcOnsCEiIpJOPBg23A6i1ipwiIiIpAMPhg0DoN4NERGRNOG9sOF3TdIuoiIiIunBe2Ej3rMR1ooUERGRtOC9sOF3YUM9GyIiIunBe2Hj454NhQ0REZF04L2wEZ+zofujiIiIpAfPhQ1/+2oU9WyIiIikBc+FjaBfS19FRETSiefCht/XvvRVwygiIiLpwHNhI6gJoiIiImnFc2Gjfc6Glr6KiIikB8+FjWB8NYo29RIREUkPngsb6tkQERFJL54LG+07iGrOhoiISHrwXtjw6UZsIiIi6cR7YaO9Z0NLX0VERNKC98JG+5wNDaOIiIikBQ+GDd0bRUREJJ14L2xou3IREZG04r2woRuxiYiIpBUPho32YRSFDRERkXTgvbDRPoyiHURFRETSgnfDhno2RERE0oL3wkb7MIp6NkRERNKC98KGejZERETSivfChk9hQ0REJJ14MGzo3igiIiLpxINho/2ur5qzISIikg48FzZ8PoPPqGdDREQkXXgubLDqdY71f0hYO4iKiIikBe+FjTd/y83+h4nqRmwiIiJpwXthwxckZCLq2RAREUkT3gsb/iBBopqzISIikia8FzZ8AQJEiWgYRUREJC14L2z4QwSJ6hbzIiIiacKDYSNI0ES0g6iIiEia8F7Y+HgYRWFDREQkHXgvbPiDBIjorq8iIiJpwoNhI0TAqmdDREQkXXgvbPgC6tkQERFJI94LG+3DKOrZEBERSQseDBsh/MSIRNSzISIikg66DBvGmDuNMVXGmAVdnHeoMSZqjLkwceXtA1/AfY+FU1qGiIiION3p2bgbOG1PJxhj/MDPgecSUFPP+IPue7QttXWIiIgI0I2wYa19HdjaxWk3AY8AVYkoqkd88bChng0REZG00OM5G8aYIcD5wG3dOHeGMWaWMWZWdXV1Tz+6c/GeDRuNJOf6IiIislcSMUH0VuAWa220qxOttbdba6daa6eWlZUl4KM7EQ8bRj0bIiIiaSGQgGtMBR4wxgCUAmcYYyLW2v8m4Np7Lz6MYqIKGyIiIumgx2HDWjuy/bEx5m7gyZQFDdgxQVQ9GyIiImmhy7BhjLkfOA4oNcZUAt8HggDW2i7nafQ6v3o2RERE0kmXYcNae2l3L2atvbpH1SRC+zCKVdgQERFJBx7cQbR9gqhWo4iIiKQDD4cN9WyIiIikA++FDZ96NkRERNKJ98JGvGfDpzkbIiIiacF7YSPes+FTz4aIiEha8F7YiPds+G2EWMymuBgRERHxbNgIECWisCEiIpJy3gsb8WGUIBGiChsiIiIp572w4Xf7lAVNlHAsluJiRERExINhIwS4YZRoVD0bIiIiqea9sOHbMWdDPRsiIiKp572wER9GCWnOhoiISFrwYNhoH0aJENEwioiISMp5L2z4tPRVREQknXgvbPjbl75GiUQ1Z0NERCTVvBc2jCFm/ARNRD0bIiIiacB7YQOwvqAbRtGcDRERkZTzaNgIENTSVxERkbTg0bARJKClryIiImnBo2EjQJAIYU0QFRERSTmPho0gQaLq2RAREUkDngwb+IIEjCaIioiIpANPho32ng0tfRUREUk9T4YN/EGCRLSpl4iISBrwbNjQduUiIiLpwZthwxfv2dA+GyIiIinnzbDhD2gHURERkTThybBh/CHdG0VERCRNeDJsuAmimrMhIiKSDjwZNkz7BFGtRhEREUk5T4cN7SAqIiKSet4MG4FQ/N4oChsiIiKp5s2wEd/UK6qlryIiIinnybDh87t7o7SpZ0NERCTlPBk2TCBESNuVi4iIpAVPhg38IS19FRERSRMeDRtBgiZCW0Q9GyIiIqnm0bCRRYiw7o0iIiKSBrwZNgJZBIgRCUdSXYmIiEjG82bY8IcAsNHWFBciIiIi3g4bkbYUFyIiIiLeDBsBFzaIqGdDREQk1bwZNvxZ7ntUPRsiIiKp5s2wEYiHDfVsiIiIpJw3w4Y/CICJqWdDREQk1TwaNtp7NhQ2REREUs2bYSM+QVQ9GyIiIqnnzbAR79kw2mdDREQk5boMG8aYO40xVcaYBbt5/XJjzPz419vGmEmJL3MvxffZ8EXDKS5EREREutOzcTdw2h5eXwUca62dCPwIuD0BdfXMx8Mo6tkQERFJtUBXJ1hrXzfGjNjD6293eDoTGJqAunrm42EU3RtFREQk1RI9Z+Na4JkEX3PvxffZ8KlnQ0REJOW67NnoLmPM8biwcdQezpkBzACoqKhI1Ed/UnyfDX9MczZERERSLSE9G8aYicAdwLnW2prdnWetvd1aO9VaO7WsrCwRH905f3vPhpa+ioiIpFqPw4YxpgJ4FLjSWru05yUlQHyCqHo2REREUq/LYRRjzP3AcUCpMaYS+D4QBLDW3gZ8DygB/myMAYhYa6cmq+Buifds+K3ChoiISKp1ZzXKpV28fh1wXcIqSoT4PhsB24a1lngIEhERkRTw6A6iAWL4CBIhGrOprkZERCSjeTNsAFFfiBBhIgobIiIiKeXZsBHzBQkRoTUSS3UpIiIiGc3zYSMcVdgQERFJJQ+HDTeM0qaeDRERkZTybNiw/hAho2EUERGRVPNw2MgiSEQ9GyIiIinm3bDhCxIiTGskmupSREREMppnwwb+ECH1bIiIiKScd8NGIIssowmiIiIiqebhsBHSPhsiIiJpwLthIz5BVGFDREQktTwbNnyB+D4b2tRLREQkpTwbNkwwyw2jhLUaRUREJJU8GzZ8gSxCRj0bIiIiqebdsBHMdnM2wgobIiIiqeTdsBEIkUVEPRsiIiIp5tmw4Q9m6UZsIiIiacCzYcMXzI5PEI2kuhQREZGM5tmwgT8Ln7FEwuFUVyIiIpLRPBw2ggBEw60pLkRERCSzeTdsBLIBiIVbUlyIiIhIZvNw2MgCwCpsiIiIpJR3w0YwB1DYEBERSTXvho32YZSIwoaIiEgqeT5sGIUNERGRlPJu2Ai6sIHChoiISEp5N2yoZ0NERCQteD5s+BQ2REREUsq7YSO+GsUX06ZeIiIiqeTdsBHfZ8MXVc+GiIhIKnk4bMR7NqLq2RAREUklD4cN17MR0DCKiIhISnk3bMTnbPjVsyEiIpJS3g0b/hAWQ8C2pboSERGRjObdsGEMEV+IoG0jGrOprkZERCRjeTdsAFFfNtm00RaJpboUERGRjOXtsOEPkUVYYUNERCSFPB42csgxrbRGo6kuRUREJGN5O2wEcsilldawejZERERSxdNhIxbIJYdW2qIKGyIiIqni6bBhAznkmRbN2RAREUkhb4eNoOvZaAlrzoaIiEiqeDtshPLJpZUWzdkQERFJGU+HDRPKJde00hJRz4aIiEiqBFJdQDL5svLIpoWWNoUNERGRVPF0z4Y/K48c2mgJR1JdioiISMbyeNgowGcsbS1NqS5FREQkY3k6bASy8wGItGxPcSUiIiKZq8uwYYy50xhTZYxZsJvXjTHm98aY5caY+caYKYkvc98EsvMAiCpsiIiIpEx3ejbuBk7bw+unA2PjXzOAv/S8rMRo79mItTamuBIREZHM1WXYsNa+DmzdwynnAv+wzkyg2BgzKFEF9oTJKnAP2ralthAREZEMlog5G0OAdR2eV8aPpV52IQCmtSHFhYiIiGSuRIQN08kx2+mJxswwxswyxsyqrq5OwEd3IbsIAF+rejZERERSJRFhoxIY1uH5UGBDZydaa2+31k611k4tKytLwEd3Icv1bATC6tkQERFJlUSEjceBq+KrUqYB9dbajQm4bs/FezYCYa1GERERSZUutys3xtwPHAeUGmMqge8DQQBr7W3A08AZwHKgCbgmWcXutWAOEfyEIurZEBERSZUuw4a19tIuXrfADQmrKJGMocmXTyiing0REZFU8fQOogAtvjyyFDZERERSxvNhozVQQHZUYUNERCRVPB82wsF8cmIKGyIiIqni/bARKqYgtg03tURERER6m+fDRiSrH/3MNprD0VSXIiIikpE8HzZiOf0pZjvbm9tSXYqIiEhG8nzYIKc/fmNpaqhJdSUiIiIZyfNhw+SVANDSsCXFlYiIiGQmz4eNQL4LG20KGyIiIinh+bARLHA3fItsV9gQERFJBc+HjayicgDs9qoUVyIiIpKZPB82cvoPAcC3PT1uRCsiIpJpPB828nJzqbaFhJo2pboUERGRjOT5sJEV8LGZErKbN6e6FBERkYzk+bBhjKHG9CevRXM2REREUsHzYQOgJlBGYdsm0P1RREREel1GhI3q4DByY9uhSbuIioiI9LaMCBs12RXuwZZlqS1EREQkA2VE2KjPHe4e1ChsiIiI9LaMCBvNeUNoIQSbF6W6FBERkYyTEWEjLzuLxYyC9bNTXYqIiEjGyYiwUZIXYnZ0NHbjPIi0pbocERGRjJIRYaO8MIs50dGYaCtULUx1OSIiIhklI8JGWX4Wc2Oj3ZPKWaktRkREJMNkRtgoyGI9pbRll8K691JdjoiISEbJiLBRXpANGDaUHAHLX4RYNNUliYiIZIyMCBtlBVkALCmaDs1bofL9FFckIiKSOTIibOSE/BRkBZgTmAK+ACx9NtUliYiIZIyMCBvgejfWtYSg4gj46OlUlyMiIpIxMiZslBZkUd3QCvufA1uWQPWSVJckIiKSETImbJQXZFG9vRX2P8sdWPx4agsSERHJEBkTNsoKsqhqaIHCwTD0UFiksCEiItIbMiZslBdk09gWpbE1AvudAZvmw7bNqS5LRETE8zImbAwuzgZgY30zjD7BHVz5auoKEhERyRAZEzaG9ssBYF1tMwycCLklsOLlFFclIiLifRkTNoYU5wJQWdsMPh+MOg5WvgLWprYwERERj8uYsFFekEXQb1hf2+wOjDoOtm+GLUtTWpeIiIjXZUzY8PkMw/rnsrJ6uzsw/Ej3fc3bqStKREQkA2RM2AA4cHARH66vd0/6j4L8AQobIiIiSZZRYWPi0CI21rdQta0FjHFbl699J9VliYiIeFpGhY1Jw4oBmL8u3rsx/EioXwd1a1NXlIiIiMdlVNg4YHAhPgPzK+vcgeFHuO9r1LshIiKSLBkVNnJDAcYNKGBuZbxno3wCZBfBmrdSW5iIiIiHZVTYAJhcUczctbXEYhZ8fhg2TZNERUREkijjwsaUin40tERY8fES2OlQswy2V6e2MBEREY/KuLBxyPB+ALy7aqs7MHy6+77mzRRVJCIi4m0ZFzZGluYxuCibN5dtcQcGT4HsYlj6fErrEhER8aqMCxvGGI4eW8bbK7YQicbAH4CxJ8PyF3SfFBERkSTIuLABcNTYUhpaIsxv3010xNHQWA01y1NbmIiIiAd1K2wYY04zxiwxxiw3xnyzk9eLjDFPGGPmGWMWGmOuSXypiXPkmFKMYcdQysfzNrQEVkREJNG6DBvGGD/wJ+B0YAJwqTFmwi6n3QAsstZOAo4Dfm2MCSW41oTpnxfioCFFvLEsvgKlZAwUDoGlz6W2MBEREQ/qTs/GYcBya+1Ka20b8ABw7i7nWKDAGGOAfGArEElopQl21JhS5qytY1tL2N0nZf9zYPlL0Lot1aWJiIh4SnfCxhBgXYfnlfFjHf0R2B/YAHwI3Gytje16IWPMDGPMLGPMrOrq1O5rcfTYMiIxy8yV8SWwE86BaKt6N0RERBKsO2HDdHJs12UbpwJzgcHAwcAfjTGFn3iTtbdba6daa6eWlZXtZamJNWV4MTlBP2+2D6UMO9zdcn7x4ymtS0RExGu6EzYqgWEdng/F9WB0dA3wqHWWA6uA8YkpMTmyAn6mjerPG+2TRH1+GH8WLHsB2hpTW5yIiIiHdCdsvA+MNcaMjE/6vATY9Z//a4ETAYwxA4D9gJWJLDQZjh5bxsotjVTWNrkD48+EcJPuAisiIpJAXYYNa20EuBF4DlgMPGStXWiMud4Yc338tB8B040xHwIvAbdYa7ckq+hEOXJMKQBvr6hxB4YdBsYH62amsCoRERFvCXTnJGvt08DTuxy7rcPjDcApiS0t+cYNyKckL8TMFTV8euowyCqAAQfCWoUNERGRRMnIHUTbGWOYNrqEd1bWYNu3Kq+YButnQzSc2uJEREQ8IqPDBsARo0rYWN/Cmpr4vI1hh7t5G5s+TG1hIiIiHqGwMboE6DBvo2Ka+77u3RRVJCIi4i0ZHzZGleZRXpDFOyvjYaNoKBQOVdgQERFJkIwPG8YYjhhdwjsrOs7bOBzWvZfawkRERDwi48MGuHkbW7a3sqJ6uzswaBI0rIemraktTERExAMUNtgxb+Od9nkbAw5w3zcvTFFFIiIi3qGwAVT0z2VIcc6OSaLl8bBRtSh1RYmIiHiEwgbx/TZGlTBzZQ2xmIWCgZDTTz0bIiIiCaCwEXf4qP7UNoVZuWU7GON2ElXYEBER6TGFjbgpFf0A+GBNnTtQPgGqFkMslrqiREREPEBhI25UaR6F2QHmrKt1BwZNgnAjbFmS2sJERET6OIWNOJ/PMLmi346ejeHT3ffVb6asJhERES9Q2OhgSkU/llZto6ElDP1GQOEQWPNWqssSERHp0xQ2OphcUYy1MH9dvZskOvxIWP0WtO8sKiIiIntNYaODgyuKMQY+WBuftzHiSGisgprlqS1MRESkD1PY6KAwO8iYsnzmtIeN4Ue575q3ISIiss8UNnYxpaIfc9bVuZuylYyG/AGatyEiItIDChu7mFxRTF1TmFVbGjVvQ0REJAEUNnYxZXh8c6+1de7AiCNh2waoXZW6okRERPowhY1djCnLpyArsGPexohj3PflL6WuKBERkT5MYWMXPp/h4IriHT0bpWOhbDwseDSldYmIiPRVChudmFzRjyWbGtjeGnHzNiacB2vfgcaaVJcmIiLS5yhsdGJyRTExC/Mr69yBsacAFla+ksqyRERE+iSFjU5MHlYMwJz2oZTBkyG3BJa9kLKaRERE+iqFjU4U54YYVZa3Y5KozwejT4DlL+qW8yIiIntJYWM3plT044O18c29AMadBk1b3NwNERER6TaFjd2YUtGPrY1trN3a5A7sdzoEc2HBw6ktTEREpI9R2NiNyRXFQIebsoXyXOBY+F+IhlNWl4iISF+jsLEb4wYUkBfy88Gauh0HJ14MzVth/kMpq0tERKSvUdjYDb/PMGlYMXPW1e44OPYUGDwFXvs5xKKpK05ERKQPUdjYgykV/Vi8cRtNbRF3wBg48maoWwPLnk9tcSIiIn2EwsYeTK4oJhqzfFhZv+Pg+LOgcAi8e1vqChMREelDFDb2YHLFLneABfAH4NBrYeWrUPVRSuoSERHpSxQ29qB/XoiRpXk7VqS0m3I1+LPgvb+mpC4REZG+RGGjC4eN6M/MFTWEox12Ds0rgYkXwbwHoLl2928WERERhY2uHD++nG2tEWat3iVUHPZ5CDfBu7enpjAREZE+QmGjC0eNLSXk9/HyR5t3fmHQRNj/bHj1/2Dtu6kpTkREpA9Q2OhCflaAw0f156WPqj754vl/dXeDffM3vV+YiIhIH6Gw0Q3H71fOyupGVm9p3PmFUB5M+Yzbc2Pb5s7fLCIikuEUNrrhxP3LATrv3Tj4MrAWXv5RL1clIiLSNyhsdMPwkjz2G1DA0x9u/OSLpWNh2hdhzr1Qt673ixMREUlzChvddPakQcxeU8uGuuZPvnj45933t27t1ZpERET6AoWNbjpr4mAAnprfSe9Gv+Fw2Ofg/TugvrKXKxMREUlvChvdNKI0jwOHFPLk/A2dnzD1WvddN2gTERHZicLGXjhr4mDmVdaztqbpky+W7Qf9RsLC//R+YSIiImlMYWMvnDVxEACPz1v/yReNcStTVr0O1Ut6uTIREZH0pbCxF4b2y+Wwkf35z5z1WGs/ecIh10BWETxzi1sOKyIiIt0LG8aY04wxS4wxy40x39zNOccZY+YaYxYaY15LbJnp4/zJQ1hR3ciC9Q2ffDG/DI7/Nqx8BT56sveLExERSUNdhg1jjB/4E3A6MAG41BgzYZdzioE/A+dYaw8ALkp8qenhjAMHEfL7eHTObladHHodlB8Az30bopHeLU5ERCQNdadn4zBgubV2pbW2DXgAOHeXcy4DHrXWrgWw1nay1aY3FOUGOWF8OY/P3UBrJPrJE/wBOOE7ULcWFj/e+wWKiIikme6EjSFAx60xK+PHOhoH9DPGvGqMmW2MuSpRBaajSw+voKaxjWcXbOr8hHGnuZUpM/+suRsiIpLxuhM2TCfHdv0NGgAOAc4ETgW+a4wZ94kLGTPDGDPLGDOrurp6r4tNF0ePKWVkaR73vL268xN8fph+I1S+Dx891au1iYiIpJvuhI1KYFiH50OBXXe2qgSetdY2Wmu3AK8Dk3a9kLX2dmvtVGvt1LKysn2tOeV8PsOV04bzwdo6Pqys7/ykKZ9xczeeuQVat/dugSIiImmkO2HjfWCsMWakMSYEXALsOhnhMeBoY0zAGJMLHA4sTmyp6eXCqUPJDfm5553VnZ/gD8JZv4GGSnj+O9DW2Pl5IiIiHtdl2LDWRoAbgedwAeIha+1CY8z1xpjr4+csBp4F5gPvAXdYaxckr+zUK8wO8qkpQ3h83ga2NrZ1flLFNDj8CzD7bvjlGJhzX6/WKCIikg5Mp5tT9YKpU6faWbNmpeSzE2Xp5m2c8tvXueW08XzhuNGdn2Stu1/K23+ANW/BdS/CkEN6t1AREZEkM8bMttZO7ew17SDaA+MGFDB9dAl3v72q82Ww4LYxH3cqXHIf5A+E/94Akd30hIiIiHiQwkYPffG4MWxuaOXfs7q4tXx2EZzxS6heDIse653iRERE0oDCRg8dOaaEKRXF/OXVFUSisT2fvN8ZUDwcZt3ZO8WJiIikAYWNHjLGcP2xo1lf18xTH27c88k+H0z7Aqx9290dVkREJAMobCTAifsPYPzAAn769Ee0hHczd6PdIVdDwSB49We9UpuIiEiqKWwkgN9n+M6Z+7OpoYXnFu5mC/N2wRyY/iW3MmXDnN4pUEREJIUUNhLkyNGljCjJ5a+vrSQW62I58eTLIZgH797eO8WJiIikkMJGgvh8hq+cPI5FGxt4fN6uu7nvIrsIDr4MFjwM9et7p0AREZEUUdhIoLMnDubAIYX86vklu993o930G92GXy9+X3eGFRERT1PYSCCfz/DN0/ansraZf76zZs8n9xsBx3wNPvw3zLm3V+oTERFJBYWNBDtqbClHjy3lj68sp745vOeTj/k6jDwWnv4arH6rdwoUERHpZQobSXDLaeOpawpz22sr9nyizw8X3AFFQ+HeC2Dzot4pUEREpBcpbCTBgUOKOO/gwdz55irW1zXv+eT8crj6acgqgIeugtZtvVOkiIhIL1HYSJKvnzYegJ8+vbjrkwsGwIV3wtYVcNfpULs6ucWJiIj0IoWNJBlSnMP1x47myfkbeW/V1q7fMPJouOhuqFsH/zgXWuqTXqOIiEhvUNhIouuPHc3gomx+8PhCol1t9AUw4Vy47CGoXQOv/yr5BYqIiPQChY0kygn5+dYZ+7NoYwN3vLGye2+qOBwmXQLv3a4Nv0RExBMUNpLsrImDOO2Agfz6+aWsrWnq3puO/zbYGLz0w+QWJyIi0gsUNpLMGMMPzz2AgN/wtYfnEYnGun5TcYW7Wdv8B2H1m8kvUkREJIkUNnrBgMJsfnTugby3aiu/f3l599509P9A8XD4z/VQ9VFyCxQREUkihY1ecsEhQzl/8hD+/MpyFm9s6PoNoVz49D1u340/Hw6v/xJi3egVERERSTMKG73oe2dNoCgnyDcfmd+91SmDJ8MN78EB58PLP4a/Hg13nQlv/T75xYqIiCSIwkYv6pcX4ntnT2BeZT13v726e28qGAAX3gXn/gkC2bB9E7zwXZhzX1JrFRERSRSFjV52zqTBnDC+nF89t4R1W7u5OsUYmHwFfO4luOF9GH4kPPctaK5NbrEiIiIJoLDRy4wx/Oi8A/EZ+PZ/PsTabgyndOTzwek/dzuMajhFRET6AIWNFBhSnMM3Tx/PG8u28LfubvbV0cCD4MAL4d3bYNvmxBcoIiKSQAobKXLFtOGcfuBAfv7sEmaurNn7Cxz/bYi0ulUqIiIiaUxhI0WMMfziwokM75/Ljf+aQ1VDy95doGQ0TLkSZt+tu8SKiEhaU9hIoYLsIH+54hAaWyPcdP8cYt1ZDtvRsbeAzw+v/iw5BYqIiCSAwkaK7TewgB+cM4F3V23lzrdW7d2bCwfDYZ+DeQ/AxvnJKVBERKSHFDbSwKenDuOUCQP4ydOLeX1p9d69+aivQl4ZPHA5rHojOQWKiIj0gMJGGjDG8LtLJjO2PJ+vPDiXzXszfyO3P1z+kLtL7D1nw/IXYfY98NHTEG5OXtEiIiLdpLCRJnJCfv58+RSa2qLc+K8PaI1Eu//mwZPhC29B4RC49wJ44kvwwKXwz/OhrTF5RYuIiHSDwkYaGVNewM8vnMj7q2v59qML9m7Dr5xiuO5FOPl/4bKH4Mxfw7p33fBKpC1pNYuIiHQlkOoCZGfnTBrMyurt3PriMkaX5/HF48Z0/82Fg+DIm3c894fg8Zvgvdth+o2JL1ZERKQb1LORhm4+cSznTBrML55dwkPvr9v3C025CkYdD2/d6jYAExERSQGFjTRkjOGXF03kmHFl3PLofF5a3IMtyY/8EjRWw4JHE1egiIjIXlDYSFNZAT9/veIQJgwq5MsPzmX1ln2c6DnqeCgbD+/+Bfb2pm8iIiIJoLCRxnJCfm674hD8PsPn/zmbxtbI3l/EGDj887BxHqx5O/FFioiIdEFhI80N65/LHy6dzLKqbXzjkfl7v6U5wMSLIX8gPDoD6nowB0RERGQfKGz0AUePLeOW08bz1PyNfO3heUSisb27QCgPLv83tDbAHSfByleTUqeIiEhnFDb6iBnHjOJ/Th7Hox+s50sPzCG8t4Fj0ET47LMuePzjXHj5x1qhIiIivUJho48wxnDTiWP5f2fuz9MfbuJL988hurdDKgMOgOvfhAM+Ba//Eu4+C1q3JadgERGROIWNPua6o0fx3bMm8MyCTfzoyUV7f4FQLlx4J3zqb7B+NjwR3wTMWmhrSmyxIiIiaAfRPunao0ayoa6Zv7+5iuEluVxz5Mi9u4AxMPHTULsaXvmJG06pWws1y+Hyh2HEkUmpW0REMpN6Nvqob5+xP6ceMID/fXIRLyzax02/jvoKHHEjLHsBomF3l9j7L4HaNYktVkREMprCRh/l9xluvXgyE4cU8aX75/D2ii37cJEgnPoT+H+b4YaZcPM8iLbBqz9LfMEiIpKxFDb6sJyQnzs+cyhD+uVw1d/f4/731u7bhYxx3/sNh0Ovg/kPwDt/hhWvaNdRERHpMYWNPq6sIItHvzid6WNK+dajH/KnV5b37IJHfRUGHgTPfQv+eZ7bCCwaTkitIiKSmboVNowxpxljlhhjlhtjvrmH8w41xkSNMRcmrkTpSmF2kDs/M5WzJg7iNy8sZfaa2n2/WF4JzHgNvjjTzen48CG47yLN4xARkX3WZdgwxviBPwGnAxOAS40xE3Zz3s+B5xJdpHQt4Pfxf586iIGF2Vz6t5k8v3DTvl/MGCjfH076AZz9O1j3Htx+LGxakLB6RUQkc3SnZ+MwYLm1dqW1tg14ADi3k/NuAh4BqhJYn+yFwuwgD8yYxrgB+dx4/xwem7u+5xc95Gr4/OvgC7itztd/0PNriohIRulO2BgCdLx7V2X82MeMMUOA84Hb9nQhY8wMY8wsY8ys6urqva1VumFY/1z+8dnDOXhoMTc/MJffvLAU29NJnqVj4PNvQF4ZPHA5bOtBr4mIiGSc7oQN08mxXX973QrcYq2N7ulC1trbrbVTrbVTy8rKulmi7K3+eSH+ed1hXHjIUH7/0jJ++8LSnl+0cBBc+i9oqYNHrtMqFRER6bbuhI1KYFiH50OBDbucMxV4wBizGrgQ+LMx5rxEFCj7Jivg55cXTuTTU4fy+5eXc9dbq/bt9vQdDTwITvsprH4D/vtF2LoyMcWKiIinma662I0xAWApcCKwHngfuMxau3A3598NPGmtfXhP1506daqdNWvWvtQseyEcjTHjH7N4ZUk1Y8vz+dkFB3HI8P77fsFYDF74Lrx7G8Qi0G+EW7VyyNWJKllERPogY8xsa+3Uzl7rsmfDWhsBbsStMlkMPGStXWiMud4Yc31iS5VEC/p9/O2qqfzukoNpiUS5/I53eW1pD+bL+Hxu19Evfwgn/RDyyt3N3Ja9kLiiRUTEU7rs2UgW9Wz0vprtrVz59/dYXrWdP1w2mVMPGNjzi4Zb3LLYho1w0Z0w5qSeX1NERPqcHvVsiHeU5Gdx/+emMWFwIV+874PELI0NZsOn/wmFg+H+y+C1X7qhFhERkTiFjQxTlBvk3usOZ+rwfnz5wbl8978L2NbSw+3Iy8bBVf+FcafCKz92czpERETiFDYyUH5WgLuvOYxzJw3mnzPX8Jk73+t54CgYCJ/+B0y9Ft75Iyx9HipnQ3NdQmoWEZG+S3M2MtyzCzZy47/mcOCQIv521VTKCrJ6dsHWbXD78VCzzD3PK4frXnCrVkRExLM0Z0N267QDB/Hbiw9m7ro6jvzZy7yypIe7zWcVwNVPwan/5+6rEm6CJ7+qTcBERDKYwoZw9qTBPDBjGsNLcvns3e9zz9urifZkA7CCAXDEDW7vjRO/BytegvsuhCXPKHSIiGQghQ0BYNqoEh678UgOH9mf7z++kC/cO5uW8B53n++eQ69zoWPV63D/JXDP2bD8xZ5fV0RE+gzN2ZCdRGOWu95axU+eXsx+Awr4/aWTGTegIAEXDsOsu+D1X0JjNUz8NARz4ZQfuaEXERHp0zRnQ7rN7zNcd/Qo7rz6ULZsb+XsP7zJP95Z3fM7x/qDcPgMuHkejD0F5j8Is++Cf13sNgYTERHPUtiQTh2/XznP3HwMR4wu4XuPLeSzd79P9bbWnl84lAuXPwTf2QSfugPWvAXPf0dLZEVEPExhQ3arrCCLu64+lB+ecwBvr6jhtFtf56XFmxNz8WAOTLwIJl8J798Bv94PFj2WmGuLiEhaUdiQPTLG8JnpI3jipqMoK8ji2ntm8dOnFxOOJmhL8nP/CDNedftwPPU12Lpqx2vh5sR8hoiIpJTChnTLuAEFPHbjkVwxrYK/vr6SM373Bh+srU3MxQdPhgv+DrEw3H8p1K11weNnFfDhw4n5DBERSRmtRpG99uKizfzgiYVsbmjhW6fvz9XTR+DzmZ5fePlL8K9PQyyy41hWEXxpDuSV9Pz6IiKSNHtajaKwIfukvinMVx+ay0sfVXHEqBJ+ceFEhvXP7fmFN8yBFa/AiKMglA9/OQIOmwGHfg5Kx4JJQKgREZGEU9iQpLDW8tCsdfzoycVYa/nOmRO49LBhmEQGgvsvhSVPu8cTzoPzbwN/Fvg0Aigikk4UNiSpKmubuOWR+by1vIZjxpXxk/MOZGi/nMSEjnALLH4cNi+At37njhUMhkvugyFTen59ERFJCIUNSbpYzHLfu2v4v6c/ojkcZdyAfP557eEMKMxO3Id89JTb9nzxE25H0s+9BMUVibu+iIjsM4UN6TWVtU088N46bn99JTkhP3+7aiqHjeyf2A+pXgJ3nAxFQ+Czz0J2UWKvLyIie03blUuvGdovl6+duh9Pfuko+uUGueT2d/jLqyvY3hrp+s3dVbYfXPwP2LIU/n216+UQEZG0pZ4NSZrtrRFuvn8OL31URV7Iz4/OO5BPTRmauA/44B/w+E1w4AUw4AD48BEYPh2O/zbkJrg3RURE9kjDKJIy1lrmrqvjp898xHurtnLFtApuOW08BdnBxHzA67+Cl38MWOg/ym0INmgSXPeSlsmKiPQihQ1Juea2KL96fgl3vrWKgYXZfOfM/Tlr4uDEXHzrKmipg0EHwwf3wBM3ux1JD7owMdcXEZEuKWxI2vhgbS3/7z8LWLSxgZP2H8BXTh7LAYMTOMEzGoE7T4GqxW4zsP3PcUtk1cshIpJUChuSViLRGLe9toK/vbGKbS1hrjpiBF89ZRyFiRpa2bYJnvgyLHsebBRCBe5Gb+f9GQZNTMxniIjIThQ2JC3VN4f59fNL+OfMNRTlBPnOGftz4SFDE7cDadNWWPocrHgZVrzk7rky7YuQVQiTLtEkUhGRBFLYkLS2YH09P3h8IbPW1DKmPJ/rjhrJBYcMJehP4Mrs2jXwz/Nh6wr3vGAQnP07GHE0hBJwTxcRkQynsCFpLxyN8cS8Ddz51ioWrG9gckUxV08fwdkTByfmjrIAsaj72vwh/PsaqFsDeWVw5X9g4EGJ+QwRkQylsCF9hrWWRz5Yz7cenU84ajl6bClfPmkshwxP8JBH7RqYe5/bqwPg3D/CmJMS+xkiIhlEYUP6nIaWMA++t45fPb+EcDTGTSeM5bqjRyZuf452G+fDvZ+CxmrIHwhn/QbGn5nYzxARyQAKG9JnbW+N8M1H5vPk/I2UF2Tx5ZPG8akpQ8gO+hP3IZE2mPV318tRtQgOuQZO/QmE8hL3GSIiHqewIX3enLW1/OCJRcxbV0d5QRZfP3U/LpgyNHHzOcCFjld+DG/9HkpGw2k/g6GHQk5x4j5DRMSjFDbEE6y1zFy5lZ8/+xFz19VxwOBCrpg2nAMHF3HgkMLELZld+Rr894vQUAm+gFsuW7MCmmth3Ckw70Fo2ABTr4GTfqANw0REUNgQj7HW8vi8Dfzi2SWsr2sG4NQDBvCLCydRlJOgOR1tTbDqdTeJdPHj4A9BdjE0VrkVLNE2aKmHI78MJ/8wMZ8pItKHKWyIJ8VilnW1TTz14UZ+8/xSBhfn8KuLJnHYyASvXNm6CgJZkNMP1s6EkceA8bl7sHzwD/j8a+7mb9Ew1Fe63UrV2yEiGUZhQzxv1uqt3HT/HDbWt3DYiP5cecRwTjlgAFmBBE4k3VVLPdx6kLsB3Kf+BvecDVuWuI3Czv8rFA1J3meLiKQZhQ3JCE1tER54bx1/f3MV6+uaKS/I4punj+f8yUMSN59jV7Pugie/7B4HcmDqZ2H23W4ly2efdRNNRUQygMKGZJRYzPLG8i385oWlzFtXx8HDivnqyeM4emxpckLHiz+Ej56EU38KY09yd5y9+0wI5roJpIv+C5sXwem/cK+LiHiQwoZkpFjM8vDsSm59cSkb6ls4eFgx1x09kjMPGpS8no52G+bCg1dC/VrIKgKD6/m4aRZkFST3s0VEUkBhQzJaayTKv2dVcuebq1i5pZH9BxVy+eEVHD22lOElSdy4q6XBrWgZeTRsWQ53nAhH3OA2DBMR8RiFDREgGrM8+kElf39zFR9t2gbAFdMquOH4MQwqykl+AY/fBHPuc/M6Ns6FkjFw9u/dypXqJVA2HvyB5NchIpIEChsiHVhrWbSxgX/PquSed1ZjLRwzrozrjx3FEaNKkjfE0lwLD3/W9XYUDHZDLBMvga0rofI9KBkLn74HBhyQnM8XEUkihQ2R3VhRvZ0n523knzNXs2V7G5OGFXPN9BGcuH954m/61s5a15vxwvfgrd+5PTsOvhyWPe9WsXzhbQjupqel/e+r9vEQkTSjsCHShZZwlIdnV/K3N1aypqaJkN/HUWNLueTQYZw8YUDyeju2rnS7kxYNhZWvwj/OhaO/Bid+1wWL6o8grxzyStz5D1zujl3+MPQfmZyaRET2gcKGSDfFYpY562p55sNNPLNgE+vrmtlvQAFnTxrEFdOGU5wbSm4Bj34eFjwM5/4JKmfB+39zwytfeBvWz4K7TnfnHfApuOiu5NYiIrIXFDZE9kEkGuPRD9bz0Kx1zFpTy6jSPK47ehRnTxqUvCGWxhq46zTYstQ9L66AurUw5iSoW+fmfUz8NLzzRzj3zzD58p3f37DRbTJ23Ddh8OTk1Cgi0gmFDZEemrmyhq8/PI91W5vxGThqbBkXT3VDLKGAL7EfFm6BDR8ABiqmwTt/gpd/DMFst3plvzPg3vNdz8eMV6Fsvx3v/fc1sPBR6D8abpqtuR0i0msUNkQSwFrL7DW1vLi4isfmrmdjfQtD++XwheNGM6WiH/sPKkzeh0fa3O3uffFg07AB/jId2hrhwAthzIlQMMjtXJpX5u5O+9nnXFixFtZ/APnlUDzsk9du2upuMqdgIiI9oLAhkmDRmOXVJVX8+vmlLNrYALjb3F92+HCOGFWS+N6OztSuhrd+D3PuhWirO1YwGD77DPzlSJhwHpzxC3joKlj+Iviz4KrHYPgRO65RtRhuOwpGHgtXPuqORdqgqQYKByW/DSLiGT0OG8aY04DfAX7gDmvtz3Z5/XLglvjT7cAXrLXz9nRNhQ3xgljMMnttLW8u28Ltr6+kORwlPyvAOQcP5qojhjN+YBJ7Oz4uIgqLHnMBYfyZUDgYHrsR5j3gejZWvwHHfAPmPwDZxfD513f0Yjz3HTf/A+DmedBvBDz9DXjvr3D+7TDp4uTXLyKe0KOwYYzxA0uBk4FK4H3gUmvtog7nTAcWW2trjTGnAz+w1h6+p+sqbIjXtISjvL1iC0/O38hT8zfSGolx2Ij+XHHEcE4YX05+Vi/uDlpfCQ9e4SaVTr4cTv5f+OAfbhfTU34C0290wye/m+QmoW5eAGf8Cg69Dm6d6DYcG3ksfObx3qtZRPq0PYWN7vz0OwxYbq1dGb/YA8C5wMdhw1r7dofzZwJD971ckb4pO+jnhPEDOGH8AL575gT+PXsd985cy5fun0PAZzh0RH9uOH4M00eX4PMleX5E0VA3ebSj9o3DXvy+m/+x4QNo3Qaf+hs8cJl7beQxLmiE8mHN27BtExQMTG6tIuJ53RlYHgKs6/C8Mn5sd64FnunsBWPMDGPMLGPMrOrq6u5XKdLH9MsLMeOY0bz6teP41+cOZ8Yxo1hd08gVf3+XaT99iR89uYjF8bkevcbnh7N+B6X7wbO3wPwHYdIlMGACjDvVbaP+6k8B4zYNA3jt571bo4h4UneGUS4CTrXWXhd/fiVwmLX2pk7OPR74M3CUtbZmT9fVMIpkmpZwlGcWbOTZBZt4+aMqwlHLhEGFnHPwYMYPLODosWX4k93jAW6Ox4a5ULUIJl4MgRDUrIC/HQ8t9TDuNLjsQXjiZnfjuHP/BPudBtVLYcEjbk7IYTMg3AS5/Xe+dtNWWPMWVBwBeaXJb4uIpI2eztk4AjcH49T4828BWGt/ust5E4H/AKdba5d2VZTChmSyrY1tPDFvA498UMn8ynoAhpfkcvGhwxhZkkdjW5SzJw0iK+DvxaJWwqLH3V1pswvdZmL3nAO1q3ac4wtALOIeB3Lgi29D/1Fuee0bv4I3fgvhRigaBjfOcnuDgAs4vl5si4j0up6GjQBuguiJwHrcBNHLrLULO5xTAbwMXLXL/I3dUtgQcTbVt/D+6q38c+Ya3lu19ePjFf1z+eWFEzl8VEnqiouGYfETsGk+lMeHW+bcB0uedqtcxp8Fl9wHb/8Bnv9/kFsCUz4Db/4GzvwNHHotrH0X7r8YDrwATv/ljr1CRMRTErH09QzgVtzS1zuttT8xxlwPYK29zRhzB3ABsCb+lsjuPrCdwobIJy1YX0/1tlYslh8+sYg1NU2MH1jAhYcM5YTx5Ywqy091iTu88Rt46Ycw+kRY8RLsfw5cdLe7i+0dJ0JjNVz5X3c/l+2b3XuO+5bbSl1EPEebeon0QY2tER58fx3/mbOeD9e7oZZJw4ppbotwzqTBXHf0KLKDKRyaiIbhqa/C0udh4IFw8X07hk1WvQH3XrBjs7EZr8Jbv4Olz8EXZ0K/4e54SwO88D23g+lJ399x7fpKNzSTWwI2BllpFLJEpFMKGyJ9XGVtE4/N3cDzCzcRCvh4f3Ut5QVZnDRhAMeNK+PwUSUU5STp5nD7qnIWPPstd0O4M36xYxJqbgkc/T/Q1uTu47L2HXf+De9D2Th481bXY2Jj7njZeBdWgjmpaomIdIPChojHvL18C3e9vZq3l2+hsS2Kz8C0USWcM2kw+dkBBhVlc8jw/l1fqLetfRfuuwhaXU8NgWw46QduvsfEi918jztPgbGnQP16qIpPDTvpB26Y5p/nQ7gZDrkajr0FbBQCWSlqjIh0pLAh4lFtkRiz19Ty1vItPD5vA2u3NgFuN/KT9h/ApKFFTBxazJFjSntnWW13tG6HbRuhbbu7eVzBwJ23Tc8rc1unh/Lc83svgHXvQeEQ2LIURh0LK17ecb3RJ8AxX3dLeQ/41CeX43Zm80K3Yia7F7aTF8kQChsiGcBay/Kq7TS2RXnw/XXMXFnDqi2NAJQVZDG2PJ+LDx3GqQcMTO1cj85EwzDrLrer6aHXwdAOP6/qK+GOk1xAmf4lOOVH8O9r3BDMyGPc/BDiP8fKxsN1L7k5HstecOFk6rU75pKACxp/mQ555fDl+TsPz0Ta4IN7XLAZf0avNF3EKxQ2RDJUQ0uYlxdX8fJHVcyvrGN1jev5yAv5mTaqhE8fOoyV1Y2U5oe4YMrQ5G+jvq/q1sLKV92W6z4/tDXCxvnuDrY1K+DDf4Pxwys/hnP+AGX7w99Pcu89/Ho4vcNOqP+6GJY+6x6fdStMvWbHay98H9661T0+6Ydw1JeT3zYRj1DYEBFiMctry6pZuL6ezQ2tPLdwE1XbWj9+/dhxZVxz5AgOHdGfFxdvpjAnyPH7laew4r1kLfzpMLcLqvGBLwgjj4a598Eh18CBn4LlL7kwceL34aOn3EZmX3gbmmth5p9hzr0u0ITjk1eve2lHL8v2ahdSRh0HxcN2fG7DRtfrMmTKjmObPoSSMZrUKhlFYUNEPqEtEuM/cyopzA5Sta2Vnzy1mLZobKdzfnjOAZx38BCKctNspcvuVM6CR651jy/4Oww4EB67ARY9BrGwOz75Sjjrt1C7Gv56THzVi4FIM4w9FS66y+14+vuD3bDKQRdA9RLXkxJudPNMrvwvlO3nwsf9l7jrXvOs2131w4fcHXbHnASX/KvrCaybPnRhZ+QxyfkzEeklChsi0qUNdc3MWlPLU/M3cP7kIfz2hWUs2bwNn4GDhxVz7LhyjhhdwqiyPErz+9gKkLYmtxNqcYUbemm3+El47IsuZJz8Q3ffl3bVS+HBK2DLEhgy1e0NMvoEeOabbnJr/5GuZ8T43aqYzky9Fs76zY7nW1fCw9e6nVXHngJPfBmWPOVeO/PXbr5Ku43zIKf/zr0oImlMYUNE9lokGmNeZR2vLanmtaXVzF9fT/uPi/0HFXLQkEKOHFOKMYZJQ4sYXpKX2oL3lbVu+U5nohE3LJPXYcv4xhqY+SdY8w5MONcFh20b3UTVQJYbdike7npU5t7nelgOvAAiLe5eM5Xv7biWL+hW0mz4wG14dvNc6DcCPnzY9dD4gnD9m1A+Ppl/Ap9UX+lCVOGg3v1c6dMUNkSkx7Y2tjF3XS2LN27jnRU1fLC2lqY29y96n4FDR/Rn7IB8xg8sZEhxDtPHlPTujeTSTc0KuO9C15sxeDKE8t39ZD71N7f65v073DyS6Te5CbC3HgQHXggV0+Dpr7telu1VkF0El/97x5yQravg5R+5EHTUV2DEUW7+SVMNHHxFz+89U7MC/nS4m/dy87w9B45YDF76gXvPeX92tUrGUtgQkYRraAmzqrqRUMDHg++v49UlVVRta/04gBRmB5hc0Y9RZXnUNrZx6gEDOe3AgZjd9SJ4USwG8+6H134OdWvg6K/Bid/t/NxnboF3b3OPBxwE1z4H1R/Bg1e6uSAX3wf161zQ2F7l9iFpa3I9K+0raKZ+Fiqmw6pX3XyT4dPhgPPckNCTX4ExJ7qlwwBNW+HRGbBtE1z6LzfEBPCfL8C8f+2o68gvu/vZdDbZdf6/4dH40M9RX915y/l22zYD1u2nIp6msCEivaItEqO2qY1FGxt4Yu4GXl5SRV1T+OPXxw8s4Nj9yhhanMOU4f0YP7AwfTYbS6ZoBFrqIK90z+dtWQ41y9xk0fZNzaoWu43NGta751mFcNmDbqjm9uOgsQqGHAKDp8D7f3PnhAqgbduOx+GmHfNKzvy12/zstqOhodIdO2wGnPFLiLTCL8fAhHPcEM7su9zrB18B5/1p51pjUdcD4g+5YaaGjXDj+zsPSVXOcjfiC+bA5193Q0S7U7vGDUcNO/yTw1rRCDzzDTdEdfBle/4z3J1YFNa8DUMP3XnfFUkYhQ0RSZmV1dsJ+n28urSah2etY9HGBsJR93OnIDvAkOIcjDFcd9RIsoI+xpYXMG5Afmb1gHSl6iPX6zF8Oow7dcdwRX2l+4U+9mQI5sKGOe5uuyOPcUMbNcvh1Z9BawNc+R949puw+i03JFP5vjs291+w4BG44hG3f8n9l8Dlj7idWtfPhiVPu5voXf+mWzmz6nU3hBPKdytvLrrHhZn/fgHGneaWDk84x9V391lu6AhgylVwwvfgma9D/kDXjtHHuzkzL/8Y3vytC0RTr4UzfuXuJFxc4Vb9vPNneO5b7jpfeGdH+xc87DZnO/jSHX9WG+e5oDRgws5/hrPudL07eWVuNdHAA3e81r5vS8W03c/fSVd1a13v0bBD3XNr3RLucJNbeRXK7bVSFDZEJG1Ya6msbWb2mlreWVHD4k0NzK+s3+mckaV5FOYEmTikiKH9cjjn4MEUZgfJywqkqOo+zFo3DOMPul/Ed5zs7sZ7yk9g+o1uOOWuM9wvrawCN5H168vd+eBe/93BO+5n09HES+D8+NDPqz+DmX9x5x02A8onwJNfhhO+6+atLHrM3YSvbs2O91//putNueNEN4k2mON+UZYf4O6L4wvCVxfB308BX8AtEQ43ua+Ozv6du1/OshfcPJlgHnx1oVuyHG6G0nHwwKVuq/ymGjfP5ZL7drz/31fDwv+4cHP+7TuvWNowx/U4HXA++Lv4/69qsVtKPeCAnf/837/DLZkeewoEQp2/d+Vrruen/Y7I3bFlmQt00Vb4xioXlN78Lbz4A/f6yGPh8od3/5kJprAhImltW0uYzQ2thKMx3l1Zw5vLt7C1sY0P19d/3AsCUJIX4sgxpUwYXMj+gwqZUlFMQXYf2QMkXTRsdL+cOg5pbNsEj9/kekKO/h+YfMXO7/noKXj086434qzfuiGephrXS9CxJyAacb0n7cM5/Ue5/UfCTXD7sa5H5MTvwZSr4XeT3BJirOsl+epiF3ae/RbM+rv7hb1hjhs2am2AT93hejne+LXr2SgZ43po3vg1rHjF9cSsfHVHLf1Hw9YVO7fjrN+69r/+C7juZRh6iGvbA5e5LeoxbmLsTbNg0eMw/wFY/qJ77/Sb4JQfu8Dy4OVuuOeIG3b0smxeBH+Jh5QZr7pJwQAzb4Nnb3GPhx4K5fu7EFRxhNtczudzvUv//QLklrpQM+VK175QJyu8omF45Do3JNRYzcdb9d88zw1p/W6S62Eae7L7bzrhPPj0PRBucfcUGnvyjiCZYAobItJnrdrSyDMLNrKhrplN9a0s2lDPhvoWwK2CKcnPYlRpHmPK8zlwSBFNbVHaIjEuOGQI5QUam0+YSJvbKt7XxQqjWAze/Yv7ZT/2lB2rY+rWwvwHYdoNrmt//WyY94ALIAdf7sLCrl76EbzxKxdqvrKw8w3SWurdv+43L4TSsXDBHS58vHUrDJvm3tOwwX3mJfe7IZM/TIFom5sw+9HT7p46M16BZc+7vVWyi90cG1/AhYrsYrcfyshj3E6y1YvdZw88yM2VWfM2NG91Acz4XZC7+ikXRH4/GcrGuV/6T3/dXXPAAW65s/G7z33+u7DqNTf3ZvNC17sUyIGL7ob9Ttu5ve3LoosrYPSJbpfchz8LF9/rJg4/9VW44T0XzF77pdvC/9IH3XDYB/e4PWMuvHPvelC6SWFDRDylrqmNRRsamLlqK+u2NrFqSyPLq7azvTXy8TlBv2HysH5UlOQyvH8uBdkBhvbL5ZhxZYSjMbKD/syYnNqXxaJu+GXYYVA0dPfnWeuGL7oKQu3q1rl75FQtdMM3Z93q7gAci8FTX4F5D8Kx33ArcXw+NxTz9h/cnYl9QZj2BRdy3vmj++whh7ghnuO/7XpI7rsQ8ge4oFO1GK56zIWpxi2u5yS7CP5x7o75LOCWMZ/0AxcYFj0G7//dhZqiYW4ZdPn+bmLvo5+DnH5u7kp7bT8b7oaRtq5wNx+8eb7rcYq0wW1HumPgQlBzLVxwJ4w9aZ/+k+yJwoaIeF40ZtlQ10wo4KOpLcq9M9cwv7KONTVNO90DpiA7QFNblLL8LM6bPIQRJbnkhPyccdAggv4e7lEhfUc07JYWDziw+5NCI60uLLQPQ2zb5Hon8st2Pm/JM/DYjW6Oysn/+8neiXb1613oaKqBL86EggE7Xmvd5u6EvHEubJjrJgNHW91E4Ote2nkC7INXuB1yAY77Nhx3y47Xale7HqSsQjj88+66OcXda+9eUtgQkYzW3Balrtn1hrywaDMxa9myvY3XllYTjbmfgaGAj4GF2QR8hvrmMMeOK+O48eUcNKSIYf1yCCiISDKEW9zcla6WRdethdn3uKGpisN3fm3de24Sbf9Rbr5IdmHSyt0ThQ0RkU7UbG9le2uEZZu38/7qraza0kg4GiMvK8BrS6vZ1uKGZYJ+w6jSfMoLsyjMCTJ5WDEV/XMZXJxDQXaAtkiMMeVarispVLPC9aQkqdeiOxQ2RET2UjRmmb2mljU1jayobmR51Ta2bG+jqqHl4wmqHQ0qymb8wAKKcoLkhAKMLM1lZGk+R44pITekJbvifXsKG/obICLSCb/PcNjI/hw2sv9Ox6211DS2saGumQ11zVRvbwPgrWVbWLO1icUbt9EcjlLfvGPn1NyQn6yAj4lDiwn6DROHFnPQkCIGFGZjjPus4SW5mX0vGfE09WyIiCTBpvoWFm2sZ9GGBmqbwmxrCfPmsi1sa4mwrcOqmXa5IT+Hj+xP/7wsxg8soCA7QHbQz9gB+Ywuyyfk9xGzVnNHJG2pZ0NEpJcNLMpmYFE2J4wf8InXtmxvZU1NE5sbWrAWIrEY763ayvurt7JoYwOPfFC50/k+4yawRmOWI0aXMqo0j+EluQwszKa80H1OeUGWVtNI2lLYEBHpZaX5WZTm77xB1bkHD/n48ZbtrTS2RmiNxFi2eTtLN2+jvjlMWzTG3LV1zF69lcb43XXbGQNl+VkMKs5hUGE2+dkByguyGF6SS15WgIOHFVOUE6QtEsMYQ/+83tnCWgQUNkRE0k7HMDJuQAFnMmin1621bG1sY3NDK5u3tbC5voVNDS1srGthQ30zy6u309AcZmtjG5FY50Pl+w0oYGi/HHJCfoYU51CUG2RbS4SBhdmMKc9nc0MLR44pZUChdmGVnlPYEBHpY4wxlORnUZKfxQR2v6dCU1uE2qYwW7a1snBDA9tbwwT9PprDUWau3MrG+haa2iI8v2gzbZEYAZ/5RDgpL8hiRGkeWKhvDnPc+DLGlhdQ0T+XQUXZbG+NsHBDA/1yg5wwvlzLf6VTmiAqIpLhrLU0h6PkBP0s2byNjfUtlOVn8drSalZtaWTVlkYiMYvfwPzK+t32lgzrn8PgohxCAR+t4RjD47uzBv0++ueFGFGSR2l+iMHFOQwozCYU0BwTL9EEURER2S1jzMd7gYwfWMj4ga635MAhRZ84NxyNsW5rE5W1zayvayY76OOgIUW8uLiKeevqqNnexraWCCG/j9eXVdMaiRGOxDqdY1KSFyIn5GdQUQ7D+uViraUgO0BZQRblhdn0zw1RlBskGrOU5IWIWRhdlqcVOX2QwoaIiHRb0O9jVFk+o8rydzo+prxgj+9btaWRbS1h6pvDH88t2dzQSnNbhCWbtzNzZQ3GQG1j2yeCSUe5IT8l+SFCfh+DinLw+wwjS/MI+AwDi7IxxlCzvZVJ8V1eY9YyqCiHfrlB1tQ0kZ8d+MTkXEk+hQ0REUm6kaV53T53a2Mb9c1hNje00ByOgoWqbS1kBfzMq6yjrilMc1uUTQ0tRGIxZq6sAaA1EuvW9ScMKmREaS7bW6MM7ZfDyJI8WsJRinODlBVkkZfl9jip6J9Lv9yQhnsSQGFDRETSSv+8EP3zQp0GlPMmD/nEsfa5h/XNYayFnJCfuevqqG1swxjDqi2NbNneyqCibJrbosxcVcNHm7aRHfAzb13dTru97soX3+E1K+CnX16QoN9HJGrplxciFrNMGFRIaUGI4hxXs99nKC/MIj/L3V14WP9cyguyMJDRwz8KGyIi0qe1r4Apzt2xd8i0USW7Pf8mxn782FpL9bZWCnOCNLSEqd7WSmOr226+Kr6sOBKzNLZGaGiJ0BqJEom6pcdNkRgvfVRFbVPbx3cP3pP8rAD98oIU5QSpbQwzoDCLkaX5NIcjDO2XC7i9UkoLQuQEA+SG/OSG/OSE/ORnBQhHLX6foSQ/RF4ogN9n2LK9lZrtbew3cM/DWKmmsCEiIhnLGEN5fC+R7KCf8oK931fEWktDS4T1tc2EAj6qtrWwvSVCTsjP2q1N1Gxvw1qoa26jtrGNhpYIpflZbG5o5Y1l1eSE/Ly0uAro/lBQTtBPXpafuqYwkZilrCALn4GpI/oT8BliFoI+w/6DChkzIJ+coLs/T9DvY1j/XIpygnvdzp5Q2BAREekBYwxFOcGPf4GPKc/v4h2daw8tWxvbaGqL0NwWpaktSlNbhMbWKAG/oaElwqb6ZlrCMZrDUdoiMbZsb2XVlkaG9sthfmUdfmPwGUNTW5RH56z/xOf85fIpnH7QoE4qSB6FDRERkTSwa2hJhKptLazb2kxrJEprOEZbNMbBw4oTdv3uUtgQERHxqPKC7H0aGkq0zJ0aKyIiIr1CYUNERESSSmFDREREkkphQ0RERJJKYUNERESSSmFDREREkkphQ0RERJJKYUNERESSSmFDREREkkphQ0RERJJKYUNERESSqlthwxhzmjFmiTFmuTHmm528bowxv4+/Pt8YMyXxpYqIiEhf1GXYMMb4gT8BpwMTgEuNMRN2Oe10YGz8awbwlwTXKSIiIn1Ud3o2DgOWW2tXWmvbgAeAc3c551zgH9aZCRQbYwYluFYRERHpg7oTNoYA6zo8r4wf29tzREREJAN1J2yYTo7ZfTgHY8wMY8wsY8ys6urq7tQnIiIifVx3wkYlMKzD86HAhn04B2vt7dbaqdbaqWVlZXtbq4iIiPRB3Qkb7wNjjTEjjTEh4BLg8V3OeRy4Kr4qZRpQb63dmOBaRUREpA8KdHWCtTZijLkReA7wA3daaxcaY66Pv34b8DRwBrAcaAKuSV7JIiIi0pd0GTYArLVP4wJFx2O3dXhsgRsSW5qIiIh4gXE5IQUfbEw1sCZJly8FtiTp2ulCbfSGTGgjZEY71UZvUBv33XBrbacTMlMWNpLJGDPLWjs11XUkk9roDZnQRsiMdqqN3qA2JofujSIiIiJJpbAhIiIiSeXVsHF7qgvoBWqjN2RCGyEz2qk2eoPamASenLMhIiIi6cOrPRsiIiKSJjwVNowxpxljlhhjlhtjvpnqenrCGHOnMabKGLOgw7H+xpgXjDHL4t/7dXjtW/F2LzHGnJqaqrvPGDPMGPOKMWaxMWahMebm+HHPtBHAGJNtjHnPGDMv3s4fxo97rZ1+Y8wcY8yT8eeeah+AMWa1MeZDY8xcY8ys+DFPtdMYU2yMedgY81H87+YRXmqjMWa/+H+/9q8GY8yXvdRGAGPMV+I/bxYYY+6P/xxKbRuttZ74wu1uugIYBYSAecCEVNfVg/YcA0wBFnQ49gvgm/HH3wR+Hn88Id7eLGBk/M/Bn+o2dNG+QcCU+OMCYGm8HZ5pY7xuA+THHweBd4FpHmznV4F/AU967f/VDm1cDZTucsxT7QTuAa6LPw4BxV5rY4e2+oFNwHAvtRF3x/VVQE78+UPA1aluo5d6Ng4DlltrV1pr24AHgHNTXNM+s9a+Dmzd5fC5uB8GxL+f1+H4A9baVmvtKty28Yf1Rp37ylq70Vr7QfzxNmAx7i+JZ9oIbndda+32+NNg/MvioXYaY4YCZwJ3dDjsmfZ1wTPtNMYU4v6R83cAa22btbYOD7VxFycCK6y1a/BeGwNAjjEmAOTiboya0jZ6KWwMAdZ1eF4ZP+YlA2z8Bnfx7+Xx43267caYEcBk3L/6PdfG+BDDXKAKeMFa67V23gp8A4h1OOal9rWzwPPGmNnGmBnxY15q5yigGrgrPiR2hzEmD2+1saNLgPvjjz3TRmvteuBXwFpgI+7GqM+T4jZ6KWyYTo5lylKbPtt2Y0w+8AjwZWttw55O7eRYn2ijtTZqrT0YGAocZow5cA+n96l2GmPOAqqstbO7+5ZOjqVt+3ZxpLV2CnA6cIMx5pg9nNsX2xnADd3+xVo7GWjEdbfvTl9sIwDG3cH8HODfXZ3aybG0bmN8Lsa5uCGRwUCeMeaKPb2lk2MJb6OXwkYlMKzD86G4riMv2WyMGQQQ/14VP94n226MCeKCxn3W2kfjhz3Vxo7iXdKvAqfhnXYeCZxjjFmNG7o8wRhzL95p38estRvi36uA/+C6mr3UzkqgMt7zBvAwLnx4qY3tTgc+sNZujj/3UhtPAlZZa6uttWHgUWA6KW6jl8LG+8BYY8zIeGq9BHg8xTUl2uPAZ+KPPwM81uH4JcaYLGPMSGAs8F4K6us2Y4zBjQ0vttb+psNLnmkjgDGmzBhTHH+cg/tB8BEeaae19lvW2qHW2hG4v3MvW2uvwCPta2eMyTPGFLQ/Bk4BFuChdlprNwHrjDH7xQ+dCCzCQ23s4FJ2DKGAt9q4FphmjMmN/5w9ETcnLrVtTPXM2UR+AWfgVjWsAL6T6np62Jb7ceNtYVzyvBYoAV4ClsW/9+9w/nfi7V4CnJ7q+rvRvqNwXXXzgbnxrzO81MZ4zROBOfF2LgC+Fz/uqXbG6z6OHatRPNU+3HyGefGvhe0/XzzYzoOBWfH/X/8L9PNgG3OBGqCowzGvtfGHuH/ULAD+iVtpktI2agdRERERSSovDaOIiIhIGlLYEBERkaRS2BAREZGkUtgQERGRpFLYEBERkaRS2BAREZGkUtgQERGRpFLYEBERkaT6/5QE6/oNLYHKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from matplotlib package import module pyplot allias plt \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "plt.plot(my_model_history['loss'])\n",
    "plt.plot(my_model_history['val_loss'])\n",
    "\n",
    "# validation loss function is still going down, but it starts going up and down. Somwere there we should to stop training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21e7a8a9730>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAIICAYAAADHZSyIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABh1klEQVR4nO3dd5wkdZ0//te7qsNMz8zmYXMgLGFBCa5kREQJ4snpGQieWY47xXR3P/X05+/ue+dXPfWCJ8qhYkQxKyrBBIICwiI5LCzLsiy7y87miR2qPr8/PvWprqqu7umZ7Z6aqX49H495THdVddXn06ne/f6EEqUUiIiIiNrFSroARERElG4MNoiIiKitGGwQERFRWzHYICIiorZisEFERERtxWCDiIiI2iqT1IEXLFigVq1aldThiYiIqIXuvffenUqp/rh1iQUbq1atwrp165I6PBEREbWQiDxTbx2bUYiIiKitGGwQERFRWzHYICIiorZisEFERERtxWCDiIiI2orBBhEREbUVgw0iIiJqKwYbRERE1FYMNoiIiKitGGwQERFRWzHYICIiorZisEFERERtxWCDiIiI2orBBhEREbUVgw0iIiJqKwYbRERE1FbjBhsico2I7BCRh+usFxH5vIhsEJEHReSE1heTiIiIZqpmMhtfB3Beg/XnA1jt/V0G4EsHXiwiIiJKi3GDDaXUbQB2N9jkQgDfVNpdAOaIyOJWFZCIiIgOnFIKSqlEjp1pwT6WAng2cH+Lt2xbC/ZNRB3isW37cfGX78KrXrgY//aXL2jZfh1X4VX/8wc8s2sYAPD6Fy3Dv1x4jL/+G3dswqdvehz/8YbjcN4xi1p2XADYPVzCqz5/O/aOlgEAs7qy+PkVp6O/Lx+7/b/+4lF89+7NOOngefja2070l//m0efxge/fD8dVyGcsfOsdJ+GYpbNjt//C757Erx/bgZ+9+7RQ/f7zjcfhxavm4YLP3459o2Usm9uNG957BkQEF3z+dmzePYJixYXjKvz4707FCSvm+s+fWW+MlBz0dWXQk8uE6rN7uOTv33jD2uX451cfjXd+Yx3ueGpnzX0AsEXw2Tcci3OPXoSK4+KVn78dSgGnHjofP7h3S2h9nODz84a1y3H6YQv8+6a8/X153PHhl0EAvOp//hCqjy2Cz73hWLxo5Vy86n/+ECq/eb7/6zdP4I6ndgEATj5kPiyBf9+Y1ZXF9e85DW++5u7Q/k8+ZD6ueeuL8c/XP4Kf3Pccrn3nSRAB/vqrd2Os7AAAls8t4JfvPR3fuusZfPbm9WgUEpjynuM9H79+9Hl8MOb9AQBf++PT/v5ee8JS/GDdFvz3Rce3/L0+nlYEGxKzLPZ5EpHLoJtasGLFihYcmojS4qHn9mHvSBk/uve5lgYbu4aLeGzbfpyxegGe2zuKOzeGTxB3bdyFkZKDP2/e0/Iv4A07hrB13xgueOFi2CK4/oGtePL5wbrBxh1P6bL88aldUEpBRH+93rt5D0ZLDi46cTm+fddmPLhlH45ZOjt2+8/+6gkA8O/79XtmD+Z0Z7Ft3xiOWNiH9c8PYmCoCFsEj28f9JcBwFdvfxonXKqDjV1DRTy+fRBnrF6AIxf14Z5Ne3D/s3sxOFbB4FgFT+6o1ufJ5wexbd8YXvXCxVg8uwu/fWwH7vTK9scNOzFadkL3D1/UhxNXzcXX79iEPz+zB+cevQi7hkt44vkhAMDAUBELZ3Vhy54Rf32cdc/o52fFvALufGoXurI2RksO3nbaKr+8A4NFDAwWYVsSqg8AfP2OTbh38x7M8p4fU/7RsuM/33/YsBNHLJoFAfDHDTpIOnLxLJy4Sj9P2/cX8fMHtuLOjbtqnq8/btgJpRR+ct9z2DdaxsPP7QOgg7NLT1qBZ/eM4rYnBrBzqIQ/bdyNrqyN156wtO77ypTXBBvrntmNsbKDN6xdjmv/tBkPP7fPDzbM/gDgFw9uQ7HiYlZXK079E9OKI24BsDxwfxmArXEbKqWuBnA1AKxduzaZXA4RTUsDg0UAgGr4m27y+730pBX4w4ad+OWD4aTrzqFiaLt2HPuKlx2GjGXh+ge2YmCo/nHM9qWKi/1jFczuzvrL+/vy+Pirjsa379rsb1dvewD+/WD9zLFffdwSfObm9RgYLMLyAhqzLGqH//ytxHnHLMJXbt+I+5/dW1NmAP7+r3jZahyxqA8jJQc3PrwdwyUHo94v+IGhon//lccswt+ceShueGh7TZ0AYO9IGecfsxi3PeE2fH0GBos4qC+PUw6djxsf3u7f/+gFa/Dl26rl3TlUre+bTl7pBy/m+OYY7z17NQ5f2IdiRQcbm3YNY6zs4oIXLIJA/P1d8IJFuOwlhwLQgdbPH9iKR7fuD+3fHH+wWIHrNWEE6/Lxv1iD368fwG1PDPiv0RGL+vDRC9bUrW/w+arWvwsf/4s1uPZPm2tekyO8oMpkYuoFu+3UiqGv1wN4szcq5WQA+5RSbEIhogkxX5BjZRfFitPy/fb35dHf24U9I2WUKm7N+vYEG2P62L15/wu+3nEcV2H3cBEr5xdqtjPBRi5jYW4hi4GhsYbbB+/7/4eqJ9M1i2f560yAYJbV1GGo+vwF/0ePE7wd3Hb3cAnb9o4CAFbOL4TuB7cbqBP09fflQ+vrldFst3u4hG37RmPLGwwogssX9OXD63r1unzGxpxC1g8gzDGCZYvefnTb/tB983/7vjEMFSt+eQeGipjdnUU+Y1ffG0Nj/mvdiClvsF4L+vLIZ2zM7s6Gniuzv3rlnirNDH39LoA7ARwhIltE5B0icrmIXO5tcgOAjQA2APgygL9rW2mJKLWCX5C7hkqt269/Aunyv2R3DVePtdM7VluCjSGdtp9byGFWVwa5jFX3OLuGi3BVOBAI1sGcAPu9E02j7YP3g/8HBovIWILDDuoNLQOAQ/t7/ceWndpg7CBz8vTKUcjZyNlWzYktYwnmeBkW83w/tl03z5iymvuhYKNO0OcHG+NkNoIn1Me3D44fbPQGTr69eT/wytoSyhD19+bxmAkgAu8hc9+Y3Z1F1pZqYNIbPv7j2wdh+maackTLuGN/MfRa12PKa+wcKtW8PwDdlGb2Z9ZH6zdVmhmNcrFSarFSKquUWqaU+qpS6iql1FXeeqWUerdS6lCl1AuUUuvaX2wiSpu4X8gt2a93MlzQl6vJLoyUKqFfm602MFjEgt4cLEsgIjUniei2QCB4CJ7Eh4o1J+a47Ye9ugTvD5ccf/+6PHkcNCsfWmb2a+wargZ7Zv2CyMlTgJogwOzfsnRThTnBmROwKWswU4DIfqKvg8kKNRVs9FY7qtYNNoZq69vfl8fOoWJN+c0683w0yhCY1ze4bfC/qbNfjkBQYZ7bTbtGMFp2xs08mPJG6w+EAxHTXBUsd1fW9vsCTaWp7yVCqee6Cu/85jq85dRVOPPw/qYf9/TOYVz+rXsxVnHwopVz8R9vOA6DY2W87Wv34JOvfQFWL+wLbf+RHz/k92YXAEvmdOOLl56At1xzt9/7vx0uPHYJPnjOEQCAK2/ZgO+vqw7G6uvK4LXHL8M379wU6nnwopVzkc/YfnkbyWcsfOGSE/C1P26qu72gTi9sADnbwnCxgmymuVbSC49dgge27MMmb7QGALx41TzkMpbfEa4RpQBL6penWVv3jmL5vG48u3sU7/rmOnTn7APco7ZnuITefAaFXMb/wn3nN/T+K44u9bK53diyZxRnfuaWlhzTGBgs4pD+Hv9+f18eNz68Hfdurj2OGZWwZok+If/z9Y/gc79a7+8neDL55UPb8Pav31Oz/advfNzfX/C+qd8vHtyGww7q9dPtV9++EQKgL58JPd8PbtnrPxd7hkuh9ebEOK83h3k9edz40Hbc+4zedsf+op81MfUFgG/duSlUVnPf/zXunaTP/Mwt2D1cQl9XBoNjFX8fwfVxdg4VQ01VwX0vCGQJrr59IwD9OTWdJs0xdg6V8MsHt2H1wmr5g3Uwt6XOOnN/676x0P5NOUydl83txgNb9gIAzj9GzxLRlbUxqytTfV6aCjaqz4euf85fd+PD23DmZ27x39/B/RVa9LmaKAYb1HJ7Rkr43eM7cNsTA9jwf1/Z9OPu27wH658fxIp5BfzigW343OuPxW1P7MS6Z/bg0zetx1fesja0/S8e3Op/IQH6V8EfNuzEA1v24bTD5o+bipyMezbtwU2PbPeDjZsf2Y5i2cXJh8zDruESbn9yJ7bv24Bi2cXZRx0EAHhs2yB+8eA25G0LC2d34Zgl8W3jAFCsuLjx4e1Yt2kPfvHgViycFd7+nk178NzeUfTlM/7+4x4PAMcun4ODvfb8RvX50Z+fw3N7R3HM0lk4rL8XDz23D796ZDtyGRt9XRkcu2x2w8c/t3cUfV0ZnH1kbXkm4vjlc/C6Fy3Hbx57HntHWteMAgDHLZ8DQP+yfuupq0L7Pz2zAK89YSm+v24LHNets4fJe8Wa6giKy888BDd5r0+cWd1ZnL56Ad579mpsDgR/L1o5F68+dgkA3fFQRKCUit3+9MwC2LZgxMtyROtnyvMP5xyOe5/ZAwA43hvmes1b1+JPT+/Gjv3F0HwMZj0AzO3J4Z9eeSResWYR1m/fX1OfYH2PXjIbbzllJfaNlrF8XgFnrO4P3Z/Xo0+Qrz5uCbbsGfWf/+NXzIUlwJM7hnDM0lmY3Z0NrY960cq5ePVxS7BiXg/ecspKDBYrePVx+vmaW8jin155JJ7fX8QuLxsQrA8AvPrYJXjO2/85kREvbzp5JSwRLJvbjbkF3fzw3rNXQynl3zf+9qWH4qaHt+OEldX9zylk8d6XHYbNu0cwqzuLc49ehB/euwVKKVxy0kp/u3889wjc+8wedGVtvGScH2nB8gLA2pXz/Pr+9SkrYVviv35nZBf4+7voxcvH3Xe7SFITfKxdu1atW8cWlzRav30Q5/7Xbcjagic/0Xyw8b+/fwqfvPFxfODlh+M/f/MEHvj4Obh9wwDe85378Io1C/HlN1eDjbGygyP/35tq9vF3Lz0UX7z1KfziitP9oV+t9LGfPoRfPrgN9338HADAKZ/8LU47bAE++/pjsWHHEF7+H78HALx41Vz84PJTAQBfuX0j/u2XjwHQXyjvPuuwuvsvVVwc/rEb8bcvPRRfuvWpmu0/+pOHcO2fNof2H/d4ALjykhNwwQsbz6/30Z88hO/cvRlKAZ94zTG49KSV+MzNj+N/f78RWdvCm05e0bBXvCnPiavm4fuXn9LwWESUbiJyr1Jqbdw6XoiNWm6y7e0Dg0V0Z22sWuD1rh8aw56R+OYQ0165dE43gNqe4AeNk4acrOBoBtdVOn0Z0zZc9/Y42RYz2qDaIa02TQsAcwq5uo+PO27d+vTl/U5rPTmd6CzkMqi4CqNlB4Vc4+RntTxT3+GMiGYOBhvUcgNDY5N8XLhH+Y5A5zXXDWfg/M5xXhPDwlnVTlgi8NOzrRYczbBvtIyyo/yAwIw2AGp7ukcfP94xoh3ooo+3mujf1eyxDNOW2xNo0+3JN27frZZn6jucEdHMwWCDWu5AMhv9fXk/KxHsKb870oYfHa43v6caoMzvySFjt+etHRzNEO3VLiL+zHzNZDkaHWNHzAgBQE+HPNGyNtwmEAj15L3MRr6azRgvs9E3gfIQUediB1GasFvX78CfN+/FB19xeGj5lbdswD2bdmO9N4a+7Ci87kt3NL3fR7ftx0tW9/tj1z/3qycwOKabUR7duj+0LzO8bPFsvW1vPoM5hSz2jpRDvc9bzZzA/+EHD/i/5oMn9ZwX5BxQsNEgE5LxUhrZJoKpniZ6ncdnNqpfC+NlNrJeeXJNjnwhos7EYIMm7K1f00PuPvDy1aHx2maq43k9OZx95EEou2pCvfuPXzEHrz1hKWZ1Z3DpSSu8oZjdKOQyGC05oWmsl8zpwotXzcUbX7wcj2/fj/edfTh+sO5Z3PX0Lpx3TPsuOnzkoj5c8ILF2Duqg53zjl4U6oj6/pcfjpse2Y5TD13gL5vdncWlJ61A2XGbGiHzl8cvxc6hEpbM6arZ/qwjD8LFJy7H+84+vM6jgW+/4yQ8sGVvU2Ppg8FGNbNRDTDGy2yY8rz/5fXLQ0TE0Sg0Yas+/EsAwIP/fI6f1i9WHBzxMT065LUnLMV/vOG4pIpHExAc1fOHD52FZXMLuPvp3XjD/94JQAcup69e0GgXREQAOBqF2iTYNyM4vXQS8+7T5JjJhIDgaJRAZmOcZhQiomYw2KBJqze9dDsm06L2McGhCSx6Ah1Ee8ZpRiEiagaDDZqQuKtlRm+P185P00t/Xx4ZS/zOrcGOpUlNbUxE6cKzQoe48pYNeMWahVg1vwf/3/UPY8+wHuXRldUnmCMXz8LlZx4KAPjTxl34+h2bsGRON45bPge/eex52CIYKTkoBa4G+aVbn8IvH9wGANi6b3SKa0St0t/XhUKuenGm4NDXYJaDiGiy+E3SAYoVB5+5eT2uvGUDvnfZKfju3c9i6ZxuWBbw7G4vSLh/K/7mJYdARPC9dc/619foztoY9S4QdVBfHnMLObxg6WyMlh04rsLTO6vXbzhyUR/6+/LjTpFN08sFL1iERbMCo1JyNs49eiEqjkrkUtRElD4MNjpA0Wv6GCk5/uyeV156Ago5G+f8523+dsMlB735TKhJxAQaAPDRC47ChcctnaJS01Q575jFoeHCIoL//evYDuVERJPCPhsdoFiu7WdhLtscZNYNDBZjJ8Zix08iIpoMBhsdoFipZidMQLGgN1eTIjfrdg4V/WuOBHFIKxERTQaDjQ5QjIwgmd2dRT5jw4pczWtgsIiK42LXcAlHLe6r2Q+DDSIimgwGGynw8HP78M/XPxLqrBkUbEa57cmddYOGgcEx/Oz+rVAKWD63ULOenQWJiGgyGGykwLV/egZfv2MTfnLfc7Hrg80o+0bLOPPwfv/+2087GG9cuxy2JRgYKuK7d28GABy3fA7+4tglWDGvgPecdRhOP2xBU9faICIiiuJolBQYLupgYqRYiV1vmlG+866TQhcIA4CP/8UaAMCtT+zAwGARO4eKePWxS3DM0tn4n4uPb2OpiYioUzCzkQIjJR1kDJec2PUm2Mhn6s8G2d+Xx8BgEQODRfbNICKilmKwkQJ+ZqNUJ7PhzZWRz9R/uft783hm1wiGSw6DDSIiaikGGyngZzaKjTMbZmryOP19eWz0OphyPg0iImolBhspYJpPdg0XcfVtT2Hdpt2h9c02o8TdJiIiOlDsIJoCpmPofZv34r7Ne7FiXgG3/T9n+evNaJRGzSgvXDYHluhroRx2UG97C0xERB2FwUYKRDuGBq9nAlTn2WiU2Tj36EV48hOvhAA1k30REREdCAYbKRDtGNqTCwcVfjNKgz4bAGAzyCAiojZgn40ZrlRxUXZUaFn0vmlGydl8uYmIaOrx7DPDmaxGcKRJ8Foo5n7Ottg8QkREiWCwMcOZ/hrBESTB6ckB3WejUedQIiKiduIZaIYbHCsDANYsrl4SPprZGKs44/bXICIiaheegWa4nYMlAMA7Tj8E6z72clzxssNQqrhQqtpvY6RYQU+efYGJiCgZDDZmuIGhMQC6GWVBbx5dWT0SJZjdGC45KOQYbBARUTIYbMxwA4NFANU+G6ZvRjDYGClVaobDEhERTRUGGzPcwGAR3VnbDybyXmajFMxsFB0U2IxCREQJ4Rlomnpk6z5s3TuGvq4MbEswt5DFYQf11WxnLgkvooe1VjMb1REpUtyLkzMbgcd3Vh84/zDAsoGB9UAmDxx8JmC34O2wfxuw9T59u28R0Le4er8dumYDC48GNt8JKDX+9s1Y/EJg9jK9v+cf0bcb7T+TB7rnAoPbW3v8XU9VX5/lJwLP3Am48Vf2xexl+vjB9b0LgeJ+oDwav3/XAZ6+rbp+1mKgd1Ht69WofitOBgrzgG0PAPuei18/sB4Y3VPn+L8HymP6vbjqDCBX0PUMbg/o9bOWAHufja+/0TUbEAvI9VSfj8XHArOXVrcJ7r9rNrDqNP0cPH177fNr9jfZ8pjnBwjXt9H2IsDmu6rvt+jnc3RPdX3XbGDhmur9uMcvPhYY2alfH1NfANi5Adj5BJDtAla9BNizCRh6Pr6+C1brPwAY26f/Zi2Nr0/w+d6/Fdh6f/X1Hdur7wP6+VtynL4dfP9ku3Q5B58HuucAK0+t//6Kls8/XgZYeQqw5R7v/ZXR72/zegXrEz2+Kb95fgD9+FWn6/dncPu41xfQz2fc6xU0azFg5/T3V9z7L/j8RG29X9c1WP9MHsjPAnY8Cozura4Lvr6mPkuO18efQgw2piHHVXjNF+8IZScAYNOnLqjZdocXbBhxzSivH/4eLtn/M+C6wANnLdMfHPPme+O1wFGvOvDC/+IDwBM36tti6y+KTbcf+H4bOfRs4Knftm5/B78EeMvPgXVfBX7598CiFwLbH2zd/sc9/pnAW64HvvNGYNeTelkr62j2v/FW4NuvrS63MsCKUyb2eq19O3D+vwNfeTnglGrXH/oy4KnfhZcd8lLgzT8DNt4CfPuvqsvP+QRw5AXA186bSG3GZ44HALs31u7/3XcDG38P3PiPrT0uAKx9B/Cq/9C3o/Wtt72dBf50VXj5xdcBR5yvb9/6qfD64Hsj7vErTwe23F19fd59D9B/OPCdNwC7n/L2/z3gB28BKnUCoTkrgfd7n4H/PRPY8zRw6Y+Aa2Pqc8hZwJt/qm9f/15gw6/17XM/qd8L5r6VBT7yrA5u6r1/AOBv72i8Pli+4PEafWaC9akUgS+fDbhl73EvA/76J8B3Xq/fL8a5nwRO+bvw9i9+F3DBZ/X6p34HXPs6ffuS7wOHn6tv3/JJ4O7/rV/2t/9KB/g3fSi83MoCH9mig4WgSlE/H6a8ADB3lQ4m6rnk+8CNH9KvGwC84ZvAmgvrb98GDDamobLjolRxcfphC/CHDdVsRLHi1FzfZGCwiEP7qxdOM+vN9VAAoMsZwlBmDnrf7n3h3vUl4LHrgcoosPI04Jk/AqPhK8VO2sguYOla4JAzgds/B+x5Rt+/4HOt2X/Qc/cCv/ygPiH3LdZfyAfq5o8CI96vOvMLbPuD9fc/tEN/KQHAKe8BXvD6Az++eS1GdlVfHxN0vOsW/eUcdNcXgQe/F17/2PX6+QeAN34bmL08Zv+7q+u33qe33/sMsOxE4JWf8er3vD4pAcCpVwDHvK563O+/We+jNKRPBHHrd23Qt8/7tP4VePM/VY8bPP7336LLZZaZ7Y0vvwxQDnD0a4HT3hf/3Jn3Q9CKU6v7BKqv7Xmf1r88f/n3ev3Irtrn97l1ev1ky/P9vw5/rvz6XqszO/W2tzI6a3DRd3R25rtvjNRhl/6xcMYHdPl2PanvixV4/DLgomuBmz4C7NusX58VpwKb74h/f43uDgca5/87sPwkffvOLwBP3FxdZ05Y5jm76Du6vABw04cjdd6l97PlHu/19e6vOAX4438BxSGd9XBKwKnv1T9OvnuRfqwp295nq+uPiQluguULHs98Zi76LvC9SwHleo8X4MlfVR9fHNIn7tPeBzx7d+D9uUtvf+oVwNVnVetltgdq6+rfjnm9Lrq2uuyRHwN//G/v+dzkPVaAy27R/8360lBtsBEs79GvBe74H+DJX4e3eeVngWUv1tmP6y723uO79efz1CuAuStrn8c2Y7AxDTmuTretXtgbCjZ2DZWwZE53aNuBoSJOPmS+f9/MpxFqRnHLcKzuakpu7kqgPKLTenNX6Q90NNU+WeVRYM4KYMHh+v7ILmDRC+qnAw+E+aUzvEsfsxXH6FsIDG6rXd41J37/w4EvmPmHHXgZ+hYCQ15zRXm0+vqM7AbsPLD0hNrHzFmh/9u56vodj1XXLzmhmtYO7X+kur44VK3PohdW6zEcaXoL1q97ri6jee/Erd/pfeEvPFqv612oA7To8XM93r5GwtsbuR7dJDRnef3nuFIM37fzuilv+0PVZcH929nqsvIIkOkKP7/Bk2+0PNkCUBpsXB7z/ESPvfQEnSKvt72Vqb7fos8VoLfpngMsPEbfH94FzDtYBxvm8d3e4/sW6pQ/oN9Lm++o7iv4/gruP1rfOStq1wfLtOSEakq+d6FO4wfLOnuZfr7Me2X2smoTRnlEBxuAXrYk8Pz77/2dgfXH1ZYjWL7g8cxnc+kJ3us15H1WJPJ8erfnr9Y/jsxnx3yXLTm+Wv7g9mab6H7itumeGy578D1pts8W9LGC6xs97/O95yPu9TGvX9+i6mPKI637npwEdhCdhipesLFwVjiiNSNPjGLFwd6RcsNmlLLjwlIVKCsQV2a9gKUyWm1vjHtTT0Z5RO/fHKM8XL3dau04RrY7PvCqt//g8myhdcd33fDrUxoavwxi1y6Lu+1/aY5Wl4Wey0Kdx0bqly14X2KjDdYPh9eFvrQjx2+0r0w+fnnoeJHnx8qEjxc6ZiFQZ+8kGH18o7pnck2UpxB/Yqr7OhaqJwWzTbCM/n7qfMZiHx94DfzP+qjuX+AUq8tMsBlb927dl8Aph7cp7o/ZNvp8j1Sfa79sMc+9eWxwX6ZsJmNQ77kOli90vOHqehNYZgv6L1if0PvQK79T0T9m/PdtdzigCdbPvx3zPvOfgwbvLbN93Gc27rso+j7KFsJNKqF13v/ifr1NK76jJonBxjRkMhvd2domk6BdQ/qX/YLeYLARnmdjpOQggwqU+bAB4Tdc91wAApRaHWzUOWG1UugYLfoQBb+c6x0rKBMICFtRz2wBKA3rQAMAuueNX4a45fWeG7N/IBwI1Hu9MnWCFnO/PFLdX8OTdeDLzxzXfFGbk0NpJHyCCJE6y4PHi3seusOvZ3D/ZvvgSbDe/iZVnu7w56oUCbzqbV+KBAtA+KRTqvMZM4FkKSZYAYCeBdXHm+e+4GVFg00A0TKa26XI58JkvaLlCG4XDIxKI7XfD+Xh8PsnuK/CgshxGgRppnzRQMxfH3i9zLrYz4H3fvHfm4HXwbyWwfdT6PWtl9mICzYi74Ho+6/ecx4tb7CMcfs3//2ArU3fxU1gsDENVVwdKEQv+T4wFA42onNsAIHMRlk3o4yUKsjC0b/yjOCbOtdb+wvsQJRHdMo7dIye1uw7KnSMVgYbMb8m6u3fssbfZjLHN2XI91VP+PX2H3fyCm6byYe3DWYWxNLrczFfdEC4ftHj5CJljVvvP7Y7/BhAfzmb42d7wpmNidQ1eoy4MhrB/U8k2JhUeWKOLbZu7mq0vfkMAbqJwc5HAibz6z3ymuV6Aif0ntrymZN38HnO9+n9NxNsRD8XI7v090omUJ+45zvXE359g98P0fdPcEScCY6ayWwE92WOB+jyRX9o5SL1CWYK6r2nc4HvSP891FubwbCy+vWNBhvR78Dg+8kpedvEvN8aZTZyhfD/IFNuO6vLZJqUWvU9OQnsszENmcxGJhJs7IxmNob1/fm91Q+7ufrrmJfZGC46yMCBhD5wkV+c9ZoOJsOkA+ul8VupHcfIFvSH34kMgWxm/y1pRino9HZxsHrcbLfOdIz3yy60LLCtSHhbp6jT6OVRfV8kvH2zJ9Zg2r7een+fgZNfZUw3E0WPH+yzMZEsTqNyB49nWeH9mwB8Ms0ozZQnrhnF1LfR9lam9r0dPYFHmxyyBR2YRB8fCjbmVx8fzSo1FWxEfpCM7Ip/zSteM6BIONMQbOIJBhumQ250X9GsS93XoKdavmhmIxs5yQeffz948P6bIKgczLAFsgfRPhuFeXVeX8S8Xg0yG3Hvv3oBXvD40exFvf1nC+M/h1OAwcY0VHF0sGFbgns/9nK4CjjtU7/DUCl8Ahwt6YCiJzAVuZmWfNTbtljRwYYK/pqKvhFbldkItnO2o4kjqi3NKOZXUuT5aGb/LWlG8fZherObL+bR3eP/sgstG+9XoNf8EXdSaqZ/irkfTMk324xijh/tm1Aeqaaimy1DaF2DoKs8AuR7w/u3vAC85KXyJ9SM0kx5uiMno3H6FpntTV+TYDlq0vIxnzHLdBC1wydJw2QKysPh5yFbCHcEjj6u3mdieGf917ziZXGUG3gP7w3cDzRlmA6i0X013YziLQ/tv04TQ7a7NtgIPRfm87cn/Pjga2C2LywIdyY3r69IuPkj2KwVLbN5XCnajNJdXRcV/YzEfv4jr9/IOM/hFGAzyjTkZzZswfzePPr78ijkbYwUI5eO90acBC8fbwKPYW/bYsVFTiqQYDNKNGWea1GwEYy466XlWymTq/46bdUxgunL4AQ7TQUbLWguMsf3vxx6qsvqlaFRGrXetv6vqZh9131s9FdiD0Ip57j1RibwpR13/FykGaXZMgTFNU9EfyEG95/JV0dwlEdrn8do89NEy2NG2Bhxx4iW1WQdok04cR0OTfkB70QZGNGTCzyvhumfFWom8N5fI9Fgo4mU/sjOmACtp7qt/30QOUbwPd3o/WPKax5X77nONvrMRE6uwSaWuPeEWRc9ZjDYMNv3LKjNbJjmuZrXKybDEnxcvT4bDTuImjrGPC/RTKWf2WhTk3YTGGxMQ2Y0im2Fg4jhSGbDdAINXj6+25u2fMRkNsouMnBq2y392y1sRon26g4eo13q/YI50P0Fmwea3X9LMhvmizPQoSsu+xD3mPGWBZdH+ylMNrPRTAdRO1dti697/EAzip2v/todrwxBcc0T0SaA4P5FAif40drnLLi/yZSnJrMR0y8kbvu4kQlxaXlTfrNN3OOjqflgQBN8XHBeCCC+r05NM0pMti2UuQp+H3TXZuv87epks8yJO/i4OH42oonPTHBdtBkllNmIdKiMbUaZX6d5KxpsjNeMEvea13nOQ+Wtl70p1DadjvccTgEGG9NQXJ+NQq42s2FmGA1O9JXLWMjZFoZLJrOhR6PU77MR8+GYrGg7cPAY7WJGg7S8GWU0/Jw0ldloQRlqvuwK9b9Uoo8Zb1lwebSdOPR6jfMLMrgv5QSGQNY58Vgx7z3/11wwTV2n70SjMowneDzzv+ZEHmnSmdD+xwkeokMsGx0jV9DbV8Zqf+WagM519Xrzi9tkX0x/A7ccfny0rsGAxOw7W6i+hvXqYcrvBmY1Lu6vH2DWDGkthN8nsdvF7CvbHT/ENsjPBsZ8ZqKZpFCwEZfZqBdsxGQ2CvPD/bui/VOA6hDjep8N/zmo14zSKLNRpxkl+F1v1o/3HE4BBhvTQNkJT0seNxqlkI/LbNQ2o+htbYwUTZ8NF9maDqIxmY24IVYTFfyF0GjIZCvVa++drOAviuBQtqnObATbqRu1zQYf00xZzLalmMzCuI+t8+usXpt6o4xLeTjSjOO9B6PzfIxXhvEEj2f+R9//BxRsNBEYmc9WtF2+3vbR/cb9qvbXxwzpDK6PBi3ZQu0Q4/HqHaxHTV+mOq+5eS3rlS30OaszJDiuX0qj8jXzmQnus9EQ8Oiw3mx37dBXv8NtoC9HNNio258pUJdSzPsv+DmNipu7JiSS4ZuqH37jYLCRsI0DQ1j90Rvx8we2+sviMhs9ORsjpUifjbLJbIRfRt3kUu2zkYEDKzg8LdQea3pgt7AZJdcTGRI6Be2ErTpGvWaUZvbf0mYU02Yc/JXWZMYBaJD2j9TP/PILbl/vCykTmTY51L9E6q+Hql0W7VsQzGyM169hIuKGOYb6EwX6ikymPbuZ4CEYKDQbSAVf62wPYn+FR48V108quJ0Z4hwdYjxevYP1iH5P1BvSGeqLEQkacoXqkExTlrghwXauur+GQ4ZNNiLmM9PoeQo+p2LrMtX0mQp89oLbWxl9sbjQfry+Gab/UXBdTX+gQF2CQ4KD661MnWaU0fCQ4/GGswZfXw597Vz3PqN7Pd/y+A78xbFLAFT7bOTL+4AhCyjMQyGXwe7h8BuvWHGRsRQyo7v0ySLXCzhF3eTi99nwhr6Ggo2YXxmlIWBo4MAqY3pm10uttlOrMxuD26vDT5vdf70hjZM5/v5t1fuTaUYZb/+mfmaq82b2F61fsKzRduLg+uDVLusdP1vQIxhG9zSuTzSgGU/weEMDesRC9P0/unfymY1G5fGfn+f0yaE4qKfgHm97U67g7eJ+Xf79W2rXm/txc+kE92mGGI/trU6DHm3ybFSu4R3V48eVM7jt4LZA1rFOhiJb0M0VYse/f4JDsuPWR/cX95mJvj7Z7mqn2uEd+jk1Q3iDfWCC+zKPK4/o581sb9bt26L3aWb5FdGv9dCAXhfcT5yxvfHvP/P8RL+Xo0OOxwvAp0lmg8FGwvaN6vbc2YVqM4fjKrzKuhOn//gSveCoV6M3/8HazEbFwWeyVwOfvTS0fNW8r2G42O1t4yKHCqxMoBklGEHneoGuWcC+Z4HPHtaaSuVnNb7fSr0H6S+2Vh2jy9vPj98VXt5o//lZjdu8J3P8p34LQPRrle9rXAbzBWKuqxAUvWibX7936v8rTqlfBqNe/fKBsvYtrr8+eB0Qs+xH7wgf36/37/RVSqMWH6uv5hm9KFUjS46vPR4Q3n/XLH3122AZmtr3ccCG3zQuj9nfV86uLjOXd48TfH2Dt7tm6QvkBT+fZn3fIv0rPD8rHGyY90zca/n074Gnb4P//vK3EYSyUEauR7+Pfvt/9F+9MgfvB5/vfF+4HGabrlnAn7+pb5sLuQEI9Y8IbluPKZ+5wmt+VnX7nHeRyiXH6fdWpktnMKL1McfPx3z+/OUK+Ozq6vb+6/uyalkOfol+3J5N8a9XHPP+M69Z8DF//ob+i5oVuJBfNLsU/SwGX9+pyDLXwWAjYXtHdLAxp7uaeag4CivkeX2n/yhgz9MoLMz42QqjWHGxSrbrC/Ls3qg76wFYZu3Cw6VF/jYZcWAHU5B2Vl8e2i3rN+Jp7wf6jwj/Ap2srjn6wmsA8I5f6wsbmfvt8Jqr9RUezeWcD9T8w4DXXVPtvT13lf5V3Gj/77kn/uJtB3r82cv1F9AZfw8sfiFw1KvjH5PtAt52E3DQUeHlf3N7tV05uP+/+qrOIADher39V8DezdULfBn16nfoWcCFX9QnhuhjgusXH1tdtmB1/PGPu0SfZNyKvvJn1Ouu0Ren6p5buy7oij/ruRaGd+rno2t2+HhAeP/nfQrY9Af9K3zNX9bfX015vjZ+eQ4JPD9Go/fRoS/T20MBq19RXX7G3+sLa5nPZ7a7uv6vvqKvdrv6FQCk9vELDtf1NyfT8z+t6wvorFKup7r/2cuBeYeiJuDIdulLlJtLmGe79fM69DywOlKf/iPCz3fXHOCgNTrgzPXq97N5n/7VV/UVlYHw++eKP+t9B8sb9/7yy9cNXPw9HZB1z9X771ukj3WoF+i9/hvA8w9XT7xme8PsP1j+OSuqzQ7Hv0nvzwyHX3iMDmYvvLLaVCJSfT4WHRN+vQ57eW25L/u9zlLs3qgDxegl31/31doLthnB79RsN3DJD3TH4OL+8MXsAOCMf9Dbz14+NVnmOkS14gQzCWvXrlXr1q1L5NjTycd++hC+fddmfOyCo/DOMw4BAPzhyZ247xt/j/dkfw5ZcyGw/UF84pBv4dt3bcZj/3qe/9gP/fBBvP2RN+OI1UcAz9zh//r8z4Wfwq9Lx+CG952BL966Aa+/5SzMPeG1yFz434nUkYiI0k9E7lVKrY1bxw6iCds3qiNl009D33bRjSLcTLc/oU8hl8Fo2fE7jwK6GaULpXDvawCzMuXQPBtZOLCDzShERERTqKlgQ0TOE5H1IrJBRD4cs36uiPxERB4UkbtFpEHOi4L2jpQAAOWKixM/8Rv8ww8egOMqFEyw4bVf9uR1Z6vRcrXfRrGigxJkC6H22l6rjKHA0Fd9bZQ6PbmJiIjabNxgQ0RsAFcCOB/AGgAXi8iayGb/BOB+pdQLAbwZAPP1TTKzgJYdFzsGi/jhvVtQcRW6pASV6fLHd5trnpj5M8xju1CsaYebmy1jz0gZjqtQrDjISaV2ohciIqIp0kxm40QAG5RSG5VSJQDXAYj0ZMEaAL8FAKXU4wBWicjClpY0pcwsoCWn2jziuArdKEJlvTHwThE9XmJiuBTMbDjIq9rZ6eZkK3BchT0jJT+zwWCDiIiS0kywsRTAs4H7W7xlQQ8AeC0AiMiJAFYCWAYal8lsmNlAAd1/o4AiVKY6Br7P1hmN4UBmo1SqII9STbAxO6NHuAwMFlEqlWFBhaeMJiIimkLNBBtxM6lEh7B8CsBcEbkfwBUA7gNQiT5IRC4TkXUism5g4AAnkEoJE2TsH60+XY7r6maUQMfPPksHEMG5NlRlTN+INKP02dVgo1LWfUL8C2ERERFNsWbOQFsALA/cXwZga3ADpdR+AG8DABERAE97f4hsdzWAqwE99HVyRU4XM+X4vtGSv6ziqGrHT28Slh5Lrw9eH8Uyc+RHJmrpEb3twGARlYq3X2Y2iIgoIc0EG/cAWC0iBwN4DsBFAC4JbiAicwCMeH063gngNi8AoXGYZhQzuRcAfzRKcEirCSCCV36VSvzVEgvetv/0k4fQ6w4CObDPBhERJWbcYEMpVRGR9wC4GYAN4Bql1CMicrm3/ioARwH4pog4AB4F8I66O6QQ04yyd7QabJjRKMELCpkAIpjZUHUuzZx1x/Avrz4aT+8cRm95F/AQGGwQEVFimmrIV0rdAOCGyLKrArfvBLC6tUXrDHGZjbKj58+QwMV+ulEEEB76KqVh3esmeFU/KwuUhvGWU1fp+/u26GCDzShERJQQziCaIKWUP/Q12GdjuFhBAUVIILPR5QUbZuir6ypIsIOomXa+e274MtCOF8Qws0FERAlhsJEgk9UAgHJgno39o2V0SwkS6LOR/dWHYVviT0M+VnHwkcy1+gHZQvWCUPlefcXC5x/V9+/4vP7PzAYRESWEwUaCgsFG0PCIvkqkZLv0VRsByNDzKORsDHsdRIeLDhaLd2XSRS8ALrkOOOffgBMv08u2PaD/D6zX/w85sz2VICIiGgeDjQQFJ/IKGh7VzSOWndXzY5zx90CliJ6s7Wc2RkoVdKGEDYe8SV8Ces4K4NQrgKNfq3dihsWWhoHV5wC9B7W9PkRERHEYbCTIzLERNVbS/TPE9LPIdgPKway88vtsDBcddKEIyYbn2PBHpph+G+XRmtEqREREU4nBRoLqZTbKY15mI+NdEMXrJDov6/ijUUbHRpETB3Y+PFW5P3V5KNiIbENERDSFGGwkaMzLbGSs8IzwJX+KcZPZ0MHCnGzFz2yMjuhmErsrktmwM4Cd080ngG5OYbBBREQJYrCRINNBtLcrPN1JyWtG8UeQ+MFG2e+zURoZ1KuiwQagm03YjEJERNMEg40EmWaU3nw42CiXopkNHSzMzpT96cqLYzpzkc3HBRsFoDyi594ojzCzQUREiWKwkSA/sxEJNiplk9nwlnvBwiy74k9XXh4bAgDkuusFG6NAnavCEhERTSUGGwkqe8HGrC6dwTBBRyXaZyOng40+u5rZqIzqzEa+0Fe7Y5PZKI14j48JSIiIiKYIg40EVVw9a+isbh1U9Hl9NzLwRqlY4WaUPquE4VIFSimUi14zSlyfjZwXbJRHQo8nIiJKAoONBJUdndmY7QUb+Yx+Ofxgww43o/RYJbhKN7+4XrAhcf0xTAdR/6qw7LNBRETJYbCRoIp3PRQTbFjeENiceFd2tc08Gzoz0WN5l5kvVuCaJpLYYKOgm1DMLKLMbBARUYIYbCSo4oYzG66rkMtYMc0ouqmkYC4zX3Kg/P4YdYKN8ggzG0RENC0w2EhQtc9Gxr+fz1jIwGQ2wn02usXLbJQqgf4YdZpR9m8FfveJ+tsQERFNEQYbCYo2oziuQj5jI+tnNrw+G5kuAEBe6czGaMmBMsNjTVNL0KFnAXOWA0PPA0tfBCxY3b5KEBERjSMz/ibULtEOotXMhukg6mU2LAvIdCPrjvnbOU7ZWxfzEh7zV/qPiIhoGmBmI0GmGSWU2chagcxGtrpxroCso/tglCsuKhWvqcWyp6y8REREk8FgI0GVaGbDcZHP2IE+G4GsRbaAjJfZKDkuXMcEG0xOERHR9MZgI0HRSb0c04wiphkl0B8j242Mo4ONsqPgmGBD+BISEdH0xjNVgiqOgiVATz48GiVnMhvBZpRsAbYXbJQqOrPhwgZEorslIiKaVhhsJKjsusjYFgpZG4tnd+H/vuYF6MratR1EAS/Y0MNd942WYSkHilkNIiKaAdjgn6CKo5C1BJYluPMjZwMAfvv484FJvYJ9NrphFXcDALbuHUUfXChh51AiIpr++NM4QY6rkLHDL0Ehl6mORgllNrphVfRolK17R5GBy5EoREQ0IzDYSFDZcZGxwn0uenKB0Sihoa89frDx3N5RWHAhHIlCREQzAIONBFUchYwdDjYK+Ux1NEowc5HthpjMxr5R2HAhNoMNIiKa/hhsJKjsushYkWaUrJ6uvCLZ8EiTbAHiXQ9l694xZMWFsBmFiIhmAP40TlDFUchGMhtdWRsKDlyJvDTZbu8qrgqOC3TlwWYUIiKaEXi2StCq4QdwROVB4M7H/GXHbtkFZT0FpybYKECUgyOsrVjvLkVO2EGUiIhmBgYbCfrr7Z9Cf2UbcHN12YkAYAFbckdgWXDj+YcCAP4283O8v3Q5MuJy9lAiIpoReLZKUJc7gpvz5wAfesb/+8m5d+CFY1/G5w/+Unjjo18D9C1GztKdR7Pi8rooREQ0I/BslaCcGsOI1Qd0z/GXSdcw9qMHRTcmDsz3ITOkr6eSYTMKERHNEMxsJMV1kVdFVKx8aHHWm+Sr7F0RNkRsZKGXZ0Qxs0FERDMCg42kVLyLqlndocVHL5kFADhnzaLax1gZZCwTbLgApysnIqIZgD+Nk1LWE3RV7K7Q4lULevDEv52PXCYmDrQsPU05wOnKiYhoxmBmIyneBF1OJNgAEB9oAIDYOqMB9tkgIqKZg8FGUrxgo2x3j7NhgJXRfTUA2GAzChERzQwMNpLiBRtuTGajLsv2Lz+vm1HYCkZERNMfg42k+H02JpbZsE1mg80oREQ0QzDYSErJy2xkJhBsiOVnNmx2ECUiohmCwUZSvGYUZAvNP8ayA302HPbZICKiGYHBRlK8ZhSZULCR8Uej2OyzQUREMwSDjaSYzEZ+AsFGYOgrm1GIiGimYLCREOUFG3Zugs0o3qReFnjVVyIimhl4tkqIUykDALLZbPMPsmyd0QBgK4fNKERENCMw2EhIpVIBAGQzEwk2Mn6wAeWwGYWIiGYEBhsJcUywkZtAsCG2bj4BIMxsEBHRDMFgIyEVrxklN8FmFEvpeTZEcegrERHNDAw2EuI4FbhKkM9OIDth2bBggg0XsPjyERHR9MezVUKcSgUVWMhnJpCdEFtnNACd4WAzChERzQAMNtrMcRX2jpRqlrtOGS4s5LMTeAmsDCzl9dngDKJERDRDMNhos7+79l4c939+jTue2hla7jgOHFjIZyYSbNh6mnIAGShmNoiIaEZgsNFmf3hSBxnb942FlrtOBQ7siTWjWBlkROHb7zgJXbbi0FciIpoR+NO4zYZLOhNRcVRouQ42JpjZEAtwHZy+egHn2SAiohmjqTOdiJwnIutFZIOIfDhm/WwR+bmIPCAij4jI21pf1JnHcasBRtl1Q+tcp4wKLHRNqM+GDbgVbwcV9tkgIqIZYdwznYjYAK4EcD6ANQAuFpE1kc3eDeBRpdSxAF4K4HMikmtxWWec3cPVjqHBwAMAXMfRHUQn2IwCbzQKXGY2iIhoZmjmZ/WJADYopTYqpUoArgNwYWQbBaBPRARAL4DdACotLekMtGOw2k+jHGlGUU4FFdgTbEbxMhtKec0obAUjIqLpr5kz3VIAzwbub/GWBX0BwFEAtgJ4CMD7lFIuOtwV37nPv11xIs0obgWuspCb0GgUL7gwTSlsRiEiohmgmTOdxCxTkfvnArgfwBIAxwH4gojMqtmRyGUisk5E1g0MDEywqDPPcKma3KlEmlHgmqGvE2lG8V6u0pD+n+06wBISERG1XzPBxhYAywP3l0FnMILeBuDHStsA4GkAR0Z3pJS6Wim1Vim1tr+/f7JlnjEcV+HiE1cAAMqRzIZy9WiUrB0Xy9VhMhvFQf0/W2hFMYmIiNqqmWDjHgCrReRgr9PnRQCuj2yzGcDZACAiCwEcAWBjKws6E5UqLvIZCyK1HUThunBgwbYmEGyYZpOiyWx0t6agREREbTRuD0OlVEVE3gPgZgA2gGuUUo+IyOXe+qsA/CuAr4vIQ9DNLh9SSu2su9MOUXYUchkLWcuq6SAKtwJXbOg+tU0yo0+Y2SAiohmkqeEMSqkbANwQWXZV4PZWAOe0tmgzX9lxkbUFGVtqOojCdeBigh082YxCREQzEKcrbxPXVai4ClnbQsaS2g6iqgJXJvj0m+1LJthgMwoREU1/DDbaxMwYmrUtZG2rpoMoXBdqokNXmdkgIqIZiMFGm5g+GjlbdwKNdhAVVYE70ac/2mcjx2CDiIimPwYbbVKumMyGeJmN2nk2lExwBlCJdhBlMwoREU1/DDbaxDSbZDOW7iAauRCbKBdqon022IxCREQzEIONNik51T4bGUtqLjEvSg99nRAOfSUiohmIwUabBPtsxHYQVe7Er9paE2ywGYWIiKY/BhttUg5kNuI6iFrKmfhoFLN9aQiwsoCdbUVRiYiI2orXKG8Te9t9+GHun7H6ljyeL52EW903htbLZIIN02fjmTvZhEJERDMGg402yW/9E9ZaT6A81IfTUMZvnNeH1lvKmXgzyrK1wJoLgdIIsOzFLSwtERFR+zDYaBPXcQAAI3OOgL13f0wH0UlM6tV7EPCGb7aqiERERFOCfTbaxHV1sCF2FhZUzdBXS1UgE81sEBERzUAMNtrEMcGFlYENt+baKBbciU/qRURENAMx2GgT04widhY23JoZRGUyQ1+JiIhmIAYbbeJ6mQ2xs7BE1Vxi3obDZhQiIuoIDDbapNpnIwOrTjOKP5SViIgoxRhstEm1GSUT20HUVg7E4tNPRETpx7Ndm7iuC0cJLMvWmQ2HmQ0iIupMPNtN0O+fGECx7OCcoxfFrr91/Q6UKi4Wug5cWLC8ZpRgB1GlFPtsEBFRx2CwMUFvueZuAMCmT10Qu/6tX7sHAPDD1Q5cCDK2DUu5KFUcf5tixYUNF8JrmxARUQdgM0qbjBbLUCKwbd2MUgqMRhkpObDhIpNhrEdEROnHYGOSoldxjRoplqBgAWLDgkKx4kIp/ZjhYoXBBhERdQwGG5O0a7hYs2y4WPFv7xkuAmIBYunZQhX8fhsjxTIsUchk2IxCRETpx2BjkgYGa4ON4LLhsZIONiwbAt2EUvT6bQwXSwCAbIYdRImIKP06Ktj4/RMDeHz7/kk//pb1O/zbA4NF3Lp+R2h/A0PVYMOCW81sKBNs6P+jY2UAQDbLzAYREaVfR3UaGG8kyXje5o00AYA9IyV84HsPhPa3d6Tsr8/ZAtvWfTaqmQ39f6TkBRvMbBARUQfoqMzGgYh2CB0cq9RsY5pJfv2Bl+DSE5chl8kA3qReAFAs6/WjfjNKR8V6RETUoRhsNGnPSCl0/7k9ozXbFMs6qMhnbECZZhTRV3hFILPhdSRlsEFERJ2AwUaToh1CN+0artnGBBP5rBUINrzAI7B+tKQDl1yWwQYREaUfg40mRYONZ3aNAAC6stWn0DSj5DPBYMOqZjb8ZhSvz4bNPhtERJR+DDaaFA02Ht8+CACY053zl/mZjWAzilXbQXTM6yBq8dooRETUARhsNCk4rDVoXk812BjzMhe5jAUo5Tej6MyGCjSjeKNWGGwQEVEHYLDRpIHBInpyNjZ96gL05qt9LazAM1isuMjaAtsSL7MhOuAAvCnLw80oEJmy8hMRESWlI4ONUsUdf6OIgcEi+vvyAIDhkh5N0pW1UK5Uh8QWy65uQgG8YMP2oxELrj9aZcx7vAlEiIiI0qwjz3ajJWf8jSKCwYZ3PTUsmdONcuBqrsWKozuHAqEOogBgw6322SibzEZHPv1ERNRhOvJsZzITEzEwVMSC3nxo2dI53aFLxxcrbkywoTMdEmhGGSsys0FERJ2jIyd6ePi5fVgyp3vc7R7btt+/9sn2fWM49dD5ofULZ3XhiecH/fvFiot8NtiMwswGERFRxwQbSlX7Vvz3b5/EOUcvGvcxf/Ote7F594h//5AFPQCA845ehJse2Y7urO1fNh7Q82jUZDa8ESe2uP7MocxsEBFRJ+mgYKN6O3qdk/jtFbbtG8UlJ63AZWccAtsSLJursyFXXnoCyo6Lf79pPcqV5ppRFhQy2DmsZw4tMrNBREQdpGOCDScQbQT7WdSzb7SMsqNwaH8vVnkZDcO2BLZlI5uRSJ8NpzoaxQ03o/T3ZP2JwcbKFf3MM9ggIqIO0DFnu2A2wwxBbcQEBmYESpycbUVGo7j6uihAdZ4Nb+jrgl4dbJQdF47jjYZhsEFERB2gY852wWaUYhPzbPjBRm/9YCNrW3BVNZDR82zED33t78lgYLCIkZIDgVcYTupFREQdoCObUcwQ1EbM9OSNMhtZWwcSe0dKKDsq3IwS7bPRk8HA0Cie3T0Cyw82OibWIyKiDtY5wYaXfcja0lRmY+eQ7szZOLOhMxOvv+pObNw5jCWzuyLNKNXRKAsKGZQqLv7xhw/C8i7MxmCDiIg6Qcec7czQ1+6sjVLFDQ2FjTPsDU/tyde/WFrOazLZuHMYALBt/1g1OIk0o8zv0XHdE88PYvmcLr0Ngw0iIuoAHXO2M5mN7pwOHsbLbgyXKshnLGTs+k9RNrJOqUCzS6QZZX4h45fjuGWz9DYMNoiIqAN0zNnO9Nko5PRJf7xgY6TooCffuJUpGmwAccGGl9koVPc1z8tyMNggIqJO0DFnO9Nq0pU1mY3GnUSHSxUUcvWbUIBqn42gajOK8vps6Kd4XiHrbzO/m8EGERF1jo4525lmFBNAjDfXxkjRQU+ucWYjN25mQ/yAojdX3WZugcEGERF1jo4529UEG0302Sg06BwKAL1dtcHIQbO8zp/Rq74q1z/2AjajEBFRB+mYoa8TbUYZKY2f2TjlkPn42ltfDFcpzPGaSWZ3e80lytXDXq3qvBvXv+c0bNs3hoNzT+plDDaIiKgDdEywUe0g2mRmo1jB/J5cw20ytoWzjjwofmWkgyhcB4ct7sNhB/UBm57QyxhsEBFRB+iYs92E+2yUxh+N0lCkGSU0X7ripF5ERNQ5OuZsZybxar4ZZfzRKI0PGMlsKCe8DmCwQUREHYHNKNCBxVhZd+A0wchwE/NsNORPV15tRgmtAxhsEBFRR2jqbCoi5wH4bwA2gK8opT4VWf+PAC4N7PMoAP1Kqd0tLOsBqTaj6CqPlfXJf2CwiNM//TsUKy5md2fxp386G1nbwmjZOcDMhoo0owSabRhsEBFRBxn3bCciNoArAZwPYA2Ai0VkTXAbpdRnlFLHKaWOA/ARAL+fToEGUO0yYTp97hnWF1rbtGsYxYqLF62ci32jZWzfN4Zdw8XQtpM7oBOaZyPcjMKrvhIRUedo5mx3IoANSqmNSqkSgOsAXNhg+4sBfLcVhWslk9mY35uHbYl/CfmBQf3/3KMX6vtDRX9Zo8vLjyty1VdmNoiIqFM1c7ZbCuDZwP0t3rIaIlIAcB6AHx140VrL9NnI2IIFvTk/oDD/1yye7d9vabAhjfps1E53TkRElDbN9NmIOyPWuz77XwD4Y70mFBG5DMBlALBixYqmCtgqZjSKJYL+vnwo2LAtweELe/37pq9Gf2/XARyQQ1+JiIiA5jIbWwAsD9xfBmBrnW0vQoMmFKXU1UqptUqptf39/c2XsgUc7/xui6C/Nx9qRpnfk8MC07wyWPTXLeg7kD4bHPpKREQENJfZuAfAahE5GMBz0AHFJdGNRGQ2gDMBvKmlJWwR02fDsoCFs7pwy/oBHPKRX8JVwDFLZ8GydBDyhVs2AAD68hl/5MqkcOgrERERgCaCDaVURUTeA+Bm6KGv1yilHhGRy731V3mbvgbAr5RSw20r7QEINqO884xDcFBf3m8LOvXQBQCAT7zmGNz/7F4AwJrFsw7wgNFmFHYQJSKiztTUT3el1A0Abogsuypy/+sAvt6qgrWa6SBqW4LDDurFB885omabs49aiLOPWtiaA/rzbLAZhYiIOlvHnO28VhRYUzUCRLl6tAmHvhIRUYfrmLOda/psTNVo04ZDXzmpFxERdY6OOduZDqL2VEUbytX9NSyvpSoUbHi3Oc8GERF1gI4INr555ya885vrAEx1M4oF2Fl93ymF1wHMbBARUUfoiLPdx3/2iH97yoMNyws23HJ4HVDtz0FERJRiHRFsBE1tM0ows1EJrwOY2SAioo7QcWc7e6pq7Gc2TJ+NmMwGgw0iIuoAHXe2kylrRlGRzAaDDSIi6kwdd7azpyrYcB1vno0GfTYYbBARUQfouLPd9OizwXk2iIioc3Tc2W7KprbwJ/US3W+DQ1+JiKhDddzZbsozG4BuSoltRuGkXkRElH6dF2xM9TwbgG5K4dBXIiLqUB13tpu60SjBzEaGHUSJiKhjddzZbkqaUZQCoCKZDQYbRETUmTJJF6Ct/vh54Onb8EZ7Fb7nnAWgRc0oSgE3/xOw80ngxMuAw8/RywefB274B6A8ou+H+mywGYWIiDpTuoONu68G9j2Li+1Dq8GG3YJgo1IE7vqivt09txpsPPsn4LHrgf6jgGUvBg4+Qy+3M8xsEBFRx0p3sOGd4DOoXt69K9OCE7zJXADVy8UDQHlU/7/oWmD+odXldUejMNggIqL0S/fZzpvbIotqE0amFRdHMUEFoGcK9Zd7QUi2O7y9nYtkNjipFxERdY50n+28fhLBzEZLBDMbwb4YJgipCTbYjEJERJ0r3Wc77wQfzGy0RKgZxQ0sH9b/sz3h7aPNKCYbwkm9iIioA6Q62FDeCT4jrc5sBJtRIpkNsavXQzHihr4yq0FERB0ivWc8pSBeIJBtazNKpINotlCbsbAytUNfxW5tmYiIiKap9AYbgZP7rFyL910yHUEL4dEopeHa/hoAMxtERNTR0nvGC5zcLdXqPhteM0q+rzazkSvUbh839JXBBhERdYj0nvG8Ya8lZcMKnuhbwTSj5Hprh75mY4KNuAuxMdggIqIOkd4znteMMoY8LLdNo1HyfbUdROs2o5Sq95VisEFERB0jvWc8rxllFDkIXAjccR4wAcFgQzWR2WAzChERdbD0nvG8k/uoygNo8YiU8qgOFrKFSGZjIs0onGODiIg6Q3qvjeJnNnSwkYGDErKNHtHYQz8Edj2lbz99mw4qrAzgBif1qtOMYmWY2SAioo6V3mDDyziM+MHGAfTbcMrAj94JQFWXLT8ZsKxIM8pYc0Nf3TJgcZ4NIiLqDOkNNkxmQ+lJNg6oGaU0DEAB53wCOPnv9DIR4AdvDTejuGWdxYiysjEdSWOaW4iIiFIoxcGGHv1hmlEO6PooZl6NXI/OZhhWJjz01SnVTlUO1GY26vXtICIiSqH0Bhv+0Fed2ciIg0l3ySwHZgwNsuxwxsKp6MvJR0WHvtab/IuIiCiF0ttL0akdjXLFWYdNbl9+sBHpj2Flwld9bdSMohw9vwbAZhQiIuooKc5s6GDDdBC95QOnAQcdMbl9+c0okQBBrEhmo1ynGSVTXZ/J6T4gvQdNrixEREQzTIozG9UZRPX9A5iyvGEzitdnQykvsxETbJhlZvhrvSGyREREKZTeYMNkNrxmFBzI9VFKDZpRTGbDBB31OogC1YCnPApkeyZfHiIiohkkvcFGYLpyff9ARqOYYCMSIIhdnWfDBDP1+mwA1cCkXOdS9ERERCmU3mDDDc8gekCZDdNnIzaz4XUQNVmL8fpsmP0x2CAiog6R3mDDO7GP+ZmNUoONx+EHG9E+G4EOon6wETf01VvmlnXfjvKInrODiIioA6Q+2PD7bBxQM8qw/h879HUCzShOuX6WhIiIKKXSG2xMRTOK2DGZjXGaUeplSYiIiFIqvfNsOOEZRLF7o3ehtC7guT8Do7ub39fA4zo4iF4W3rL1pF5m2Csw/tDXesNoiYiIUiq9wYaXcTAziOJXHwM23wWc90ngy2dNfH9zVtYuM00mrlNtphlv6CubUYiIqMOkN9jwphEvBav4xE3AS/5B3375vwArT21+f7OX1y4TrxVKOc0PffX7fzCzQUREnSH1wUYRgUyDUtXMwuJjgeUnHtgxQpmNJvtsmD4ezGwQEVGHSG+wAX3Rs3K0iq3sM2HZ+r9bqQYR4w19Ndtx6CsREXWI9AYbphlFBaoo0to+E+IFG8qpzuPRcOhrpf4VZImIiFIqvUNfvcu5OxI5+ZdamdmYaDNKiUNfiYio46Q42NCZjbJEmjVMZiF6ufjJsLynz3U49JWIiKiO9AYbXp+NikRO/q1sRvEzG5XA0NeYZhQOfSUiog6W3mDDa0ZxTb8Ko5VDT4N9NhpmNgJBCYe+EhFRh0l9sCESqWJ5VAcJcaNGJio4GqVhn41IZsPKAJkWHJ+IiGgGSG+w4TWj1EwxXh6Nn3p8MvyMhVsd0jpun41RZjWIiKijNBVsiMh5IrJeRDaIyIfrbPNSEblfRB4Rkd+3tpiT4HUQtaKZjdJw6/pLBGcQbZjZMJe5r7T2+ERERDPAuPNsiIgN4EoArwCwBcA9InK9UurRwDZzAHwRwHlKqc0iclCbyts8paAgtQmM8mjrTvahDqLePBvNDH1lsEFERB2kmczGiQA2KKU2KqVKAK4DcGFkm0sA/FgptRkAlFI7WlvMSVAuFASWFYg2XAco7m/d7J2mz8bYPqA05C1r0IxSGtLHz3L2UCIi6hzNzCC6FMCzgftbAJwU2eZwAFkRuRVAH4D/Vkp9syUlnDSd2bBCqQ2lL8a2PFr8Scp06f9fOz+wLF+7nZ3TTS63flLfX35ya45PREQ0AzQTbMT1pFQx+3kRgLMBdAO4U0TuUko9EdqRyGUALgOAFStWTLy0E6FcKBFY0dIvOxE4/9OtOcaqM4BX/Vd1oq7Zy4CuWbXb2RngjdcCe57W9ydytVkiIqIZrplgYwuA4PXVlwHYGrPNTqXUMIBhEbkNwLEAQsGGUupqAFcDwNq1a6MBS2spBQULEu20sfRFwJLjW3OMbBew9m3NbXvkK1tzTCIiohmmmT4b9wBYLSIHi0gOwEUAro9s8zMAZ4hIRkQK0M0sj7W2qBPkj0aJLG/FNOVERETUtHEzG0qpioi8B8DNAGwA1yilHhGRy731VymlHhORmwA8CMAF8BWl1MPtLPj4dGbDimY2OBKEiIhoSjV1iXml1A0Abogsuypy/zMAPtO6oh0gpbw+G9Fgg5kNIiKiqZTeGUTrzbPBzAYREdGUSnGw4cYMfQXnuCAiIppi6Q02/Hk2IouZ2SAiIppS6Q026mY22GeDiIhoKqU42KjTZ4NDX4mIiKZUeoMN1BmNYqYYJyIioimR3mBDuVCKwQYREVHSUhxs6MxGTTNK3CXgiYiIqG1SHGzU6SBq55IpDxERUYdqagbRmckb+moBeNfvgMd+AeR6gDltvtosERERhaQ32AhmNpa+SP8RERHRlEtxMwq8oa/RThtEREQ0lVIcbLjxM4gSERHRlEpvsAEFN66DKBEREU2p9AYbygWY2SAiIkpcioMNndlgnw0iIqJkpTjYYJ8NIiKi6SC9wYZ/iXlGG0RERElKb7BRbwZRIiIimlIpDjbqXGKeiIiIplSKgw2XQ1+JiIimgfQGG36fjaTLQURE1NnSG2woTupFREQ0HaQ62FAA59kgIiJKWHqDDSi4sNiMQkRElLD0BhvKhVJgMwoREVHCUhxsKChYsNJbQyIiohkhvadi5cIF+2wQERElLb3BBqcrJyIimhbSG2zwQmxERETTQoqDDc6zQURENB2kONjQ05Uz1CAiIkpWeoMNKCgl7CBKRESUsPQGG7zqKxER0bSQ8mADbEYhIiJKWIqDDRcuLGY2iIiIEpbeYAM6s8HRKERERMlKb7DhDX1lrEFERJSsFAcbelIv9togIiJKVnqDDZhJvZIuBxERUWdLb7ChXG+ejaQLQkRE1NlSHGx4fTbYjEJERJSoFAcbrp5ng7EGERFRotIbbEDBhcWhr0RERAlLb7ChXLhJl4GIiIjSHGyAHUSJiIimgRQHG3qeDXYQJSIiSlZ6gw3Os0FERDQtpDfYUC6nKyciIpoGUhxseJeYZ7RBRESUqBQHGy5cxR4bRERESUtvsAGlO4gys0FERJSo9AYbvMQ8ERHRtJDiYIPNKERERNNBeoMNMLNBREQ0HTQVbIjIeSKyXkQ2iMiHY9a/VET2icj93t/HW1/UCfIuxMZroxARESUrM94GImIDuBLAKwBsAXCPiFyvlHo0suntSqlXtaGMk6MAFxabUYiIiBLWTGbjRAAblFIblVIlANcBuLC9xWoB5ULxGvNERESJaybYWArg2cD9Ld6yqFNE5AERuVFEjm5J6Q6A8i4xz1CDiIgoWeM2owCx52sVuf9nACuVUkMi8koAPwWwumZHIpcBuAwAVqxYMbGSThT7bBAREU0LzWQ2tgBYHri/DMDW4AZKqf1KqSHv9g0AsiKyILojpdTVSqm1Sqm1/f39B1DsJnCeDSIiommhmWDjHgCrReRgEckBuAjA9cENRGSReFN1isiJ3n53tbqwE6JcgBeYJyIiSty4zShKqYqIvAfAzQBsANcopR4Rkcu99VcBeB2AvxWRCoBRABcppaJNLVPMu8Q8rzFPRESUqGb6bJimkRsiy64K3P4CgC+0tmgHSLlQzGsQERElLr0ziLLPBhER0bSQ4mBDZzbYa4OIiChZ6Q02vEvMs8sGERFRstIbbCgdbLAZhYiIKFkpDjbYjEJERDQdpDfY4CXmiYiIpoX0Bht+MwqjDSIioiSlOthw2YhCRESUuBQHG9505Yw2iIiIEpXeYAPMbBAREU0H6Q02zCXmOdEGERFRolIcbCi4sJjZICIiSliKgw2d2WCnDSIiomSlNtgQKChmNoiIiBKXzmBDKf0PgMXMBhERUaLSHWwoDn0lIiJKWkqDDQcA4LAZhYiIKHHpDDZcHWy4sNiMQkRElLB0BhteZqMCC0xtEBERJSudwYZbAcBmFCIioukgpcGG6bNh86qvRERECUt5sGGBs5UTERElK53Bhqp2EGVig4iIKFnpDDa8PhsV2LzuKxERUcJSGmyYzAYn9SIiIkpaOoMNM/RVsYMoERFR0tIZbLicQZSIiGi6SHmwYbMZhYiIKGEpDTaCk3ox2iAiIkpSOoMNVe0gynk2iIiIkpXOYCM49JXBBhERUaJSGmy4+h8s8EpsREREyUppsMHMBhER0XSRzmBDBa+NwmiDiIgoSekMNszQV8V5NoiIiJKW0mAjMPSV0QYREVGi0hlsqGoHUQYbREREyUpnsBHqIMpog4iIKEkpDTbMpF7ss0FERJS0lAYbJrNhMbNBRESUsHQGG6GhrwmXhYiIqMOlM9jwZhB1YPNCbERERAlLabDBoa9ERETTRTqDDcUOokRERNNFOoMN00FUsYMoERFR0lIabFQ7iDLWICIiSlbKgw2bzShEREQJS2ewoYKZDYYbRERESUpnsOH12XA5zwYREVHiUhps6MxGhX02iIiIEpfOYCMw9BXstUFERJSodAYbfmbDZmaDiIgoYakONvS1URhtEBERJSmlwUYFSnQTCkMNIiKiZKUz2FAOlNgAwGYUIiKihDUVbIjIeSKyXkQ2iMiHG2z3YhFxROR1rSviJPiZDeY2iIiIkjZusCEiNoArAZwPYA2Ai0VkTZ3tPg3g5lYXcsJcl5kNIiKiaaKZzMaJADYopTYqpUoArgNwYcx2VwD4EYAdLSzfxA3vBMb2MdggIiKaJpoJNpYCeDZwf4u3zCciSwG8BsBVrSvaJP34XcD934ZjdwFgMwoREVHSMk1sE3e2VpH7/wXgQ0opp9G1SETkMgCXAcCKFSuaLOIEnfxu4OjX4L79/cBNLjMbRERECWsm2NgCYHng/jIAWyPbrAVwnRdoLADwShGpKKV+GtxIKXU1gKsBYO3atdGApTVWvxwAsOehbQD+zHk2iIiIEtZMsHEPgNUicjCA5wBcBOCS4AZKqYPNbRH5OoBfRAONqeYq5ZUnyVIQERHRuMGGUqoiIu+BHmViA7hGKfWIiFzurU++n0YML9Zgjw0iIqKENZPZgFLqBgA3RJbFBhlKqbceeLEOnGmjadSHhIiIiNovnTOIAlBsRiEiIpoWUhxs6P+MNYiIiJKV3mADJrPBcIOIiChJ6Q02vMyGxViDiIgoUakNNly/GYXRBhERUZJSG2ywgygREdH0kN5gI+kCEBEREYAUBxsm2rDYaYOIiChRqQ02/OnKEy4HERFRp0ttsFGdQTTRYhAREXW89AYbHI1CREQ0LaQ32PByG+yyQURElKzUBhuu346SaDGIiIg6XmqDDfgdRBltEBERJSm1wQY7iBIREU0P6Q02/GujMNogIiJKUmqDDc6zQUREND2kNtjwh74y2iAiIkpUeoMN7z87iBIRESUrtcGG6419tVJbQyIiopkhtafisusCALJ2aqtIREQ0I6T2TFxxdGYjwylEiYiIEpXiYENnNmwGG0RERIlKbbBRdhWytkA4HIWIiChRqQ02HFcxq0FERDQNpDbYKDsushyKQkRElLjUno0rjkLGZmaDiIgoaekNNlwXGQ57JSIiSlxqz8YVRyHLPhtERESJS2+w4SrYbEYhIiJKXGqDDXYQJSIimh5SezZmB1EiIqLpIb3Bhusiw8wGERFR4lJ7Nq64zGwQERFNB+kNNhzFi7ARERFNA6kNNsoO59kgIiKaDlJ7Nq54F2IjIiKiZKU32HDYQZSIiGg6SO3ZuOKyzwYREdF0kN5gg/NsEBERTQupDTbKvBAbERHRtJDaszEvxEZERDQ9pDjYYGaDiIhoOkjt2ZgdRImIiKaHdAcb7CBKRESUuNQGG2XOs0FERDQtpPZsXHE4gygREdF0kN5gw3VhM7NBRESUuNSejXltFCIioukhlcFGqeJCKSDHoa9ERESJS+XZeNdwEQAwvzefcEmIiIgolcHGwKAONvr7GGwQEREljcEGERERtRWDDSIiImqr1AUbz+waxmPb9gMAFvTmEi4NERERNRVsiMh5IrJeRDaIyIdj1l8oIg+KyP0isk5ETm99UZvzsZ8+jG/c+QwW9OaRz9hJFYOIiIg8mfE2EBEbwJUAXgFgC4B7ROR6pdSjgc1+C+B6pZQSkRcC+D6AI9tR4PG8/+Wr8aaTV+LgBT1JHJ6IiIgixg02AJwIYINSaiMAiMh1AC4E4AcbSqmhwPY9AFQrCzkRL1o5L6lDExERUYxmmlGWAng2cH+LtyxERF4jIo8D+CWAt7emeERERDTTNRNsxM35XZO5UEr9RCl1JIC/BPCvsTsSuczr07FuYGBgQgUlIiKimamZYGMLgOWB+8sAbK23sVLqNgCHisiCmHVXK6XWKqXW9vf3T7iwRERENPM0E2zcA2C1iBwsIjkAFwG4PriBiBwmIuLdPgFADsCuVheWiIiIZp5xO4gqpSoi8h4ANwOwAVyjlHpERC731l8F4K8AvFlEygBGAbxRKZVYJ1EiIiKaPiSpmGDt2rVq3bp1iRybiIiIWktE7lVKrY1bl7oZRImIiGh6YbBBREREbcVgg4iIiNqKwQYRERG1FYMNIiIiaisGG0RERNRWDDaIiIiorRhsEBERUVsx2CAiIqK2YrBBREREbcVgg4iIiNqKwQYRERG1FYMNIiIiaisGG0RERNRWiV1iXkQGADzTpt0vALCzTfueLljHdOiEOgKdUU/WMR1Yx8lbqZTqj1uRWLDRTiKyTim1NulytBPrmA6dUEegM+rJOqYD69gebEYhIiKitmKwQURERG2V1mDj6qQLMAVYx3TohDoCnVFP1jEdWMc2SGWfDSIiIpo+0prZICIiomkiVcGGiJwnIutFZIOIfDjp8hwIEblGRHaIyMOBZfNE5Nci8qT3f25g3Ue8eq8XkXOTKXXzRGS5iNwiIo+JyCMi8j5veWrqCAAi0iUid4vIA149/8VbnrZ62iJyn4j8wrufqvoBgIhsEpGHROR+EVnnLUtVPUVkjoj8UEQe9z6bp6SpjiJyhPf6mb/9IvL+NNURAETkA973zcMi8l3veyjZOiqlUvEHwAbwFIBDAOQAPABgTdLlOoD6vATACQAeDiz7dwAf9m5/GMCnvdtrvPrmARzsPQ920nUYp36LAZzg3e4D8IRXj9TU0Su3AOj1bmcB/AnAySms5wcBfAfAL9L2Xg3UcROABZFlqaongG8AeKd3OwdgTtrqGKirDWA7gJVpqiOApQCeBtDt3f8+gLcmXcc0ZTZOBLBBKbVRKVUCcB2ACxMu06QppW4DsDuy+ELoLwN4//8ysPw6pVRRKfU0gA3Qz8e0pZTappT6s3d7EMBj0B+S1NQRAJQ25N3Nen8KKaqniCwDcAGArwQWp6Z+40hNPUVkFvSPnK8CgFKqpJTaixTVMeJsAE8ppZ5B+uqYAdAtIhkABQBbkXAd0xRsLAXwbOD+Fm9ZmixUSm0D9MkawEHe8hlddxFZBeB46F/9qauj18RwP4AdAH6tlEpbPf8LwP8DwA0sS1P9DAXgVyJyr4hc5i1LUz0PATAA4Gtek9hXRKQH6apj0EUAvuvdTk0dlVLPAfgsgM0AtgHYp5T6FRKuY5qCDYlZ1ilDbWZs3UWkF8CPALxfKbW/0aYxy2ZEHZVSjlLqOADLAJwoIsc02HxG1VNEXgVgh1Lq3mYfErNs2tYv4jSl1AkAzgfwbhF5SYNtZ2I9M9BNt19SSh0PYBg63V7PTKwjAEBEcgBeDeAH420as2xa19Hri3EhdJPIEgA9IvKmRg+JWdbyOqYp2NgCYHng/jLo1FGaPC8iiwHA+7/DWz4j6y4iWehA41ql1I+9xamqY5CXkr4VwHlITz1PA/BqEdkE3XT5MhH5NtJTP59Saqv3fweAn0CnmtNUzy0AtniZNwD4IXTwkaY6GucD+LNS6nnvfprq+HIATyulBpRSZQA/BnAqEq5jmoKNewCsFpGDvaj1IgDXJ1ymVrsewFu8228B8LPA8otEJC8iBwNYDeDuBMrXNBER6Lbhx5RS/xFYlZo6AoCI9IvIHO92N/QXweNIST2VUh9RSi1TSq2C/sz9Tin1JqSkfoaI9IhIn7kN4BwADyNF9VRKbQfwrIgc4S06G8CjSFEdAy5GtQkFSFcdNwM4WUQK3vfs2dB94pKtY9I9Z1v5B+CV0KMangLw0aTLc4B1+S50e1sZOvJ8B4D5AH4L4Env/7zA9h/16r0ewPlJl7+J+p0Onap7EMD93t8r01RHr8wvBHCfV8+HAXzcW56qenrlfimqo1FSVT/o/gwPeH+PmO+XFNbzOADrvPfrTwHMTWEdCwB2AZgdWJa2Ov4L9I+ahwF8C3qkSaJ15AyiRERE1FZpakYhIiKiaYjBBhEREbUVgw0iIiJqKwYbRERE1FYMNoiIiKitGGwQERFRWzHYICIiorZisEFERERt9f8DqIZzJEH5KCQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also display accuracy\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "plt.plot(my_model_history['accuracy'])\n",
    "plt.plot(my_model_history['val_accuracy'])\n",
    "\n",
    "# in my case after 400 epochs validation accuracy is almost not improving\n",
    "# but maybe training went different way and it found global minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use confusion matrix to check which data are wrong classified\n",
    "\n",
    "# predict target on all input data. Data are still cached in memory (X variable)\n",
    "predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.98511136e-01 1.48883939e-03 2.68995159e-10]\n",
      " [9.95956481e-01 4.04350646e-03 2.14790430e-09]\n",
      " [9.97325778e-01 2.67420383e-03 1.33810096e-09]\n",
      " [9.94819224e-01 5.18080872e-03 4.25120028e-09]\n",
      " [9.98655438e-01 1.34456134e-03 2.46628662e-10]\n",
      " [9.97982144e-01 2.01788428e-03 3.59374364e-10]\n",
      " [9.96990442e-01 3.00952350e-03 2.02987871e-09]\n",
      " [9.97659683e-01 2.34030280e-03 6.33715302e-10]\n",
      " [9.93195772e-01 6.80417288e-03 9.57320800e-09]\n",
      " [9.96495783e-01 3.50422598e-03 1.24411947e-09]\n",
      " [9.98944461e-01 1.05552119e-03 9.43184489e-11]\n",
      " [9.96678710e-01 3.32131167e-03 1.36843270e-09]\n",
      " [9.96383071e-01 3.61690158e-03 1.60747160e-09]\n",
      " [9.97267127e-01 2.73293769e-03 2.11420303e-09]\n",
      " [9.99747097e-01 2.52900179e-04 5.69251070e-12]\n",
      " [9.99631166e-01 3.68821435e-04 1.39965105e-11]\n",
      " [9.99293327e-01 7.06599734e-04 7.76508718e-11]\n",
      " [9.98214364e-01 1.78569823e-03 4.54730420e-10]\n",
      " [9.98684227e-01 1.31579128e-03 1.04165981e-10]\n",
      " [9.98684585e-01 1.31546112e-03 2.33894820e-10]\n",
      " [9.97307301e-01 2.69272178e-03 4.51448545e-10]\n",
      " [9.98030245e-01 1.96974864e-03 5.90545335e-10]\n",
      " [9.99233127e-01 7.66933197e-04 1.89773572e-10]\n",
      " [9.88239408e-01 1.17605496e-02 1.45846002e-08]\n",
      " [9.90701795e-01 9.29814950e-03 6.36818331e-09]\n",
      " [9.94125962e-01 5.87404193e-03 3.21334448e-09]\n",
      " [9.94588971e-01 5.41107683e-03 3.72718345e-09]\n",
      " [9.98286903e-01 1.71304657e-03 2.87184665e-10]\n",
      " [9.98351455e-01 1.64857251e-03 2.93385566e-10]\n",
      " [9.94667053e-01 5.33296680e-03 3.62366981e-09]\n",
      " [9.94132340e-01 5.86769124e-03 3.91334964e-09]\n",
      " [9.97373819e-01 2.62615783e-03 7.44500184e-10]\n",
      " [9.99491453e-01 5.08548284e-04 2.46309223e-11]\n",
      " [9.99662876e-01 3.37083562e-04 1.10410795e-11]\n",
      " [9.95798767e-01 4.20124643e-03 2.10230611e-09]\n",
      " [9.98243570e-01 1.75649556e-03 4.89836227e-10]\n",
      " [9.99088645e-01 9.11317708e-04 7.78176135e-11]\n",
      " [9.98797655e-01 1.20236084e-03 1.84521481e-10]\n",
      " [9.95350480e-01 4.64947009e-03 5.14706322e-09]\n",
      " [9.97817993e-01 2.18202081e-03 5.01051201e-10]\n",
      " [9.98448014e-01 1.55199773e-03 4.25933039e-10]\n",
      " [9.82273281e-01 1.77265555e-02 6.82530015e-08]\n",
      " [9.96701062e-01 3.29889404e-03 2.70681744e-09]\n",
      " [9.91191089e-01 8.80885124e-03 1.23787478e-08]\n",
      " [9.93543386e-01 6.45661587e-03 3.24949689e-09]\n",
      " [9.94802117e-01 5.19787986e-03 4.58913574e-09]\n",
      " [9.98646438e-01 1.35354593e-03 1.86835714e-10]\n",
      " [9.96461689e-01 3.53835523e-03 2.28448749e-09]\n",
      " [9.98867869e-01 1.13218068e-03 1.19300861e-10]\n",
      " [9.97747719e-01 2.25227373e-03 6.47413734e-10]\n",
      " [7.41082651e-04 9.96071935e-01 3.18696629e-03]\n",
      " [6.34063152e-04 9.85686123e-01 1.36798462e-02]\n",
      " [3.93258902e-04 9.75813806e-01 2.37928554e-02]\n",
      " [1.47344195e-03 9.12822008e-01 8.57044980e-02]\n",
      " [5.69254975e-04 9.43316281e-01 5.61144315e-02]\n",
      " [6.33298652e-04 9.32649553e-01 6.67171329e-02]\n",
      " [3.53109528e-04 9.43794012e-01 5.58530167e-02]\n",
      " [9.38548706e-03 9.87475693e-01 3.13879107e-03]\n",
      " [8.08504410e-04 9.92023706e-01 7.16770487e-03]\n",
      " [1.27761380e-03 9.25929070e-01 7.27933273e-02]\n",
      " [4.86415392e-03 9.81159568e-01 1.39763225e-02]\n",
      " [8.80213105e-04 9.68629360e-01 3.04904096e-02]\n",
      " [3.03399609e-03 9.93314087e-01 3.65194050e-03]\n",
      " [4.48240025e-04 9.22926307e-01 7.66254589e-02]\n",
      " [6.37894496e-03 9.89739716e-01 3.88135412e-03]\n",
      " [1.27649051e-03 9.95294034e-01 3.42942798e-03]\n",
      " [3.92636750e-04 8.21534812e-01 1.78072557e-01]\n",
      " [2.57749902e-03 9.95453119e-01 1.96937285e-03]\n",
      " [4.23826452e-04 6.04424894e-01 3.95151287e-01]\n",
      " [2.52735522e-03 9.91944849e-01 5.52778225e-03]\n",
      " [8.04098963e-05 3.90603662e-01 6.09315872e-01]\n",
      " [2.21432978e-03 9.93573368e-01 4.21229936e-03]\n",
      " [1.87260273e-04 5.38127720e-01 4.61685091e-01]\n",
      " [6.34406344e-04 9.74541068e-01 2.48244666e-02]\n",
      " [1.28613517e-03 9.94797587e-01 3.91625240e-03]\n",
      " [9.80273122e-04 9.93916690e-01 5.10308705e-03]\n",
      " [5.39953006e-04 9.72730160e-01 2.67299917e-02]\n",
      " [1.74270142e-04 7.23510385e-01 2.76315302e-01]\n",
      " [5.17918845e-04 9.03039634e-01 9.64424312e-02]\n",
      " [1.43258320e-02 9.85039115e-01 6.35061413e-04]\n",
      " [2.92659248e-03 9.90261853e-01 6.81160577e-03]\n",
      " [4.29234700e-03 9.93396223e-01 2.31148559e-03]\n",
      " [2.67915963e-03 9.93261874e-01 4.05901391e-03]\n",
      " [3.38498503e-05 1.84765995e-01 8.15200210e-01]\n",
      " [3.22283100e-04 7.32484698e-01 2.67193049e-01]\n",
      " [4.39973926e-04 9.58305836e-01 4.12542485e-02]\n",
      " [5.14129526e-04 9.80774105e-01 1.87118426e-02]\n",
      " [1.06672267e-03 9.47623014e-01 5.13102263e-02]\n",
      " [1.44337246e-03 9.87052202e-01 1.15044480e-02]\n",
      " [1.48652692e-03 9.52581525e-01 4.59319577e-02]\n",
      " [8.20155139e-04 9.29512739e-01 6.96670637e-02]\n",
      " [5.45200077e-04 9.60487425e-01 3.89673933e-02]\n",
      " [1.97558221e-03 9.90671873e-01 7.35263154e-03]\n",
      " [8.56829435e-03 9.88442838e-01 2.98895338e-03]\n",
      " [1.06783130e-03 9.59538162e-01 3.93939987e-02]\n",
      " [1.55627099e-03 9.91987109e-01 6.45670062e-03]\n",
      " [1.10216695e-03 9.82922435e-01 1.59754921e-02]\n",
      " [1.15126593e-03 9.92410302e-01 6.43843971e-03]\n",
      " [2.64367405e-02 9.72104788e-01 1.45846512e-03]\n",
      " [1.33315497e-03 9.83457923e-01 1.52089633e-02]\n",
      " [3.51424867e-09 2.76384177e-04 9.99723613e-01]\n",
      " [1.52668235e-06 1.36952577e-02 9.86303151e-01]\n",
      " [3.90164246e-07 1.12958374e-02 9.88703787e-01]\n",
      " [1.94161316e-06 3.02827023e-02 9.69715357e-01]\n",
      " [4.59212188e-08 1.64568925e-03 9.98354316e-01]\n",
      " [3.63430530e-08 2.86872243e-03 9.97131228e-01]\n",
      " [8.88492013e-06 3.00764907e-02 9.69914615e-01]\n",
      " [8.12063661e-07 2.80804243e-02 9.71918702e-01]\n",
      " [6.14657608e-07 1.07295122e-02 9.89269912e-01]\n",
      " [3.25206031e-08 2.45347945e-03 9.97546494e-01]\n",
      " [2.09303162e-05 1.75584868e-01 8.24394166e-01]\n",
      " [3.01866885e-06 2.98521668e-02 9.70144749e-01]\n",
      " [1.43956152e-06 2.36349478e-02 9.76363659e-01]\n",
      " [4.31395222e-07 3.76588968e-03 9.96233642e-01]\n",
      " [3.61126169e-08 6.25490036e-04 9.99374449e-01]\n",
      " [4.17799299e-07 7.80888507e-03 9.92190659e-01]\n",
      " [7.90406557e-06 9.71036702e-02 9.02888417e-01]\n",
      " [1.42553688e-07 1.68650132e-02 9.83134866e-01]\n",
      " [8.59121607e-10 1.24007944e-04 9.99876022e-01]\n",
      " [3.21409716e-05 1.18149929e-01 8.81817937e-01]\n",
      " [2.04744651e-07 6.21231180e-03 9.93787527e-01]\n",
      " [1.42545684e-06 1.14779361e-02 9.88520622e-01]\n",
      " [3.66628932e-08 2.77952873e-03 9.97220397e-01]\n",
      " [4.21624645e-05 1.89613968e-01 8.10343921e-01]\n",
      " [9.05515265e-07 2.30310913e-02 9.76968050e-01]\n",
      " [7.09992628e-06 1.60275251e-01 8.39717627e-01]\n",
      " [6.72218885e-05 2.69585967e-01 7.30346799e-01]\n",
      " [5.33532111e-05 2.74185807e-01 7.25760818e-01]\n",
      " [1.34052527e-07 2.98424694e-03 9.97015595e-01]\n",
      " [4.17632182e-05 4.89471823e-01 5.10486364e-01]\n",
      " [9.95013352e-07 2.63733789e-02 9.73625600e-01]\n",
      " [5.95151187e-06 2.92851061e-01 7.07142949e-01]\n",
      " [5.48411485e-08 1.40155223e-03 9.98598397e-01]\n",
      " [1.39408323e-04 5.95470071e-01 4.04390484e-01]\n",
      " [1.33498997e-05 1.23780049e-01 8.76206636e-01]\n",
      " [1.31612353e-07 5.53595927e-03 9.94463861e-01]\n",
      " [4.51267930e-08 1.75312674e-03 9.98246908e-01]\n",
      " [7.96243057e-06 1.03688665e-01 8.96303356e-01]\n",
      " [6.64124091e-05 2.99252272e-01 7.00681329e-01]\n",
      " [4.47995990e-06 6.03830926e-02 9.39612448e-01]\n",
      " [5.83811577e-08 1.82720006e-03 9.98172760e-01]\n",
      " [4.03395143e-06 4.26658988e-02 9.57330108e-01]\n",
      " [1.52668235e-06 1.36952577e-02 9.86303151e-01]\n",
      " [5.00323871e-08 2.23549060e-03 9.97764468e-01]\n",
      " [2.57686281e-08 1.13836711e-03 9.98861670e-01]\n",
      " [9.51449010e-07 1.27756428e-02 9.87223387e-01]\n",
      " [6.23650112e-06 3.70008498e-02 9.62992907e-01]\n",
      " [7.19971877e-06 6.94080666e-02 9.30584729e-01]\n",
      " [2.47216747e-07 6.17106073e-03 9.93828714e-01]\n",
      " [1.19827973e-05 9.45117325e-02 9.05476213e-01]]\n"
     ]
    }
   ],
   "source": [
    "# let's see result\n",
    "print(predict)\n",
    "\n",
    "# It is 2-d array.\n",
    "# For every input model returns probability into which class it belongs to, \n",
    "# i.e. 0.95 it belongs to first class, 0.01 to second class, 0.04 to third class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# numpy has a method that returns the max argument form array\n",
    "import numpy as np\n",
    "\n",
    "predict_converted = np.argmax(predict, axis=1)\n",
    "\n",
    "print(predict_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 48,  1],\n",
       "       [ 0,  2, 49]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(predict_converted, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run script few times to see that the result (accuracy, loss) is different each time.\n",
    "# the reason is that it finds local minimum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
